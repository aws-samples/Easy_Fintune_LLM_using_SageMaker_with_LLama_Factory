{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LLama Factory finetune on SageMaker \n",
    "# 1. Single GPU QLORA- 本地notebook实例训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq sagemaker boto3 datasets==2.21.0 huggingface-hub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install torch==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import boto3\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import sagemaker\n",
    "from sagemaker.collection import Collection\n",
    "from sagemaker.utils import name_from_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session =  sagemaker.session.Session() #sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "sm_client = boto3.client('sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集1. 从huggingface上下载ruozhiba数据集\n",
    "- 改数据集有近5k条数据，本次实验我们可以只用前1k条做训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1967fd83e759412b988b17b0a66433a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/2.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3a73c62e194e3b9a2a8d76b0b3bab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 4898\n",
      "\n",
      "Training sample:\n",
      "\n",
      "{'input': '', 'instruction': '三个人里面有三个是弱智你能分辨出他们之中谁不是弱智吗？ 能吗？', 'output': \"这个问题本身是自相矛盾的，因为它先假设了'三个人里面有三个是弱智'，这意味着所有三个人都是弱智。因此，在逻辑上讲，不存在'他们之中谁不是弱智'这一选项。如果所有人都具有相同的属性（在本例中是'弱智'），那么就不可能从中挑选出一个与众不同的人。这可能是一个设计来考查逻辑思维或是一种幽默表达的题目。\"}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from random import randrange\n",
    "dataset_name = \"hfl/ruozhiba_gpt4\"\n",
    "# Load dataset from the hub\n",
    "train_dataset = load_dataset(dataset_name, split=\"train\",revision='41d2c61beb86c8d4c61916cc656c39d018c40ce5')\n",
    "\n",
    "print(f\"Training size: {len(train_dataset)}\")\n",
    "print(\"\\nTraining sample:\\n\")\n",
    "print(train_dataset[randrange(len(train_dataset))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存到本地json文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('./train',exist_ok=True)\n",
    "all_examples = []\n",
    "for example in train_dataset:\n",
    "    all_examples.append(example)\n",
    "    \n",
    "with open('./train/ruozhiba.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_examples, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集2. 身份数据集\n",
    "```json\n",
    "[{'instruction': 'hi',\n",
    "  'input': '',\n",
    "  'output': 'Hello! I am {{name}}, an AI assistant developed by {{author}}. How can I assist you today?'},\n",
    " {'instruction': 'hello',\n",
    "  'input': '',\n",
    "  'output': 'Hello! I am {{name}}, an AI assistant developed by {{author}}. How can I assist you today?'},\n",
    " {'instruction': 'Who are you?',\n",
    "  'input': '',\n",
    "  'output': 'I am {{name}}, an AI assistant developed by {{author}}. How can I assist you today?'}]\n",
    "```\n",
    "把其中的name和author替换成您自己想替换的值，这样微调完成之后，问模型“你是谁，谁创造的你？”这类的身份问题，模型就会按这个新的值来回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_identity(origin_obj,name,author):\n",
    "    ret = []\n",
    "    for ele in origin_obj:\n",
    "        ele['output'] = ele['output'].replace(\"{{name}}\",name).replace(\"{{author}}\",author)\n",
    "        ret.append(ele)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- 替换成您自己的设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NAME = <Your Name>\n",
    "AUTHOR = <Your Author>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Easy_Fintune_LLM_using_SageMaker_with_LLama_Factory\n",
      "/home/ec2-user/SageMaker/Easy_Fintune_LLM_using_SageMaker_with_LLama_Factory\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "%cd ~/SageMaker/Easy_Fintune_LLM_using_SageMaker_with_LLama_Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'hi',\n",
       "  'input': '',\n",
       "  'output': 'Hello! I am Riverbot, an AI assistant developed by Riverbot. How can I assist you today?'},\n",
       " {'instruction': 'hello',\n",
       "  'input': '',\n",
       "  'output': 'Hello! I am Riverbot, an AI assistant developed by Riverbot. How can I assist you today?'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "file_name = './LLaMA-Factory/data/identity.json'\n",
    "with open(file_name) as f:\n",
    "    identity = json.load(f)\n",
    "identity_2 = format_identity(identity,name=NAME,author=AUTHOR)\n",
    "identity_2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./train/identity_2.json','w') as f:\n",
    "    json.dump(identity_2,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把数据copy至S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_data_uri = f\"s3://{default_bucket}/dataset-for-training\"\n",
    "training_input_path = f'{s3_data_uri}/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving training dataset to: s3://sagemaker-us-east-1-434444145045/dataset-for-training/train\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3\n",
    "sagemaker.s3.S3Uploader.upload(local_path=\"./train/ruozhiba.json\", desired_s3_uri=training_input_path, sagemaker_session=sagemaker_session)\n",
    "sagemaker.s3.S3Uploader.upload(local_path=\"./train/identity_2.json\", desired_s3_uri=training_input_path, sagemaker_session=sagemaker_session)\n",
    "\n",
    "print(f\"saving training dataset to: {training_input_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载基础模型到本地，并上传到s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d386e19909df486d9d92d592945defb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bd71fbde9c43edb5134e7ec7056708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/885 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1918ec68c5914e72a8a4b3ebdf135066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/152 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361749973fd34ab0bd98b357f9f144b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/63.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b91566c37214e618f974b71877fa289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b023e8c109e40a8b20a7233469eb839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15f80b468b74d4b9d4d4d1b576549b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/37.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff357777b134330abd41b54e64e6dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea480a04a89451fb4dab53ec93985fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d17ede820b44fbb98e7e4c024029f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6e53fe22744cbc85cd6a7189547db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Llama-3-8B-Instruct-AWQ/models--TechxGenus--Meta-Llama-3-8B-Instruct-AWQ/snapshots/129d90727841a07bcdb3173ed4165d1353b44386'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "# 更换成hf上的模型\n",
    "model_name = \"TechxGenus/Meta-Llama-3-8B-Instruct-AWQ\"\n",
    "local_model_path = Path(\"./Llama-3-8B-Instruct-AWQ\")\n",
    "\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "snapshot_download(repo_id=model_name, cache_dir=local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: Llama-3-8B-Instruct-AWQ/models--TechxGenus--Meta-Llama-3-8B-Instruct-AWQ/snapshots/129d90727841a07bcdb3173ed4165d1353b44386/.gitattributes to s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/.gitattributes\n",
      "upload: Llama-3-8B-Instruct-AWQ/models--TechxGenus--Meta-Llama-3-8B-Instruct-AWQ/snapshots/129d90727841a07bcdb3173ed4165d1353b44386/generation_config.json to s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/generation_config.json\n",
      "upload: Llama-3-8B-Instruct-AWQ/models--TechxGenus--Meta-Llama-3-8B-Instruct-AWQ/snapshots/129d90727841a07bcdb3173ed4165d1353b44386/tokenizer_config.json to s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/tokenizer_config.json\n",
      "upload: Llama-3-8B-Instruct-AWQ/models--TechxGenus--Meta-Llama-3-8B-Instruct-AWQ/snapshots/129d90727841a07bcdb3173ed4165d1353b44386/special_tokens_map.json to s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/special_tokens_map.json\n",
      "upload: Llama-3-8B-Instruct-AWQ/models--TechxGenus--Meta-Llama-3-8B-Instruct-AWQ/snapshots/129d90727841a07bcdb3173ed4165d1353b44386/config.json to s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/config.json\n",
      "upload: Llama-3-8B-Instruct-AWQ/models--TechxGenus--Meta-Llama-3-8B-Instruct-AWQ/snapshots/129d90727841a07bcdb3173ed4165d1353b44386/model.safetensors.index.json to s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/model.safetensors.index.json\n",
      "upload: Llama-3-8B-Instruct-AWQ/models--TechxGenus--Meta-Llama-3-8B-Instruct-AWQ/snapshots/129d90727841a07bcdb3173ed4165d1353b44386/README.md to s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/README.md\n",
      "upload: Llama-3-8B-Instruct-AWQ/models--TechxGenus--Meta-Llama-3-8B-Instruct-AWQ/snapshots/129d90727841a07bcdb3173ed4165d1353b44386/tokenizer.json to s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/tokenizer.json\n",
      "upload: Llama-3-8B-Instruct-AWQ/models--TechxGenus--Meta-Llama-3-8B-Instruct-AWQ/snapshots/129d90727841a07bcdb3173ed4165d1353b44386/model-00002-of-00002.safetensors to s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/model-00002-of-00002.safetensors\n",
      "upload: Llama-3-8B-Instruct-AWQ/models--TechxGenus--Meta-Llama-3-8B-Instruct-AWQ/snapshots/129d90727841a07bcdb3173ed4165d1353b44386/model-00001-of-00002.safetensors to s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/model-00001-of-00002.safetensors\n",
      "uploaded to s3_model_path:s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/\n"
     ]
    }
   ],
   "source": [
    "s3_model_prefix = \"Meta-Llama-3-8B-Instruct-AWQ\"  \n",
    "model_snapshot_path = list(local_model_path.glob(\"**/snapshots/*\"))[0]\n",
    "s3_model_path =  f\"s3://{default_bucket}/{s3_model_prefix}/\"\n",
    "!aws s3 sync {model_snapshot_path}/ s3://{default_bucket}/{s3_model_prefix}/\n",
    "print(f\"uploaded to s3_model_path:{s3_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备LLaMA-Factory 的 dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = './LLaMA-Factory/data/dataset_info.json'\n",
    "with open(file_name) as f:\n",
    "    datainfo = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datainfo['identity']={'file_name': 'identity_2.json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datainfo['ruozhiba']={\n",
    "    'file_name':'ruozhiba.json',\n",
    "    \"columns\": {\n",
    "    \"prompt\": \"instruction\",\n",
    "    \"query\": \"input\",\n",
    "    \"response\": \"output\",\n",
    "  }      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./LLaMA-Factory/data/dataset_info.json','w') as f:\n",
    "    json.dump(fp=f,obj=datainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备LLaMA-Factory 的 训练配置yaml文件\n",
    "###  从LLaMA-Factory/examples/train_qlora/目录中复制出llama3_lora_sft_awq.yaml，并修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name_or_path': 'TechxGenus/Meta-Llama-3-8B-Instruct-AWQ',\n",
       " 'stage': 'sft',\n",
       " 'do_train': True,\n",
       " 'finetuning_type': 'lora',\n",
       " 'lora_target': 'all',\n",
       " 'dataset': 'identity,alpaca_en_demo',\n",
       " 'template': 'llama3',\n",
       " 'cutoff_len': 1024,\n",
       " 'max_samples': 1000,\n",
       " 'overwrite_cache': True,\n",
       " 'preprocessing_num_workers': 16,\n",
       " 'output_dir': 'saves/llama3-8b/lora/sft',\n",
       " 'logging_steps': 10,\n",
       " 'save_steps': 500,\n",
       " 'plot_loss': True,\n",
       " 'overwrite_output_dir': True,\n",
       " 'per_device_train_batch_size': 1,\n",
       " 'gradient_accumulation_steps': 8,\n",
       " 'learning_rate': 0.0001,\n",
       " 'num_train_epochs': 3.0,\n",
       " 'lr_scheduler_type': 'cosine',\n",
       " 'warmup_ratio': 0.1,\n",
       " 'bf16': True,\n",
       " 'ddp_timeout': 180000000,\n",
       " 'val_size': 0.1,\n",
       " 'per_device_eval_batch_size': 1,\n",
       " 'eval_strategy': 'steps',\n",
       " 'eval_steps': 500}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load template\n",
    "import yaml\n",
    "file_name = './LLaMA-Factory/examples/train_qlora/llama3_lora_sft_awq.yaml'\n",
    "with open(file_name) as f:\n",
    "    doc = yaml.safe_load(f)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#设置模型的保存目录在本notebook实例本地\n",
    "save_dir = '/home/ec2-user/SageMaker/Easy_Fintune_LLM_using_SageMaker_with_LLama_Factory/finetuned_model'\n",
    "# doc['output_dir'] = save_dir\n",
    "\n",
    "# 如果是用SageMaker则使用以下模型文件路径\n",
    "doc['output_dir'] ='/tmp/finetuned_model'\n",
    "doc['per_device_train_batch_size'] =1\n",
    "doc['gradient_accumulation_steps'] =8\n",
    "# doc['lora_target'] = 'all'\n",
    "doc['cutoff_len'] = 2048\n",
    "doc['num_train_epochs'] = 3.0\n",
    "doc['warmup_steps'] = 10\n",
    "\n",
    "#实验时间，只选取前200条数据做训练\n",
    "doc['max_samples'] = 200 \n",
    "#数据集\n",
    "doc['dataset'] = 'identity,ruozhiba'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存为训练配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name_or_path': 'TechxGenus/Meta-Llama-3-8B-Instruct-AWQ',\n",
       " 'stage': 'sft',\n",
       " 'do_train': True,\n",
       " 'finetuning_type': 'lora',\n",
       " 'lora_target': 'all',\n",
       " 'dataset': 'identity,ruozhiba',\n",
       " 'template': 'llama3',\n",
       " 'cutoff_len': 2048,\n",
       " 'max_samples': 200,\n",
       " 'overwrite_cache': True,\n",
       " 'preprocessing_num_workers': 16,\n",
       " 'output_dir': '/tmp/finetuned_model',\n",
       " 'logging_steps': 10,\n",
       " 'save_steps': 500,\n",
       " 'plot_loss': True,\n",
       " 'overwrite_output_dir': True,\n",
       " 'per_device_train_batch_size': 1,\n",
       " 'gradient_accumulation_steps': 8,\n",
       " 'learning_rate': 0.0001,\n",
       " 'num_train_epochs': 3.0,\n",
       " 'lr_scheduler_type': 'cosine',\n",
       " 'warmup_ratio': 0.1,\n",
       " 'bf16': True,\n",
       " 'ddp_timeout': 180000000,\n",
       " 'val_size': 0.1,\n",
       " 'per_device_eval_batch_size': 1,\n",
       " 'eval_strategy': 'steps',\n",
       " 'eval_steps': 500,\n",
       " 'warmup_steps': 10}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_config = 'sg_config_qlora.yaml'\n",
    "with open(f'./LLaMA-Factory/{sg_config}', 'w') as f:\n",
    "    yaml.safe_dump(doc, f)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_config = 'sg_config_qlora.yaml'\n",
    "with open(f'./LLaMA-Factory/{sg_config}', 'w') as f:\n",
    "    yaml.safe_dump(doc, f)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本地GPU测试提交 Training job\n",
    "\n",
    "### 由于我们的实验环境限制，无法提交Training Job，所以在本次实验是在notebook实例中进行训练\n",
    "### 如果您在自己的AWS环境中，且有SageMaker Training Job 所需GPU实例的quota，则可以用如下代码提交，instance_type改成'ml.g5.2xlarge' \n",
    "\n",
    "```python\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from datetime import datetime\n",
    "\n",
    "instance_count = 1\n",
    "instance_type = 'local_gpu' \n",
    "max_time = 3600*24\n",
    "\n",
    "# Get the current time\n",
    "current_time = datetime.now()\n",
    "\n",
    "# wandb.sagemaker_auth(path=\"./\")\n",
    "# Format the current time as a string\n",
    "formatted_time = current_time.strftime(\"%Y%m%d%H%M%S\")\n",
    "print(formatted_time)\n",
    "\n",
    "base_job_name = 'llama3-8b-qlora-finetune'\n",
    "environment = {\n",
    "    \"s3_model_path\":s3_model_path,\n",
    "    'NODE_NUMBER':str(instance_count),\n",
    "    \"s3_data_paths\":f\"{training_input_path}\",\n",
    "    \"sg_config\":sg_config,\n",
    "    'OUTPUT_MODEL_S3_PATH': f's3://{default_bucket}/llama3-8b-qlora/', # destination\n",
    "    'WANDB_DISABLED':\"true\"\n",
    "}\n",
    "\n",
    "estimator = PyTorch(entry_point='entry_single_lora.py',\n",
    "                            source_dir='./LLaMA-Factory/',\n",
    "                            role=role,\n",
    "                            base_job_name=base_job_name,\n",
    "                            environment=environment,\n",
    "                            framework_version='2.3.0',\n",
    "                            py_version='py311',\n",
    "                            script_mode=True,\n",
    "                            instance_count=instance_count,\n",
    "                            instance_type=instance_type,\n",
    "                            # enable_remote_debug=True,\n",
    "                            # keep_alive_period_in_seconds=600,\n",
    "                            max_run=max_time)\n",
    "\n",
    "estimator.fit()\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20241102112658\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from datetime import datetime\n",
    "\n",
    "instance_count = 1\n",
    "\n",
    "#使用本地机器，也可以指定为 ml.g5.2xlarge等其他实例\n",
    "instance_type = 'local_gpu' \n",
    "max_time = 3600*24\n",
    "\n",
    "# Get the current time\n",
    "current_time = datetime.now()\n",
    "\n",
    "# wandb.sagemaker_auth(path=\"./\")\n",
    "# Format the current time as a string\n",
    "formatted_time = current_time.strftime(\"%Y%m%d%H%M%S\")\n",
    "print(formatted_time)\n",
    "\n",
    "base_job_name = 'llama3-8b-qlora-finetune'\n",
    "environment = {\n",
    "    \"s3_model_path\":s3_model_path,\n",
    "    'NODE_NUMBER':str(instance_count),\n",
    "    \"s3_data_paths\":f\"{training_input_path}\",\n",
    "    \"sg_config\":sg_config,\n",
    "    'OUTPUT_MODEL_S3_PATH': f's3://{default_bucket}/llama3-8b-qlora/', # destination\n",
    "    'WANDB_DISABLED':\"true\"\n",
    "}\n",
    "\n",
    "estimator = PyTorch(entry_point='entry_single_lora.py',\n",
    "                            source_dir='./LLaMA-Factory/',\n",
    "                            role=role,\n",
    "                            base_job_name=base_job_name,\n",
    "                            environment=environment,\n",
    "                            framework_version='2.3.0',\n",
    "                            py_version='py311',\n",
    "                            script_mode=True,\n",
    "                            instance_count=instance_count,\n",
    "                            instance_type=instance_type,\n",
    "                            # enable_remote_debug=True,\n",
    "                            # keep_alive_period_in_seconds=600,\n",
    "                            max_run=max_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: llama3-8b-qlora-finetune-2024-11-02-11-26-59-557\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.local.image:'Docker Compose' is not installed. Proceeding to check for 'docker-compose' CLI.\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker Compose CLI.\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-une3w:\n",
      "    command: train\n",
      "    container_name: f4qy70hcyr-algo-1-une3w\n",
      "    deploy:\n",
      "      resources:\n",
      "        reservations:\n",
      "          devices:\n",
      "          - capabilities:\n",
      "            - gpu\n",
      "            count: all\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.3.0-gpu-py311\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-une3w\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpylaeupv0/algo-1-une3w/output:/opt/ml/output\n",
      "    - /tmp/tmpylaeupv0/algo-1-une3w/input:/opt/ml/input\n",
      "    - /tmp/tmpylaeupv0/algo-1-une3w/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpylaeupv0/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpylaeupv0/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Container f4qy70hcyr-algo-1-une3w  Creating\n",
      " Container f4qy70hcyr-algo-1-une3w  Created\n",
      "Attaching to f4qy70hcyr-algo-1-une3w\n",
      "f4qy70hcyr-algo-1-une3w  | /opt/conda/lib/python3.11/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "f4qy70hcyr-algo-1-une3w  |   \"cipher\": algorithms.TripleDES,\n",
      "f4qy70hcyr-algo-1-une3w  | /opt/conda/lib/python3.11/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "f4qy70hcyr-algo-1-une3w  |   \"class\": algorithms.TripleDES,\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:27:11,171 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:27:11,194 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:27:11,201 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:27:11,204 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:27:11,206 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:27:12,358 botocore.credentials INFO     Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:27:14,458 sagemaker-training-toolkit INFO     Installing module.\n",
      "f4qy70hcyr-algo-1-une3w  | Processing /opt/ml/code\n",
      "f4qy70hcyr-algo-1-une3w  | Installing build dependencies: started\n",
      "f4qy70hcyr-algo-1-une3w  | Installing build dependencies: finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Getting requirements to build wheel: started\n",
      "f4qy70hcyr-algo-1-une3w  | Getting requirements to build wheel: finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (pyproject.toml): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting autoawq@ git+https://github.com/casper-hansen/AutoAWQ.git (from -r requirements.txt (line 22))\n",
      "f4qy70hcyr-algo-1-une3w  | Cloning https://github.com/casper-hansen/AutoAWQ.git to /tmp/pip-install-w8k3ahr7/autoawq_b4815cc1685a4b95adc065b4bd8c73b4\n",
      "f4qy70hcyr-algo-1-une3w  | Running command git clone --filter=blob:none --quiet https://github.com/casper-hansen/AutoAWQ.git /tmp/pip-install-w8k3ahr7/autoawq_b4815cc1685a4b95adc065b4bd8c73b4\n",
      "f4qy70hcyr-algo-1-une3w  | Resolved https://github.com/casper-hansen/AutoAWQ.git to commit 79547665bdb27768a9b392ef375776b020acbf0c\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting transformers<=4.45.2,>=4.41.2 (from -r requirements.txt (line 1))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting datasets<=2.21.0,>=2.16.0 (from -r requirements.txt (line 2))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting accelerate<=0.34.2,>=0.34.0 (from -r requirements.txt (line 3))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting peft<=0.12.0,>=0.11.1 (from -r requirements.txt (line 4))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting trl<=0.9.6,>=0.8.6 (from -r requirements.txt (line 5))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting gradio<5.0.0,>=4.0.0 (from -r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pandas>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (2.2.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.13.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (0.8.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting sentencepiece (from -r requirements.txt (line 10))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting tiktoken (from -r requirements.txt (line 11))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (3.20.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting uvicorn (from -r requirements.txt (line 13))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pydantic in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (2.7.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting fastapi (from -r requirements.txt (line 15))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting sse-starlette (from -r requirements.txt (line 16))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading sse_starlette-2.1.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: matplotlib>=3.7.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (3.8.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting fire (from -r requirements.txt (line 18))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (23.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (6.0.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting deepspeed==0.15.1 (from -r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading deepspeed-0.15.1.tar.gz (1.4 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 31.2 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting metrics (from -r requirements.txt (line 23))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading metrics-0.3.3.tar.gz (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting bitsandbytes>=0.39.0 (from -r requirements.txt (line 24))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting rouge-chinese (from -r requirements.txt (line 25))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rouge_chinese-1.0.3-py3-none-any.whl.metadata (7.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting jieba (from -r requirements.txt (line 26))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.2/19.2 MB 104.6 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting modelscope (from -r requirements.txt (line 28))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading modelscope-1.19.2-py3-none-any.whl.metadata (40 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting wandb (from -r requirements.txt (line 29))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading wandb-0.18.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting vllm==0.6.0 (from -r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading vllm-0.6.0-cp38-abi3-manylinux1_x86_64.whl.metadata (2.2 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting nltk (from -r requirements.txt (line 31))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 33)) (1.26.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting av (from -r requirements.txt (line 34))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading av-13.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting hjson (from deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: ninja in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.1->-r requirements.txt (line 21)) (1.11.1.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.1->-r requirements.txt (line 21)) (5.9.8)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting py-cpuinfo (from deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.1->-r requirements.txt (line 21)) (2.3.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.1->-r requirements.txt (line 21)) (4.66.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting nvidia-ml-py (from deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (2.32.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting tokenizers>=0.19.1 (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading tokenizers-0.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting aiohttp (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading aiohttp-3.10.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting openai>=1.0 (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading openai-1.53.0-py3-none-any.whl.metadata (24 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting pydantic (from -r requirements.txt (line 14))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (10.3.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting prometheus-client>=0.18.0 (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading prometheus_client-0.21.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting lm-format-enforcer==0.10.6 (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading lm_format_enforcer-0.10.6-py3-none-any.whl.metadata (16 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting outlines<0.1,>=0.0.43 (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading outlines-0.0.46-py3-none-any.whl.metadata (15 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: typing-extensions>=4.10 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (4.11.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: filelock>=3.10.4 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (3.14.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting partial-json-parser (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading partial_json_parser-0.2.1.1.post4-py3-none-any.whl.metadata (6.2 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pyzmq in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (26.0.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting msgspec (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading msgspec-0.18.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting gguf==0.9.1 (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading gguf-0.9.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (6.11.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting mistral-common>=1.3.4 (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading mistral_common-1.4.4-py3-none-any.whl.metadata (4.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting ray>=2.9 (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading ray-2.38.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting torch (from deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting torchvision==0.19 (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting xformers==0.0.27.post2 (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading xformers-0.0.27.post2-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting vllm-flash-attn==2.6.1 (from vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading vllm_flash_attn-2.6.1-cp311-cp311-manylinux1_x86_64.whl.metadata (476 bytes)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting interegular>=0.3.2 (from lm-format-enforcer==0.10.6->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (1.12)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (3.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (3.1.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (2024.5.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting nvidia-curand-cu12==10.3.2.106 (from torch->deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting nvidia-nccl-cu12==2.20.5 (from torch->deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting nvidia-nvtx-cu12==12.1.105 (from torch->deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting triton==3.0.0 (from torch->deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed==0.15.1->-r requirements.txt (line 21))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting huggingface-hub<1.0,>=0.23.2 (from transformers<=4.45.2,>=4.41.2->-r requirements.txt (line 1))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting regex!=2019.12.17 (from transformers<=4.45.2,>=4.41.2->-r requirements.txt (line 1))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading regex-2024.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers<=4.45.2,>=4.41.2->-r requirements.txt (line 1)) (0.4.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (16.1.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (0.3.8)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting xxhash (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (0.70.16)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting tyro>=0.5.11 (from trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting aiofiles<24.0,>=22.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting anyio<5.0,>=3.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting ffmpy (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting gradio-client==1.3.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting httpx>=0.24.1 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting importlib-resources<7.0,>=1.3 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (2.1.5)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting orjson~=3.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading orjson-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting pydub (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting python-multipart>=0.0.9 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading python_multipart-0.0.17-py3-none-any.whl.metadata (1.8 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting ruff>=0.2.2 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading ruff-0.7.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting semantic-version~=2.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting tomlkit==0.12.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting typer<1.0,>=0.12 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting urllib3~=2.0 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2.9.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2024.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2024.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn->-r requirements.txt (line 13)) (8.1.7)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting h11>=0.8 (from uvicorn->-r requirements.txt (line 13))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic->-r requirements.txt (line 14)) (0.7.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting pydantic-core==2.23.4 (from pydantic->-r requirements.txt (line 14))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting starlette<0.42.0,>=0.40.0 (from fastapi->-r requirements.txt (line 15))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.2.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (0.12.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (4.52.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.4.5)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (3.1.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting termcolor (from fire->-r requirements.txt (line 18))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: zstandard in /opt/conda/lib/python3.11/site-packages (from autoawq@ git+https://github.com/casper-hansen/AutoAWQ.git->-r requirements.txt (line 22)) (0.19.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting Pygments==2.2.0 (from metrics->-r requirements.txt (line 23))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading Pygments-2.2.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting pathspec==0.5.5 (from metrics->-r requirements.txt (line 23))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading pathspec-0.5.5.tar.gz (21 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting pathlib2>=2.3.0 (from metrics->-r requirements.txt (line 23))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from rouge-chinese->-r requirements.txt (line 25)) (1.16.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 29))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 29))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 29)) (4.1.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting sentry-sdk>=2.0.0 (from wandb->-r requirements.txt (line 29))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading sentry_sdk-2.17.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting setproctitle (from wandb->-r requirements.txt (line 29))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 29)) (75.2.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk->-r requirements.txt (line 31)) (1.4.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (3.7)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting sniffio>=1.1 (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting aiosignal>=1.1.2 (from aiohttp->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->vllm==0.6.0->-r requirements.txt (line 30)) (23.2.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting frozenlist>=1.1.1 (from aiohttp->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting multidict<7.0,>=4.5 (from aiohttp->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting yarl<2.0,>=1.12.0 (from aiohttp->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading yarl-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (64 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 29))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx>=0.24.1->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (2024.8.30)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting httpcore==1.* (from httpx>=0.24.1->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: jsonschema<5.0.0,>=4.21.1 in /opt/conda/lib/python3.11/site-packages (from mistral-common>=1.3.4->vllm==0.6.0->-r requirements.txt (line 30)) (4.22.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting tiktoken (from -r requirements.txt (line 11))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai>=1.0->vllm==0.6.0->-r requirements.txt (line 30)) (1.8.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting jiter<1,>=0.4.0 (from openai>=1.0->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading jiter-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting lark (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30)) (1.6.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.11/site-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30)) (2.2.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting diskcache (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30)) (0.59.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: referencing in /opt/conda/lib/python3.11/site-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30)) (0.35.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting pycountry (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting pyairports (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading pyairports-2.1.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.9->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->vllm==0.6.0->-r requirements.txt (line 30)) (3.3.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (1.5.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (13.7.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting docstring-parser>=0.16 (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata->vllm==0.6.0->-r requirements.txt (line 30)) (3.20.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting httptools>=0.5.0 (from uvicorn[standard]->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading watchfiles-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 29))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.3.4->vllm==0.6.0->-r requirements.txt (line 30)) (2023.12.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.3.4->vllm==0.6.0->-r requirements.txt (line 30)) (0.18.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (3.0.0)\n",
      "f4qy70hcyr-algo-1-une3w  | INFO: pip is looking at multiple versions of rich to determine which version is compatible with other requirements. This could take a while.\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.9.3-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.9.2-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.9.1-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.9.0-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.8.0-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | INFO: pip is still looking at multiple versions of rich to determine which version is compatible with other requirements. This could take a while.\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.6.0-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.5.3-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.5.2-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.5.1-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.5.0-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.4.1-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting markdown-it-py<3.0.0,>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading markdown_it_py-2.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.4.0-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.3.5-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.3.4-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.3.3-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.3.2-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.3.1-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting commonmark<0.10.0,>=0.9.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.0.1-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-13.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-12.6.0-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-12.5.1-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-12.5.0-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-12.4.4-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-12.4.3-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-12.4.2-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-12.4.1-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-12.4.0-py3-none-any.whl.metadata (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-12.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-12.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-12.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-12.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-11.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (0.4.6)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-11.1.0-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting tyro>=0.5.11 (from trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading tyro-0.8.13-py3-none-any.whl.metadata (8.4 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-11.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-10.16.2-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-10.16.1-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-10.16.0-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-10.15.2-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-10.15.1-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-10.15.0-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-10.14.0-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-10.13.0-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-10.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rich-10.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting typer<1.0,>=0.12 (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading typer-0.12.4-py3-none-any.whl.metadata (15 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading typer-0.12.2-py3-none-any.whl.metadata (15 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading typer-0.12.1-py3-none-any.whl.metadata (15 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading typer-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting typer-slim==0.12.0 (from typer-slim[standard]==0.12.0->typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading typer_slim-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting typer-cli==0.12.0 (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading typer_cli-0.12.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting metrics (from -r requirements.txt (line 23))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading metrics-0.3.2.tar.gz (18 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading metrics-0.3.1.tar.gz (14 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading metrics-0.3.0.tar.gz (14 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading metrics-0.2.8.tar.gz (12 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting pathspec==0.5.3 (from metrics->-r requirements.txt (line 23))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading pathspec-0.5.3.tar.gz (20 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting metrics (from -r requirements.txt (line 23))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading metrics-0.2.7.tar.gz (12 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading metrics-0.2.6.tar.gz (12 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: Pygments>=0.8 in /opt/conda/lib/python3.11/site-packages (from metrics->-r requirements.txt (line 23)) (2.18.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->vllm==0.6.0->-r requirements.txt (line 30))\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading propcache-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30)) (0.42.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (1.3.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (0.1.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading vllm-0.6.0-cp38-abi3-manylinux1_x86_64.whl (170.6 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.6/170.6 MB 117.6 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading gguf-0.9.1-py3-none-any.whl (49 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading lm_format_enforcer-0.10.6-py3-none-any.whl (43 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 797.3/797.3 MB 62.8 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 121.7 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading vllm_flash_attn-2.6.1-cp311-cp311-manylinux1_x86_64.whl (75.9 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.9/75.9 MB 113.4 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading xformers-0.0.27.post2-cp311-cp311-manylinux2014_x86_64.whl (20.8 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.8/20.8 MB 130.3 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 120.0 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 146.4 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 155.6 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 58.3 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 76.6 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 124.8 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 147.6 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 138.2 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 125.1 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.2/176.2 MB 135.4 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.4/209.4 MB 154.0 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.9/9.9 MB 155.9 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 527.3/527.3 kB 29.7 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.1/18.1 MB 114.5 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 82.5 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 107.2 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading sse_starlette-2.1.3-py3-none-any.whl (9.4 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.4/122.4 MB 157.1 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading modelscope-1.19.2-py3-none-any.whl (5.8 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 128.8 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading wandb-0.18.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.0/16.0 MB 126.0 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 100.6 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading av-13.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.0 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.0/34.0 MB 115.2 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading aiohttp-3.10.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 50.6 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading mistral_common-1.4.4-py3-none-any.whl (6.0 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 117.9 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 81.0 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading openai-1.53.0-py3-none-any.whl (387 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading orjson-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading outlines-0.0.46-py3-none-any.whl (101 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading prometheus_client-0.21.0-py3-none-any.whl (54 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading python_multipart-0.0.17-py3-none-any.whl (24 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading ray-2.38.0-cp311-cp311-manylinux2014_x86_64.whl (66.2 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.2/66.2 MB 117.2 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading regex-2024.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 792.8/792.8 kB 57.3 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading ruff-0.7.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.0/11.0 MB 64.2 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading sentry_sdk-2.17.0-py2.py3-none-any.whl (314 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading tokenizers-0.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 111.5 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading tyro-0.8.14-py3-none-any.whl (109 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading msgspec-0.18.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading partial_json_parser-0.2.1.1.post4-py3-none-any.whl (9.9 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading jiter-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.0/4.0 MB 113.3 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading watchfiles-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading yarl-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading pyairports-2.1.1-py3-none-any.whl (371 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 125.1 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Downloading propcache-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.7/19.7 MB 138.3 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Building wheels for collected packages: deepspeed, llamafactory, fire, autoawq, metrics, jieba\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheel for deepspeed (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheel for deepspeed (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Created wheel for deepspeed: filename=deepspeed-0.15.1-py3-none-any.whl size=1483866 sha256=4f7e9401ddca7a20f80b8f2607a2eaab89b51c003177e40cf0843e23283e3070\n",
      "f4qy70hcyr-algo-1-une3w  | Stored in directory: /root/.cache/pip/wheels/6e/77/1f/c1727c979b4d8a9d0c78c23ab0f996e779b24e36c4fcfe93b3\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheel for llamafactory (pyproject.toml): started\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheel for llamafactory (pyproject.toml): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Created wheel for llamafactory: filename=llamafactory-0.9.1.dev0-py3-none-any.whl size=249382 sha256=3c7b601632d569676eb0b250abfe1c95019e9b0817668d6d1131871797510bc4\n",
      "f4qy70hcyr-algo-1-une3w  | Stored in directory: /tmp/pip-ephem-wheel-cache-bhozu0y6/wheels/97/37/90/3cc13bb9f26c0af43ccd729b88b6cb4cc3f450b4bccc2e847a\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheel for fire (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheel for fire (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=0e197f5b8602edc8c3a4e22b41bb69e4edc0e5a1be2a9bff8013ebbc326bc86c\n",
      "f4qy70hcyr-algo-1-une3w  | Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheel for autoawq (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheel for autoawq (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Created wheel for autoawq: filename=autoawq-0.2.6+cu121-py3-none-any.whl size=100486 sha256=294d013440b166afcd0e4ba1c6663bab205ec34135b6306104664e2f0ae05841\n",
      "f4qy70hcyr-algo-1-une3w  | Stored in directory: /tmp/pip-ephem-wheel-cache-bhozu0y6/wheels/6b/65/d4/e4f5244a8c915c5ee2554df3f5eddcb280b242fc50b01b89e1\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheel for metrics (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheel for metrics (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Created wheel for metrics: filename=metrics-0.2.6-py3-none-any.whl size=12795 sha256=8778180565149c435aba26b7a4b727d6648d34ddd1388d6c950d9987696fbe2e\n",
      "f4qy70hcyr-algo-1-une3w  | Stored in directory: /root/.cache/pip/wheels/1a/a0/fa/3b2647b0379c5972dffbfc900c9357feb6a72e48102ddd4034\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheel for jieba (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheel for jieba (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=c048042706ff8969c8ec20cac9ff0b3c902e70ace969e18734887cdb42611811\n",
      "f4qy70hcyr-algo-1-une3w  | Stored in directory: /root/.cache/pip/wheels/ac/60/cf/538a1f183409caf1fc136b5d2c2dee329001ef6da2c5084bef\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully built deepspeed llamafactory fire autoawq metrics jieba\n",
      "f4qy70hcyr-algo-1-une3w  | Installing collected packages: sentencepiece, pydub, pyairports, py-cpuinfo, nvidia-ml-py, jieba, hjson, xxhash, websockets, uvloop, urllib3, triton, tomlkit, termcolor, sniffio, smmap, shtab, setproctitle, semantic-version, ruff, rouge-chinese, regex, python-multipart, python-dotenv, pydantic-core, pycountry, propcache, prometheus-client, partial-json-parser, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multidict, msgspec, msgpack, metrics, lark, jiter, interegular, importlib-resources, httptools, h11, gguf, frozenlist, ffmpy, docstring-parser, docker-pycreds, diskcache, av, aiohappyeyeballs, aiofiles, yarl, uvicorn, sentry-sdk, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nltk, httpcore, gitdb, fire, anyio, aiosignal, watchfiles, tyro, typer, tiktoken, starlette, nvidia-cusolver-cu12, modelscope, lm-format-enforcer, huggingface-hub, httpx, gitpython, aiohttp, wandb, torch, tokenizers, sse-starlette, ray, prometheus-fastapi-instrumentator, openai, mistral-common, gradio-client, fastapi, xformers, vllm-flash-attn, transformers, torchvision, gradio, deepspeed, datasets, bitsandbytes, accelerate, trl, peft, outlines, autoawq, vllm, llamafactory\n",
      "f4qy70hcyr-algo-1-une3w  | Attempting uninstall: urllib3\n",
      "f4qy70hcyr-algo-1-une3w  | Found existing installation: urllib3 1.26.20\n",
      "f4qy70hcyr-algo-1-une3w  | Uninstalling urllib3-1.26.20:\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully uninstalled urllib3-1.26.20\n",
      "f4qy70hcyr-algo-1-une3w  | Attempting uninstall: triton\n",
      "f4qy70hcyr-algo-1-une3w  | Found existing installation: triton 2.3.0\n",
      "f4qy70hcyr-algo-1-une3w  | Uninstalling triton-2.3.0:\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully uninstalled triton-2.3.0\n",
      "f4qy70hcyr-algo-1-une3w  | Attempting uninstall: pydantic-core\n",
      "f4qy70hcyr-algo-1-une3w  | Found existing installation: pydantic_core 2.18.2\n",
      "f4qy70hcyr-algo-1-une3w  | Uninstalling pydantic_core-2.18.2:\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully uninstalled pydantic_core-2.18.2\n",
      "f4qy70hcyr-algo-1-une3w  | Attempting uninstall: pydantic\n",
      "f4qy70hcyr-algo-1-une3w  | Found existing installation: pydantic 2.7.1\n",
      "f4qy70hcyr-algo-1-une3w  | Uninstalling pydantic-2.7.1:\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully uninstalled pydantic-2.7.1\n",
      "f4qy70hcyr-algo-1-une3w  | Attempting uninstall: typer\n",
      "f4qy70hcyr-algo-1-une3w  | Found existing installation: typer 0.9.4\n",
      "f4qy70hcyr-algo-1-une3w  | Uninstalling typer-0.9.4:\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully uninstalled typer-0.9.4\n",
      "f4qy70hcyr-algo-1-une3w  | Attempting uninstall: huggingface-hub\n",
      "f4qy70hcyr-algo-1-une3w  | Found existing installation: huggingface_hub 0.23.0\n",
      "f4qy70hcyr-algo-1-une3w  | Uninstalling huggingface_hub-0.23.0:\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully uninstalled huggingface_hub-0.23.0\n",
      "f4qy70hcyr-algo-1-une3w  | Attempting uninstall: torch\n",
      "f4qy70hcyr-algo-1-une3w  | Found existing installation: torch 2.3.0\n",
      "f4qy70hcyr-algo-1-une3w  | Uninstalling torch-2.3.0:\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully uninstalled torch-2.3.0\n",
      "f4qy70hcyr-algo-1-une3w  | Attempting uninstall: torchvision\n",
      "f4qy70hcyr-algo-1-une3w  | Found existing installation: torchvision 0.18.0\n",
      "f4qy70hcyr-algo-1-une3w  | Uninstalling torchvision-0.18.0:\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully uninstalled torchvision-0.18.0\n",
      "f4qy70hcyr-algo-1-une3w  | Attempting uninstall: accelerate\n",
      "f4qy70hcyr-algo-1-une3w  | Found existing installation: accelerate 0.30.1\n",
      "f4qy70hcyr-algo-1-une3w  | Uninstalling accelerate-0.30.1:\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully uninstalled accelerate-0.30.1\n",
      "f4qy70hcyr-algo-1-une3w  | ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "f4qy70hcyr-algo-1-une3w  | spacy 3.7.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.5 which is incompatible.\n",
      "f4qy70hcyr-algo-1-une3w  | fastai 2.7.15 requires torch<2.4,>=1.10, but you have torch 2.4.0 which is incompatible.\n",
      "f4qy70hcyr-algo-1-une3w  | weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.5 which is incompatible.\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully installed accelerate-0.34.2 aiofiles-23.2.1 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 anyio-4.6.2.post1 autoawq-0.2.6+cu121 av-13.1.0 bitsandbytes-0.44.1 datasets-2.21.0 deepspeed-0.15.1 diskcache-5.6.3 docker-pycreds-0.4.0 docstring-parser-0.16 fastapi-0.115.4 ffmpy-0.4.0 fire-0.7.0 frozenlist-1.5.0 gguf-0.9.1 gitdb-4.0.11 gitpython-3.1.43 gradio-4.44.1 gradio-client-1.3.0 h11-0.14.0 hjson-3.1.0 httpcore-1.0.6 httptools-0.6.4 httpx-0.27.2 huggingface-hub-0.26.2 importlib-resources-6.4.5 interegular-0.3.3 jieba-0.42.1 jiter-0.7.0 lark-1.2.2 llamafactory-0.9.1.dev0 lm-format-enforcer-0.10.6 metrics-0.2.6 mistral-common-1.4.4 modelscope-1.19.2 msgpack-1.1.0 msgspec-0.18.6 multidict-6.1.0 nltk-3.9.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py-12.560.30 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 openai-1.53.0 orjson-3.10.11 outlines-0.0.46 partial-json-parser-0.2.1.1.post4 peft-0.12.0 prometheus-client-0.21.0 prometheus-fastapi-instrumentator-7.0.0 propcache-0.2.0 py-cpuinfo-9.0.0 pyairports-2.1.1 pycountry-24.6.1 pydantic-2.9.2 pydantic-core-2.23.4 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.17 ray-2.38.0 regex-2024.9.11 rouge-chinese-1.0.3 ruff-0.7.2 semantic-version-2.10.0 sentencepiece-0.2.0 sentry-sdk-2.17.0 setproctitle-1.3.3 shtab-1.7.1 smmap-5.0.1 sniffio-1.3.1 sse-starlette-2.1.3 starlette-0.41.2 termcolor-2.5.0 tiktoken-0.7.0 tokenizers-0.20.1 tomlkit-0.12.0 torch-2.4.0 torchvision-0.19.0 transformers-4.45.2 triton-3.0.0 trl-0.9.6 typer-0.12.5 tyro-0.8.14 urllib3-2.2.3 uvicorn-0.32.0 uvloop-0.21.0 vllm-0.6.0 vllm-flash-attn-2.6.1 wandb-0.18.5 watchfiles-0.24.0 websockets-12.0 xformers-0.0.27.post2 xxhash-3.5.0 yarl-1.17.1\n",
      "f4qy70hcyr-algo-1-une3w  | WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "f4qy70hcyr-algo-1-une3w  | [notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "f4qy70hcyr-algo-1-une3w  | [notice] To update, run: pip install --upgrade pip\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:29:40,394 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:29:40,394 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:29:40,438 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:29:40,445 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:29:40,472 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:29:40,479 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:29:40,505 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:29:40,512 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:29:40,516 sagemaker-training-toolkit INFO     Invoking user script\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Training Env:\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | {\n",
      "f4qy70hcyr-algo-1-une3w  |     \"additional_framework_parameters\": {},\n",
      "f4qy70hcyr-algo-1-une3w  |     \"channel_input_dirs\": {},\n",
      "f4qy70hcyr-algo-1-une3w  |     \"current_host\": \"algo-1-une3w\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"current_instance_group\": \"homogeneousCluster\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"current_instance_group_hosts\": [],\n",
      "f4qy70hcyr-algo-1-une3w  |     \"current_instance_type\": \"local\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"distribution_hosts\": [\n",
      "f4qy70hcyr-algo-1-une3w  |         \"algo-1-une3w\"\n",
      "f4qy70hcyr-algo-1-une3w  |     ],\n",
      "f4qy70hcyr-algo-1-une3w  |     \"distribution_instance_groups\": [],\n",
      "f4qy70hcyr-algo-1-une3w  |     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"hosts\": [\n",
      "f4qy70hcyr-algo-1-une3w  |         \"algo-1-une3w\"\n",
      "f4qy70hcyr-algo-1-une3w  |     ],\n",
      "f4qy70hcyr-algo-1-une3w  |     \"hyperparameters\": {},\n",
      "f4qy70hcyr-algo-1-une3w  |     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"input_data_config\": {},\n",
      "f4qy70hcyr-algo-1-une3w  |     \"input_dir\": \"/opt/ml/input\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"instance_groups\": [],\n",
      "f4qy70hcyr-algo-1-une3w  |     \"instance_groups_dict\": {},\n",
      "f4qy70hcyr-algo-1-une3w  |     \"is_hetero\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"is_master\": true,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"is_modelparallel_enabled\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"is_smddpmprun_installed\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"is_smddprun_installed\": true,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"job_name\": \"llama3-8b-qlora-finetune-2024-11-02-11-26-59-557\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"log_level\": 20,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"master_hostname\": \"algo-1-une3w\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"model_dir\": \"/opt/ml/model\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"module_dir\": \"s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora-finetune-2024-11-02-11-26-59-557/source/sourcedir.tar.gz\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"module_name\": \"entry_single_lora\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"network_interface_name\": \"eth0\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"num_cpus\": 16,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"num_gpus\": 1,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"num_neurons\": 0,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"output_dir\": \"/opt/ml/output\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"resource_config\": {\n",
      "f4qy70hcyr-algo-1-une3w  |         \"current_host\": \"algo-1-une3w\",\n",
      "f4qy70hcyr-algo-1-une3w  |         \"hosts\": [\n",
      "f4qy70hcyr-algo-1-une3w  |             \"algo-1-une3w\"\n",
      "f4qy70hcyr-algo-1-une3w  |         ]\n",
      "f4qy70hcyr-algo-1-une3w  |     },\n",
      "f4qy70hcyr-algo-1-une3w  |     \"user_entry_point\": \"entry_single_lora.py\"\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Environment variables:\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | SM_HOSTS=[\"algo-1-une3w\"]\n",
      "f4qy70hcyr-algo-1-une3w  | SM_NETWORK_INTERFACE_NAME=eth0\n",
      "f4qy70hcyr-algo-1-une3w  | SM_HPS={}\n",
      "f4qy70hcyr-algo-1-une3w  | SM_USER_ENTRY_POINT=entry_single_lora.py\n",
      "f4qy70hcyr-algo-1-une3w  | SM_FRAMEWORK_PARAMS={}\n",
      "f4qy70hcyr-algo-1-une3w  | SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-une3w\",\"hosts\":[\"algo-1-une3w\"]}\n",
      "f4qy70hcyr-algo-1-une3w  | SM_INPUT_DATA_CONFIG={}\n",
      "f4qy70hcyr-algo-1-une3w  | SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "f4qy70hcyr-algo-1-une3w  | SM_CHANNELS=[]\n",
      "f4qy70hcyr-algo-1-une3w  | SM_CURRENT_HOST=algo-1-une3w\n",
      "f4qy70hcyr-algo-1-une3w  | SM_CURRENT_INSTANCE_TYPE=local\n",
      "f4qy70hcyr-algo-1-une3w  | SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "f4qy70hcyr-algo-1-une3w  | SM_CURRENT_INSTANCE_GROUP_HOSTS=[]\n",
      "f4qy70hcyr-algo-1-une3w  | SM_INSTANCE_GROUPS=[]\n",
      "f4qy70hcyr-algo-1-une3w  | SM_INSTANCE_GROUPS_DICT={}\n",
      "f4qy70hcyr-algo-1-une3w  | SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "f4qy70hcyr-algo-1-une3w  | SM_IS_HETERO=false\n",
      "f4qy70hcyr-algo-1-une3w  | SM_MODULE_NAME=entry_single_lora\n",
      "f4qy70hcyr-algo-1-une3w  | SM_LOG_LEVEL=20\n",
      "f4qy70hcyr-algo-1-une3w  | SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "f4qy70hcyr-algo-1-une3w  | SM_INPUT_DIR=/opt/ml/input\n",
      "f4qy70hcyr-algo-1-une3w  | SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "f4qy70hcyr-algo-1-une3w  | SM_OUTPUT_DIR=/opt/ml/output\n",
      "f4qy70hcyr-algo-1-une3w  | SM_NUM_CPUS=16\n",
      "f4qy70hcyr-algo-1-une3w  | SM_NUM_GPUS=1\n",
      "f4qy70hcyr-algo-1-une3w  | SM_NUM_NEURONS=0\n",
      "f4qy70hcyr-algo-1-une3w  | SM_MODEL_DIR=/opt/ml/model\n",
      "f4qy70hcyr-algo-1-une3w  | SM_MODULE_DIR=s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora-finetune-2024-11-02-11-26-59-557/source/sourcedir.tar.gz\n",
      "f4qy70hcyr-algo-1-une3w  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-une3w\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[],\"current_instance_type\":\"local\",\"distribution_hosts\":[\"algo-1-une3w\"],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-une3w\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[],\"instance_groups_dict\":{},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"llama3-8b-qlora-finetune-2024-11-02-11-26-59-557\",\"log_level\":20,\"master_hostname\":\"algo-1-une3w\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora-finetune-2024-11-02-11-26-59-557/source/sourcedir.tar.gz\",\"module_name\":\"entry_single_lora\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-une3w\",\"hosts\":[\"algo-1-une3w\"]},\"user_entry_point\":\"entry_single_lora.py\"}\n",
      "f4qy70hcyr-algo-1-une3w  | SM_USER_ARGS=[]\n",
      "f4qy70hcyr-algo-1-une3w  | SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "f4qy70hcyr-algo-1-une3w  | PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Invoking script with the following command:\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | /opt/conda/bin/python3.11 -m entry_single_lora\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:29:40,518 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:29:40,518 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "f4qy70hcyr-algo-1-une3w  | Obtaining file:///opt/ml/code\n",
      "f4qy70hcyr-algo-1-une3w  | Installing build dependencies: started\n",
      "f4qy70hcyr-algo-1-une3w  | Installing build dependencies: finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Checking if build backend supports build_editable: started\n",
      "f4qy70hcyr-algo-1-une3w  | Checking if build backend supports build_editable: finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Getting requirements to build editable: started\n",
      "f4qy70hcyr-algo-1-une3w  | Getting requirements to build editable: finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing editable metadata (pyproject.toml): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheels for collected packages: llamafactory\n",
      "f4qy70hcyr-algo-1-une3w  | Building editable for llamafactory (pyproject.toml): started\n",
      "f4qy70hcyr-algo-1-une3w  | Building editable for llamafactory (pyproject.toml): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Created wheel for llamafactory: filename=llamafactory-0.9.1.dev0-0.editable-py3-none-any.whl size=22717 sha256=bd3ee18ec192e956a3854d0413ceb5f6f0ca0223933277ccadfb925ffa23efeb\n",
      "f4qy70hcyr-algo-1-une3w  | Stored in directory: /tmp/pip-ephem-wheel-cache-hojyuzbh/wheels/97/37/90/3cc13bb9f26c0af43ccd729b88b6cb4cc3f450b4bccc2e847a\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully built llamafactory\n",
      "f4qy70hcyr-algo-1-une3w  | Installing collected packages: llamafactory\n",
      "f4qy70hcyr-algo-1-une3w  | Attempting uninstall: llamafactory\n",
      "f4qy70hcyr-algo-1-une3w  | Found existing installation: llamafactory 0.9.1.dev0\n",
      "f4qy70hcyr-algo-1-une3w  | Uninstalling llamafactory-0.9.1.dev0:\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully uninstalled llamafactory-0.9.1.dev0\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully installed llamafactory-0.9.1.dev0\n",
      "f4qy70hcyr-algo-1-une3w  | WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "f4qy70hcyr-algo-1-une3w  | [notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "f4qy70hcyr-algo-1-une3w  | [notice] To update, run: pip install --upgrade pip\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting autoawq@ git+https://github.com/casper-hansen/AutoAWQ.git (from -r requirements.txt (line 22))\n",
      "f4qy70hcyr-algo-1-une3w  | Cloning https://github.com/casper-hansen/AutoAWQ.git to /tmp/pip-install-f8lzezvl/autoawq_1fed3088508142538742a077268e3555\n",
      "f4qy70hcyr-algo-1-une3w  | Running command git clone --filter=blob:none --quiet https://github.com/casper-hansen/AutoAWQ.git /tmp/pip-install-f8lzezvl/autoawq_1fed3088508142538742a077268e3555\n",
      "f4qy70hcyr-algo-1-une3w  | Resolved https://github.com/casper-hansen/AutoAWQ.git to commit 79547665bdb27768a9b392ef375776b020acbf0c\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: transformers<=4.45.2,>=4.41.2 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (4.45.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: datasets<=2.21.0,>=2.16.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.21.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: accelerate<=0.34.2,>=0.34.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.34.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: peft<=0.12.0,>=0.11.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.12.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.9.6)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: gradio<5.0.0,>=4.0.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (4.44.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pandas>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (2.2.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.13.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (0.8.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.2.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: tiktoken in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (0.7.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (3.20.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: uvicorn in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (0.32.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pydantic in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (2.9.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: fastapi in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (0.115.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: sse-starlette in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (2.1.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: matplotlib>=3.7.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (3.8.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: fire in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (0.7.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (23.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (6.0.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: deepspeed==0.15.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 21)) (0.15.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: metrics in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (0.2.6)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: bitsandbytes>=0.39.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 24)) (0.44.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: rouge-chinese in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 25)) (1.0.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: jieba in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 26)) (0.42.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: modelscope in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 28)) (1.19.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: wandb in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 29)) (0.18.5)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: vllm==0.6.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 30)) (0.6.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 31)) (3.9.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 33)) (1.26.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: av in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 34)) (13.1.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: hjson in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.1->-r requirements.txt (line 21)) (3.1.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: ninja in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.1->-r requirements.txt (line 21)) (1.11.1.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.1->-r requirements.txt (line 21)) (5.9.8)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.1->-r requirements.txt (line 21)) (9.0.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.1->-r requirements.txt (line 21)) (2.4.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.1->-r requirements.txt (line 21)) (4.66.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-ml-py in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.1->-r requirements.txt (line 21)) (12.560.30)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (2.32.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: tokenizers>=0.19.1 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (0.20.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (3.10.10)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: openai>=1.0 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (1.53.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (10.3.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: prometheus-client>=0.18.0 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (0.21.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (7.0.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: lm-format-enforcer==0.10.6 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (0.10.6)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: outlines<0.1,>=0.0.43 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (0.0.46)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: typing-extensions>=4.10 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (4.11.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: filelock>=3.10.4 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (3.14.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: partial-json-parser in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (0.2.1.1.post4)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pyzmq in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (26.0.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: msgspec in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (0.18.6)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: gguf==0.9.1 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (0.9.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (6.11.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: mistral-common>=1.3.4 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (1.4.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: ray>=2.9 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (2.38.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: torchvision==0.19 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (0.19.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: xformers==0.0.27.post2 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (0.0.27.post2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: vllm-flash-attn==2.6.1 in /opt/conda/lib/python3.11/site-packages (from vllm==0.6.0->-r requirements.txt (line 30)) (2.6.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: interegular>=0.3.2 in /opt/conda/lib/python3.11/site-packages (from lm-format-enforcer==0.10.6->vllm==0.6.0->-r requirements.txt (line 30)) (0.3.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (1.12)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (3.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (3.1.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (2024.5.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (12.1.105)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (12.1.105)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (12.1.105)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (9.1.0.70)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (12.1.3.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (11.0.2.54)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (10.3.2.106)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (11.4.5.107)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (12.1.0.106)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (2.20.5)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (12.1.105)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.11/site-packages (from torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (3.0.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (12.6.77)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers<=4.45.2,>=4.41.2->-r requirements.txt (line 1)) (0.26.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<=4.45.2,>=4.41.2->-r requirements.txt (line 1)) (2024.9.11)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers<=4.45.2,>=4.41.2->-r requirements.txt (line 1)) (0.4.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (16.1.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (0.3.8)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (3.5.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (0.70.16)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.11/site-packages (from trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5)) (0.8.14)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (23.2.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (4.6.2.post1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: ffmpy in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (0.4.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: gradio-client==1.3.0 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (1.3.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (0.27.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (6.4.5)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (2.1.5)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (3.10.11)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pydub in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (0.25.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (0.0.17)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: ruff>=0.2.2 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (0.7.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: semantic-version~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (2.10.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: tomlkit==0.12.0 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (0.12.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (0.12.5)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: urllib3~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (2.2.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: websockets<13.0,>=10.0 in /opt/conda/lib/python3.11/site-packages (from gradio-client==1.3.0->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (12.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2.9.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2024.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2024.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn->-r requirements.txt (line 13)) (8.1.7)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.11/site-packages (from uvicorn->-r requirements.txt (line 13)) (0.14.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic->-r requirements.txt (line 14)) (0.7.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.11/site-packages (from pydantic->-r requirements.txt (line 14)) (2.23.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /opt/conda/lib/python3.11/site-packages (from fastapi->-r requirements.txt (line 15)) (0.41.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.2.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (0.12.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (4.52.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.4.5)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (3.1.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: termcolor in /opt/conda/lib/python3.11/site-packages (from fire->-r requirements.txt (line 18)) (2.5.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: zstandard in /opt/conda/lib/python3.11/site-packages (from autoawq@ git+https://github.com/casper-hansen/AutoAWQ.git->-r requirements.txt (line 22)) (0.19.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: Pygments>=0.8 in /opt/conda/lib/python3.11/site-packages (from metrics->-r requirements.txt (line 23)) (2.18.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from rouge-chinese->-r requirements.txt (line 25)) (1.16.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 29)) (0.4.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 29)) (3.1.43)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 29)) (4.1.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 29)) (2.17.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: setproctitle in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 29)) (1.3.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 29)) (75.2.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk->-r requirements.txt (line 31)) (1.4.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (3.7)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (1.3.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->vllm==0.6.0->-r requirements.txt (line 30)) (2.4.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->vllm==0.6.0->-r requirements.txt (line 30)) (1.3.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->vllm==0.6.0->-r requirements.txt (line 30)) (23.2.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->vllm==0.6.0->-r requirements.txt (line 30)) (1.5.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->vllm==0.6.0->-r requirements.txt (line 30)) (6.1.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->vllm==0.6.0->-r requirements.txt (line 30)) (1.17.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 29)) (4.0.11)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx>=0.24.1->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (2024.8.30)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx>=0.24.1->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (1.0.6)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: jsonschema<5.0.0,>=4.21.1 in /opt/conda/lib/python3.11/site-packages (from mistral-common>=1.3.4->vllm==0.6.0->-r requirements.txt (line 30)) (4.22.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai>=1.0->vllm==0.6.0->-r requirements.txt (line 30)) (1.8.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from openai>=1.0->vllm==0.6.0->-r requirements.txt (line 30)) (0.7.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: lark in /opt/conda/lib/python3.11/site-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30)) (1.2.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30)) (1.6.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.11/site-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30)) (2.2.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: diskcache in /opt/conda/lib/python3.11/site-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30)) (5.6.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30)) (0.59.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: referencing in /opt/conda/lib/python3.11/site-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30)) (0.35.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pycountry in /opt/conda/lib/python3.11/site-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30)) (24.6.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: pyairports in /opt/conda/lib/python3.11/site-packages (from outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30)) (2.1.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from ray>=2.9->vllm==0.6.0->-r requirements.txt (line 30)) (1.1.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->vllm==0.6.0->-r requirements.txt (line 30)) (3.3.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (1.5.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (13.7.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.11/site-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5)) (0.16)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.11/site-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5)) (1.7.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata->vllm==0.6.0->-r requirements.txt (line 30)) (3.20.2)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn[standard]->vllm==0.6.0->-r requirements.txt (line 30)) (0.6.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.11/site-packages (from uvicorn[standard]->vllm==0.6.0->-r requirements.txt (line 30)) (1.0.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn[standard]->vllm==0.6.0->-r requirements.txt (line 30)) (0.21.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.11/site-packages (from uvicorn[standard]->vllm==0.6.0->-r requirements.txt (line 30)) (0.24.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 29)) (5.0.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.3.4->vllm==0.6.0->-r requirements.txt (line 30)) (2023.12.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.3.4->vllm==0.6.0->-r requirements.txt (line 30)) (0.18.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (3.0.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp->vllm==0.6.0->-r requirements.txt (line 30)) (0.2.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->outlines<0.1,>=0.0.43->vllm==0.6.0->-r requirements.txt (line 30)) (0.42.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->deepspeed==0.15.1->-r requirements.txt (line 21)) (1.3.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->-r requirements.txt (line 6)) (0.1.2)\n",
      "f4qy70hcyr-algo-1-une3w  | WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "f4qy70hcyr-algo-1-une3w  | [notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "f4qy70hcyr-algo-1-une3w  | [notice] To update, run: pip install --upgrade pip\n",
      "f4qy70hcyr-algo-1-une3w  | Collecting flash_attn==2.6.3\n",
      "f4qy70hcyr-algo-1-une3w  | Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n",
      "f4qy70hcyr-algo-1-une3w  | ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.6/2.6 MB 75.1 MB/s eta 0:00:00\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Preparing metadata (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from flash_attn==2.6.3) (2.4.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from flash_attn==2.6.3) (0.8.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (3.14.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (4.11.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (1.12)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (3.3)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (3.1.4)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (2024.5.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (12.1.105)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (12.1.105)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (12.1.105)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (9.1.0.70)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (12.1.3.1)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (11.0.2.54)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (10.3.2.106)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (11.4.5.107)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (12.1.0.106)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (2.20.5)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (12.1.105)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn==2.6.3) (3.0.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash_attn==2.6.3) (12.6.77)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->flash_attn==2.6.3) (2.1.5)\n",
      "f4qy70hcyr-algo-1-une3w  | Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->flash_attn==2.6.3) (1.3.0)\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheels for collected packages: flash_attn\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheel for flash_attn (setup.py): started\n",
      "f4qy70hcyr-algo-1-une3w  | Building wheel for flash_attn (setup.py): finished with status 'done'\n",
      "f4qy70hcyr-algo-1-une3w  | Created wheel for flash_attn: filename=flash_attn-2.6.3-cp311-cp311-linux_x86_64.whl size=187328293 sha256=25405479af3f6865c873ee3bbdfadcfccea9055355de78e7cd6b93170e9d4377\n",
      "f4qy70hcyr-algo-1-une3w  | Stored in directory: /root/.cache/pip/wheels/e3/ef/b1/7889928ffa2dea61032e61480db4e4c20d00a9d9e28cd4f55a\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully built flash_attn\n",
      "f4qy70hcyr-algo-1-une3w  | Installing collected packages: flash_attn\n",
      "f4qy70hcyr-algo-1-une3w  | Attempting uninstall: flash_attn\n",
      "f4qy70hcyr-algo-1-une3w  | Found existing installation: flash-attn 2.0.4\n",
      "f4qy70hcyr-algo-1-une3w  | Uninstalling flash-attn-2.0.4:\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully uninstalled flash-attn-2.0.4\n",
      "f4qy70hcyr-algo-1-une3w  | ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "f4qy70hcyr-algo-1-une3w  | transformer-engine 0.12.0+170797 requires flash-attn<=2.0.4,>=1.0.6, but you have flash-attn 2.6.3 which is incompatible.\n",
      "f4qy70hcyr-algo-1-une3w  | Successfully installed flash_attn-2.6.3\n",
      "f4qy70hcyr-algo-1-une3w  | WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "f4qy70hcyr-algo-1-une3w  | [notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "f4qy70hcyr-algo-1-une3w  | [notice] To update, run: pip install --upgrade pip\n",
      "f4qy70hcyr-algo-1-une3w  | CITATION.cff\n",
      "f4qy70hcyr-algo-1-une3w  | LICENSE\n",
      "f4qy70hcyr-algo-1-une3w  | MANIFEST.in\n",
      "f4qy70hcyr-algo-1-une3w  | Makefile\n",
      "f4qy70hcyr-algo-1-une3w  | README.md\n",
      "f4qy70hcyr-algo-1-une3w  | README_zh.md\n",
      "f4qy70hcyr-algo-1-une3w  | assets\n",
      "f4qy70hcyr-algo-1-une3w  | build\n",
      "f4qy70hcyr-algo-1-une3w  | data\n",
      "f4qy70hcyr-algo-1-une3w  | docker\n",
      "f4qy70hcyr-algo-1-une3w  | entry-multi-nodes.py\n",
      "f4qy70hcyr-algo-1-une3w  | entry_single_lora.py\n",
      "f4qy70hcyr-algo-1-une3w  | evaluation\n",
      "f4qy70hcyr-algo-1-une3w  | examples\n",
      "f4qy70hcyr-algo-1-une3w  | pyproject.toml\n",
      "f4qy70hcyr-algo-1-une3w  | requirements.txt\n",
      "f4qy70hcyr-algo-1-une3w  | s5cmd\n",
      "f4qy70hcyr-algo-1-une3w  | scripts\n",
      "f4qy70hcyr-algo-1-une3w  | setup.py\n",
      "f4qy70hcyr-algo-1-une3w  | sg_config_qlora.yaml\n",
      "f4qy70hcyr-algo-1-une3w  | src\n",
      "f4qy70hcyr-algo-1-une3w  | tests\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/dataset_info.json /opt/ml/code/data/multl-modal-data/dataset_info.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1575697898005393409.jpg /opt/ml/code/data/multl-modal-data/images/instance_1575697898005393409.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1575684349891768322.jpg /opt/ml/code/data/multl-modal-data/images/instance_1575684349891768322.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1575754532383682562.jpg /opt/ml/code/data/multl-modal-data/images/instance_1575754532383682562.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1603659751587115010.jpg /opt/ml/code/data/multl-modal-data/images/instance_1603659751587115010.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/identity_2.json /opt/ml/code/data/identity_2.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1575684349858213889.jpg /opt/ml/code/data/multl-modal-data/images/instance_1575684349858213889.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1575697898059919365.jpg /opt/ml/code/data/multl-modal-data/images/instance_1575697898059919365.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579408762898280451.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579408762898280451.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1575684349887574018.jpg /opt/ml/code/data/multl-modal-data/images/instance_1575684349887574018.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1575754532417236996.jpg /opt/ml/code/data/multl-modal-data/images/instance_1575754532417236996.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579376275388166145.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579376275388166145.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579398113556230146.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579398113556230146.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1575697898022170627.jpg /opt/ml/code/data/multl-modal-data/images/instance_1575697898022170627.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1575684349870796803.jpg /opt/ml/code/data/multl-modal-data/images/instance_1575684349870796803.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579376278118658052.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579376278118658052.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1552218853139910657.jpg /opt/ml/code/data/multl-modal-data/images/instance_1552218853139910657.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1552220458182610945.jpg /opt/ml/code/data/multl-modal-data/images/instance_1552220458182610945.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1541679966589616129.jpg /opt/ml/code/data/multl-modal-data/images/instance_1541679966589616129.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579408762881503233.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579408762881503233.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579398113589784583.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579398113589784583.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712305779123552258.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712305779123552258.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1586286817218457602.jpg /opt/ml/code/data/multl-modal-data/images/instance_1586286817218457602.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1603662164888973314.jpg /opt/ml/code/data/multl-modal-data/images/instance_1603662164888973314.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579388661318873090.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579388661318873090.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1603662836053110786.jpg /opt/ml/code/data/multl-modal-data/images/instance_1603662836053110786.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579398113589784578.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579398113589784578.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712360200394113025.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712360200394113025.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1589506784390868993.jpg /opt/ml/code/data/multl-modal-data/images/instance_1589506784390868993.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712390636436103170.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712390636436103170.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579398113581395972.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579398113581395972.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712356537546436609.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712356537546436609.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579388661327261697.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579388661327261697.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579376278198349827.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579376278198349827.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/huanhuan.json /opt/ml/code/data/multl-modal-data/huanhuan.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1598551736093569026.jpg /opt/ml/code/data/multl-modal-data/images/instance_1598551736093569026.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712369377371398146.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712369377371398146.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/huanhuan.json /opt/ml/code/data/huanhuan.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579376278252875778.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579376278252875778.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712303696378503170.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712303696378503170.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579388661302095873.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579388661302095873.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1594942441246486530.jpg /opt/ml/code/data/multl-modal-data/images/instance_1594942441246486530.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1605474594426253313.jpg /opt/ml/code/data/multl-modal-data/images/instance_1605474594426253313.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1609824244960653314.jpg /opt/ml/code/data/multl-modal-data/images/instance_1609824244960653314.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712304288266584066.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712304288266584066.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712310957381910530.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712310957381910530.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712408837058772993.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712408837058772993.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1588110120253976578.jpg /opt/ml/code/data/multl-modal-data/images/instance_1588110120253976578.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1588114992445583361.jpg /opt/ml/code/data/multl-modal-data/images/instance_1588114992445583361.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1586990758474346497.jpg /opt/ml/code/data/multl-modal-data/images/instance_1586990758474346497.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712353819591049217.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712353819591049217.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1642025622293786626.jpg /opt/ml/code/data/multl-modal-data/images/instance_1642025622293786626.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1645237409419964418.jpg /opt/ml/code/data/multl-modal-data/images/instance_1645237409419964418.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1583755072329805825.jpg /opt/ml/code/data/multl-modal-data/images/instance_1583755072329805825.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1584816943107469314.jpg /opt/ml/code/data/multl-modal-data/images/instance_1584816943107469314.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712362888703901698.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712362888703901698.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1588114119933882370.jpg /opt/ml/code/data/multl-modal-data/images/instance_1588114119933882370.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1585151302117158913.jpg /opt/ml/code/data/multl-modal-data/images/instance_1585151302117158913.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1598221987395727362.jpg /opt/ml/code/data/multl-modal-data/images/instance_1598221987395727362.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1605861397096361985.jpg /opt/ml/code/data/multl-modal-data/images/instance_1605861397096361985.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712436279368429570.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712436279368429570.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1609831567124918274.jpg /opt/ml/code/data/multl-modal-data/images/instance_1609831567124918274.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579408762873114627.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579408762873114627.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1609831285456433153.jpg /opt/ml/code/data/multl-modal-data/images/instance_1609831285456433153.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1605406510357213186.jpg /opt/ml/code/data/multl-modal-data/images/instance_1605406510357213186.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1605453554706870273.jpg /opt/ml/code/data/multl-modal-data/images/instance_1605453554706870273.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1609717271372034050.jpg /opt/ml/code/data/multl-modal-data/images/instance_1609717271372034050.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/train_1.json /opt/ml/code/data/multl-modal-data/train_1.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1585212135388016642.jpg /opt/ml/code/data/multl-modal-data/images/instance_1585212135388016642.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1583752643131535361.jpg /opt/ml/code/data/multl-modal-data/images/instance_1583752643131535361.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1585181488808259586.jpg /opt/ml/code/data/multl-modal-data/images/instance_1585181488808259586.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712410705440849922.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712410705440849922.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712366770942812161.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712366770942812161.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712437520343293954.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712437520343293954.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1605474945132982273.jpg /opt/ml/code/data/multl-modal-data/images/instance_1605474945132982273.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712368925837795330.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712368925837795330.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1588116956264853505.jpg /opt/ml/code/data/multl-modal-data/images/instance_1588116956264853505.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1575005049068777475.jpg /opt/ml/code/data/multl-modal-data/images/instance_1575005049068777475.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1641394053371736065.jpg /opt/ml/code/data/multl-modal-data/images/instance_1641394053371736065.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1638131855224549378.jpg /opt/ml/code/data/multl-modal-data/images/instance_1638131855224549378.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/train.json /opt/ml/code/data/multl-modal-data/train.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712411007734722562.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712411007734722562.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712438235273048066.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712438235273048066.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1634147576819822594.jpg /opt/ml/code/data/multl-modal-data/images/instance_1634147576819822594.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712368307161919490.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712368307161919490.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1638129274825814017.jpg /opt/ml/code/data/multl-modal-data/images/instance_1638129274825814017.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1579398113560424451.jpg /opt/ml/code/data/multl-modal-data/images/instance_1579398113560424451.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712415517955645441.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712415517955645441.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1594943407861592066.jpg /opt/ml/code/data/multl-modal-data/images/instance_1594943407861592066.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1792820301478404098.jpg /opt/ml/code/data/multl-modal-data/images/instance_1792820301478404098.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/multl-modal-data/images/instance_1712355420103901186.jpg /opt/ml/code/data/multl-modal-data/images/instance_1712355420103901186.jpg\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/ruozhiba.json /opt/ml/code/data/ruozhiba.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/anta-voc-data-0002-train.json /opt/ml/code/data/anta-voc-data-0002-train.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/train-openai.json /opt/ml/code/data/train-openai.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/README.md /tmp/model_path/README.md\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/generation_config.json /tmp/model_path/generation_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/.gitattributes /tmp/model_path/.gitattributes\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/config.json /tmp/model_path/config.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/special_tokens_map.json /tmp/model_path/special_tokens_map.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/model.safetensors.index.json /tmp/model_path/model.safetensors.index.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/tokenizer_config.json /tmp/model_path/tokenizer_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/tokenizer.json /tmp/model_path/tokenizer.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/model-00002-of-00002.safetensors /tmp/model_path/model-00002-of-00002.safetensors\n",
      "f4qy70hcyr-algo-1-une3w  | cp s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ/model-00001-of-00002.safetensors /tmp/model_path/model-00001-of-00002.safetensors\n",
      "f4qy70hcyr-algo-1-une3w  | s3 model_name_or_path s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-8B-Instruct-AWQ\n",
      "f4qy70hcyr-algo-1-une3w  | Checkpoint monitoring process started.\n",
      "f4qy70hcyr-algo-1-une3w  | [2024-11-02 11:30:40,752] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "f4qy70hcyr-algo-1-une3w  | df: /root/.triton/autotune: No such file or directory\n",
      "f4qy70hcyr-algo-1-une3w  | Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "f4qy70hcyr-algo-1-une3w  | Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:30:44 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.bfloat16\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:673] 2024-11-02 11:30:44,958 >> loading configuration file /tmp/model_path/config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:673] 2024-11-02 11:30:44,958 >> loading configuration file /tmp/model_path/config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:742] 2024-11-02 11:30:44,959 >> Model config LlamaConfig {\n",
      "f4qy70hcyr-algo-1-une3w  |   \"_name_or_path\": \"/tmp/model_path/\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"architectures\": [\n",
      "f4qy70hcyr-algo-1-une3w  |     \"LlamaForCausalLM\"\n",
      "f4qy70hcyr-algo-1-une3w  |   ],\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_dropout\": 0.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"bos_token_id\": 128000,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"eos_token_id\": 128001,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"head_dim\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_act\": \"silu\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_size\": 4096,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"initializer_range\": 0.02,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"intermediate_size\": 14336,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"max_position_embeddings\": 8192,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"mlp_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"model_type\": \"llama\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_attention_heads\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_hidden_layers\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_key_value_heads\": 8,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"pretraining_tp\": 1,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"quantization_config\": {\n",
      "f4qy70hcyr-algo-1-une3w  |     \"bits\": 4,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"group_size\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"modules_to_not_convert\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"quant_method\": \"awq\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"version\": \"gemm\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"zero_point\": true\n",
      "f4qy70hcyr-algo-1-une3w  |   },\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rms_norm_eps\": 1e-05,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_scaling\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_theta\": 500000.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"tie_word_embeddings\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"torch_dtype\": \"float16\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"transformers_version\": \"4.45.2\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"use_cache\": true,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"vocab_size\": 128256\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:742] 2024-11-02 11:30:44,959 >> Model config LlamaConfig {\n",
      "f4qy70hcyr-algo-1-une3w  |   \"_name_or_path\": \"/tmp/model_path/\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"architectures\": [\n",
      "f4qy70hcyr-algo-1-une3w  |     \"LlamaForCausalLM\"\n",
      "f4qy70hcyr-algo-1-une3w  |   ],\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_dropout\": 0.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"bos_token_id\": 128000,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"eos_token_id\": 128001,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"head_dim\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_act\": \"silu\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_size\": 4096,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"initializer_range\": 0.02,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"intermediate_size\": 14336,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"max_position_embeddings\": 8192,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"mlp_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"model_type\": \"llama\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_attention_heads\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_hidden_layers\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_key_value_heads\": 8,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"pretraining_tp\": 1,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"quantization_config\": {\n",
      "f4qy70hcyr-algo-1-une3w  |     \"bits\": 4,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"group_size\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"modules_to_not_convert\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"quant_method\": \"awq\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"version\": \"gemm\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"zero_point\": true\n",
      "f4qy70hcyr-algo-1-une3w  |   },\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rms_norm_eps\": 1e-05,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_scaling\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_theta\": 500000.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"tie_word_embeddings\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"torch_dtype\": \"float16\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"transformers_version\": \"4.45.2\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"use_cache\": true,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"vocab_size\": 128256\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:44,960 >> loading file tokenizer.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:44,960 >> loading file tokenizer.model\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:44,960 >> loading file added_tokens.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:44,960 >> loading file special_tokens_map.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:44,960 >> loading file tokenizer_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:44,960 >> loading file tokenizer.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:44,960 >> loading file tokenizer.model\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:44,960 >> loading file added_tokens.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:44,960 >> loading file special_tokens_map.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:44,960 >> loading file tokenizer_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2470] 2024-11-02 11:30:45,368 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2470] 2024-11-02 11:30:45,368 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:673] 2024-11-02 11:30:45,368 >> loading configuration file /tmp/model_path/config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:673] 2024-11-02 11:30:45,368 >> loading configuration file /tmp/model_path/config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:742] 2024-11-02 11:30:45,369 >> Model config LlamaConfig {\n",
      "f4qy70hcyr-algo-1-une3w  |   \"_name_or_path\": \"/tmp/model_path/\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"architectures\": [\n",
      "f4qy70hcyr-algo-1-une3w  |     \"LlamaForCausalLM\"\n",
      "f4qy70hcyr-algo-1-une3w  |   ],\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_dropout\": 0.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"bos_token_id\": 128000,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"eos_token_id\": 128001,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"head_dim\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_act\": \"silu\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_size\": 4096,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"initializer_range\": 0.02,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"intermediate_size\": 14336,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"max_position_embeddings\": 8192,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"mlp_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"model_type\": \"llama\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_attention_heads\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_hidden_layers\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_key_value_heads\": 8,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"pretraining_tp\": 1,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"quantization_config\": {\n",
      "f4qy70hcyr-algo-1-une3w  |     \"bits\": 4,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"group_size\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"modules_to_not_convert\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"quant_method\": \"awq\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"version\": \"gemm\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"zero_point\": true\n",
      "f4qy70hcyr-algo-1-une3w  |   },\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rms_norm_eps\": 1e-05,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_scaling\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_theta\": 500000.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"tie_word_embeddings\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"torch_dtype\": \"float16\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"transformers_version\": \"4.45.2\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"use_cache\": true,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"vocab_size\": 128256\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:742] 2024-11-02 11:30:45,369 >> Model config LlamaConfig {\n",
      "f4qy70hcyr-algo-1-une3w  |   \"_name_or_path\": \"/tmp/model_path/\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"architectures\": [\n",
      "f4qy70hcyr-algo-1-une3w  |     \"LlamaForCausalLM\"\n",
      "f4qy70hcyr-algo-1-une3w  |   ],\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_dropout\": 0.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"bos_token_id\": 128000,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"eos_token_id\": 128001,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"head_dim\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_act\": \"silu\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_size\": 4096,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"initializer_range\": 0.02,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"intermediate_size\": 14336,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"max_position_embeddings\": 8192,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"mlp_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"model_type\": \"llama\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_attention_heads\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_hidden_layers\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_key_value_heads\": 8,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"pretraining_tp\": 1,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"quantization_config\": {\n",
      "f4qy70hcyr-algo-1-une3w  |     \"bits\": 4,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"group_size\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"modules_to_not_convert\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"quant_method\": \"awq\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"version\": \"gemm\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"zero_point\": true\n",
      "f4qy70hcyr-algo-1-une3w  |   },\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rms_norm_eps\": 1e-05,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_scaling\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_theta\": 500000.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"tie_word_embeddings\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"torch_dtype\": \"float16\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"transformers_version\": \"4.45.2\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"use_cache\": true,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"vocab_size\": 128256\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:45,371 >> loading file tokenizer.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:45,371 >> loading file tokenizer.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:45,371 >> loading file tokenizer.model\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:45,371 >> loading file added_tokens.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:45,372 >> loading file special_tokens_map.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:45,371 >> loading file tokenizer.model\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:45,371 >> loading file added_tokens.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:45,372 >> loading file special_tokens_map.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:45,372 >> loading file tokenizer_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2204] 2024-11-02 11:30:45,372 >> loading file tokenizer_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2470] 2024-11-02 11:30:45,761 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2470] 2024-11-02 11:30:45,761 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:30:45 - WARNING - llamafactory.model.loader - Processor was not found: 'LlamaConfig' object has no attribute 'vision_config'.\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:30:45 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:30:45 - INFO - llamafactory.data.template - Add pad token: <|eot_id|>\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:30:45 - INFO - llamafactory.data.loader - Loading dataset identity_2.json...\n",
      "f4qy70hcyr-algo-1-une3w  | Generating train split: 0 examples [00:00, ? examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Generating train split: 91 examples [00:00, 9837.66 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Converting format of dataset (num_proc=16):   0%|          | 0/91 [00:00<?, ? examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Converting format of dataset (num_proc=16):  89%|████████▉ | 81/91 [00:00<00:00, 799.03 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Converting format of dataset (num_proc=16): 100%|██████████| 91/91 [00:00<00:00, 484.58 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:30:46 - INFO - llamafactory.data.loader - Loading dataset ruozhiba.json...\n",
      "f4qy70hcyr-algo-1-une3w  | Generating train split: 0 examples [00:00, ? examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Generating train split: 4898 examples [00:00, 14872.66 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Generating train split: 4898 examples [00:00, 14854.01 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Converting format of dataset (num_proc=16):   0%|          | 0/200 [00:00<?, ? examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Converting format of dataset (num_proc=16): 100%|██████████| 200/200 [00:00<00:00, 1959.24 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Converting format of dataset (num_proc=16): 100%|██████████| 200/200 [00:00<00:00, 1125.08 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):   0%|          | 0/291 [00:00<?, ? examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):   7%|▋         | 19/291 [00:00<00:12, 21.27 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):  13%|█▎        | 38/291 [00:01<00:06, 39.55 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):  20%|█▉        | 57/291 [00:01<00:04, 54.66 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):  26%|██▌       | 75/291 [00:01<00:03, 64.83 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):  32%|███▏      | 93/291 [00:01<00:02, 71.63 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):  38%|███▊      | 111/291 [00:01<00:02, 76.33 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):  44%|████▍     | 129/291 [00:02<00:02, 79.28 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):  51%|█████     | 147/291 [00:02<00:01, 82.82 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):  57%|█████▋    | 165/291 [00:02<00:01, 87.74 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 183/291 [00:02<00:01, 87.75 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 201/291 [00:02<00:01, 86.43 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 219/291 [00:03<00:00, 87.97 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 255/291 [00:03<00:00, 104.03 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 273/291 [00:03<00:00, 101.91 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16): 100%|██████████| 291/291 [00:03<00:00, 104.63 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Running tokenizer on dataset (num_proc=16): 100%|██████████| 291/291 [00:03<00:00, 77.15 examples/s]\n",
      "f4qy70hcyr-algo-1-une3w  | training example:\n",
      "f4qy70hcyr-algo-1-une3w  | input_ids:\n",
      "f4qy70hcyr-algo-1-une3w  | [128000, 128006, 882, 128007, 271, 6151, 128009, 128006, 78191, 128007, 271, 9906, 0, 358, 1097, 11188, 6465, 11, 459, 15592, 18328, 8040, 555, 11188, 6465, 13, 2650, 649, 358, 7945, 499, 3432, 30, 128009]\n",
      "f4qy70hcyr-algo-1-une3w  | inputs:\n",
      "f4qy70hcyr-algo-1-une3w  | <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Hello! I am Riverbot, an AI assistant developed by Riverbot. How can I assist you today?<|eot_id|>\n",
      "f4qy70hcyr-algo-1-une3w  | label_ids:\n",
      "f4qy70hcyr-algo-1-une3w  | [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 9906, 0, 358, 1097, 11188, 6465, 11, 459, 15592, 18328, 8040, 555, 11188, 6465, 13, 2650, 649, 358, 7945, 499, 3432, 30, 128009]\n",
      "f4qy70hcyr-algo-1-une3w  | labels:\n",
      "f4qy70hcyr-algo-1-une3w  | Hello! I am Riverbot, an AI assistant developed by Riverbot. How can I assist you today?<|eot_id|>\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:673] 2024-11-02 11:30:51,509 >> loading configuration file /tmp/model_path/config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:673] 2024-11-02 11:30:51,509 >> loading configuration file /tmp/model_path/config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:742] 2024-11-02 11:30:51,510 >> Model config LlamaConfig {\n",
      "f4qy70hcyr-algo-1-une3w  |   \"_name_or_path\": \"/tmp/model_path/\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"architectures\": [\n",
      "f4qy70hcyr-algo-1-une3w  |     \"LlamaForCausalLM\"\n",
      "f4qy70hcyr-algo-1-une3w  |   ],\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_dropout\": 0.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"bos_token_id\": 128000,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"eos_token_id\": 128001,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"head_dim\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_act\": \"silu\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_size\": 4096,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"initializer_range\": 0.02,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"intermediate_size\": 14336,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"max_position_embeddings\": 8192,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"mlp_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"model_type\": \"llama\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_attention_heads\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_hidden_layers\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_key_value_heads\": 8,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"pretraining_tp\": 1,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"quantization_config\": {\n",
      "f4qy70hcyr-algo-1-une3w  |     \"bits\": 4,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"group_size\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"modules_to_not_convert\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"quant_method\": \"awq\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"version\": \"gemm\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"zero_point\": true\n",
      "f4qy70hcyr-algo-1-une3w  |   },\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rms_norm_eps\": 1e-05,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_scaling\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_theta\": 500000.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"tie_word_embeddings\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"torch_dtype\": \"float16\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"transformers_version\": \"4.45.2\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"use_cache\": true,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"vocab_size\": 128256\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:742] 2024-11-02 11:30:51,510 >> Model config LlamaConfig {\n",
      "f4qy70hcyr-algo-1-une3w  |   \"_name_or_path\": \"/tmp/model_path/\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"architectures\": [\n",
      "f4qy70hcyr-algo-1-une3w  |     \"LlamaForCausalLM\"\n",
      "f4qy70hcyr-algo-1-une3w  |   ],\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_dropout\": 0.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"bos_token_id\": 128000,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"eos_token_id\": 128001,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"head_dim\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_act\": \"silu\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_size\": 4096,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"initializer_range\": 0.02,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"intermediate_size\": 14336,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"max_position_embeddings\": 8192,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"mlp_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"model_type\": \"llama\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_attention_heads\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_hidden_layers\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_key_value_heads\": 8,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"pretraining_tp\": 1,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"quantization_config\": {\n",
      "f4qy70hcyr-algo-1-une3w  |     \"bits\": 4,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"group_size\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"modules_to_not_convert\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"quant_method\": \"awq\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"version\": \"gemm\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"zero_point\": true\n",
      "f4qy70hcyr-algo-1-une3w  |   },\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rms_norm_eps\": 1e-05,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_scaling\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_theta\": 500000.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"tie_word_embeddings\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"torch_dtype\": \"float16\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"transformers_version\": \"4.45.2\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"use_cache\": true,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"vocab_size\": 128256\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:30:51 - INFO - llamafactory.model.model_utils.quantization - Loading 4-bit AWQ-quantized model.\n",
      "f4qy70hcyr-algo-1-une3w  | [WARNING|quantizer_awq.py:74] 2024-11-02 11:30:51,536 >> We suggest you to set `torch_dtype=torch.float16` for better efficiency with AWQ.\n",
      "f4qy70hcyr-algo-1-une3w  | [WARNING|quantizer_awq.py:74] 2024-11-02 11:30:51,536 >> We suggest you to set `torch_dtype=torch.float16` for better efficiency with AWQ.\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|modeling_utils.py:3729] 2024-11-02 11:30:51,536 >> loading weights file /tmp/model_path/model.safetensors.index.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|modeling_utils.py:3729] 2024-11-02 11:30:51,536 >> loading weights file /tmp/model_path/model.safetensors.index.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|modeling_utils.py:1622] 2024-11-02 11:30:51,536 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|modeling_utils.py:1622] 2024-11-02 11:30:51,536 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:1099] 2024-11-02 11:30:51,538 >> Generate config GenerationConfig {\n",
      "f4qy70hcyr-algo-1-une3w  |   \"bos_token_id\": 128000,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"eos_token_id\": 128001\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:1099] 2024-11-02 11:30:51,538 >> Generate config GenerationConfig {\n",
      "f4qy70hcyr-algo-1-une3w  |   \"bos_token_id\": 128000,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"eos_token_id\": 128001\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "f4qy70hcyr-algo-1-une3w  | Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|modeling_utils.py:4574] 2024-11-02 11:30:54,214 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|modeling_utils.py:4574] 2024-11-02 11:30:54,214 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|modeling_utils.py:4582] 2024-11-02 11:30:54,215 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at /tmp/model_path/.\n",
      "f4qy70hcyr-algo-1-une3w  | If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|modeling_utils.py:4582] 2024-11-02 11:30:54,215 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at /tmp/model_path/.\n",
      "f4qy70hcyr-algo-1-une3w  | If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:1052] 2024-11-02 11:30:54,218 >> loading configuration file /tmp/model_path/generation_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:1052] 2024-11-02 11:30:54,218 >> loading configuration file /tmp/model_path/generation_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:1099] 2024-11-02 11:30:54,218 >> Generate config GenerationConfig {\n",
      "f4qy70hcyr-algo-1-une3w  |   \"bos_token_id\": 128000,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"do_sample\": true,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"eos_token_id\": [\n",
      "f4qy70hcyr-algo-1-une3w  |     128001,\n",
      "f4qy70hcyr-algo-1-une3w  |     128009\n",
      "f4qy70hcyr-algo-1-une3w  |   ]\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:1099] 2024-11-02 11:30:54,218 >> Generate config GenerationConfig {\n",
      "f4qy70hcyr-algo-1-une3w  |   \"bos_token_id\": 128000,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"do_sample\": true,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"eos_token_id\": [\n",
      "f4qy70hcyr-algo-1-une3w  |     128001,\n",
      "f4qy70hcyr-algo-1-une3w  |     128009\n",
      "f4qy70hcyr-algo-1-une3w  |   ]\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:30:54 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:30:54 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:30:54 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:30:54 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:30:54 - INFO - llamafactory.model.model_utils.misc - Found linear modules: down_proj,o_proj,gate_proj,up_proj,v_proj,k_proj,q_proj\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:30:54 - INFO - llamafactory.model.loader - trainable params: 20,971,520 || all params: 1,071,910,912 || trainable%: 1.9565\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:667] 2024-11-02 11:30:54,873 >> Using auto half precision backend\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:667] 2024-11-02 11:30:54,873 >> Using auto half precision backend\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2243] 2024-11-02 11:30:55,539 >> ***** Running training *****\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2244] 2024-11-02 11:30:55,540 >>   Num examples = 261\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2243] 2024-11-02 11:30:55,539 >> ***** Running training *****\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2244] 2024-11-02 11:30:55,540 >>   Num examples = 261\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2245] 2024-11-02 11:30:55,540 >>   Num Epochs = 3\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2245] 2024-11-02 11:30:55,540 >>   Num Epochs = 3\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2246] 2024-11-02 11:30:55,540 >>   Instantaneous batch size per device = 1\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2249] 2024-11-02 11:30:55,540 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2250] 2024-11-02 11:30:55,540 >>   Gradient Accumulation steps = 8\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2251] 2024-11-02 11:30:55,540 >>   Total optimization steps = 96\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2246] 2024-11-02 11:30:55,540 >>   Instantaneous batch size per device = 1\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2249] 2024-11-02 11:30:55,540 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2250] 2024-11-02 11:30:55,540 >>   Gradient Accumulation steps = 8\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2251] 2024-11-02 11:30:55,540 >>   Total optimization steps = 96\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2252] 2024-11-02 11:30:55,545 >>   Number of trainable parameters = 20,971,520\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2252] 2024-11-02 11:30:55,545 >>   Number of trainable parameters = 20,971,520\n",
      "f4qy70hcyr-algo-1-une3w  | 0%|          | 0/96 [00:00<?, ?it/s]\n",
      "f4qy70hcyr-algo-1-une3w  | /opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "f4qy70hcyr-algo-1-une3w  |   with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "f4qy70hcyr-algo-1-une3w  | /opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "f4qy70hcyr-algo-1-une3w  |   with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "f4qy70hcyr-algo-1-une3w  | /opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "f4qy70hcyr-algo-1-une3w  |   with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "f4qy70hcyr-algo-1-une3w  | 1%|          | 1/96 [00:06<09:54,  6.26s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 2%|▏         | 2/96 [00:10<07:44,  4.94s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 3%|▎         | 3/96 [00:14<06:55,  4.47s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 4%|▍         | 4/96 [00:18<06:32,  4.26s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 5%|▌         | 5/96 [00:22<06:28,  4.27s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 6%|▋         | 6/96 [00:26<06:21,  4.24s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 7%|▋         | 7/96 [00:30<06:05,  4.11s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 8%|▊         | 8/96 [00:34<05:53,  4.02s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 9%|▉         | 9/96 [00:37<05:28,  3.78s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 10%|█         | 10/96 [00:41<05:32,  3.86s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | {'loss': 2.3185, 'grad_norm': 1.69431734085083, 'learning_rate': 0.0001, 'epoch': 0.31}\n",
      "f4qy70hcyr-algo-1-une3w  | 10%|█         | 10/96 [00:41<05:32,  3.86s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 11%|█▏        | 11/96 [00:45<05:31,  3.90s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 12%|█▎        | 12/96 [00:49<05:28,  3.91s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 14%|█▎        | 13/96 [00:53<05:18,  3.84s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 15%|█▍        | 14/96 [00:56<05:11,  3.80s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 16%|█▌        | 15/96 [01:00<05:05,  3.77s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 17%|█▋        | 16/96 [01:04<05:06,  3.83s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 18%|█▊        | 17/96 [01:08<05:00,  3.80s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 19%|█▉        | 18/96 [01:12<05:00,  3.86s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 20%|█▉        | 19/96 [01:16<05:00,  3.90s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 21%|██        | 20/96 [01:20<04:55,  3.89s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | {'loss': 1.8483, 'grad_norm': 1.7542682886123657, 'learning_rate': 9.67008054366274e-05, 'epoch': 0.61}\n",
      "f4qy70hcyr-algo-1-une3w  | 21%|██        | 20/96 [01:20<04:55,  3.89s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 22%|██▏       | 21/96 [01:23<04:45,  3.80s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 23%|██▎       | 22/96 [01:27<04:38,  3.77s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 24%|██▍       | 23/96 [01:31<04:35,  3.78s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 25%|██▌       | 24/96 [01:35<04:37,  3.86s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 26%|██▌       | 25/96 [01:39<04:32,  3.84s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 27%|██▋       | 26/96 [01:42<04:25,  3.79s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 28%|██▊       | 27/96 [01:46<04:23,  3.82s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 29%|██▉       | 28/96 [01:50<04:22,  3.87s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 30%|███       | 29/96 [01:54<04:17,  3.85s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 31%|███▏      | 30/96 [01:58<04:22,  3.97s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | {'loss': 1.6299, 'grad_norm': 1.6644738912582397, 'learning_rate': 8.72386091371891e-05, 'epoch': 0.92}\n",
      "f4qy70hcyr-algo-1-une3w  | 31%|███▏      | 30/96 [01:58<04:22,  3.97s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 32%|███▏      | 31/96 [02:02<04:18,  3.98s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 33%|███▎      | 32/96 [02:06<04:08,  3.88s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 34%|███▍      | 33/96 [02:10<04:07,  3.92s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 35%|███▌      | 34/96 [02:13<03:58,  3.84s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 36%|███▋      | 35/96 [02:17<03:49,  3.76s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 38%|███▊      | 36/96 [02:21<03:42,  3.70s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 39%|███▊      | 37/96 [02:25<03:47,  3.85s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 40%|███▉      | 38/96 [02:29<03:46,  3.90s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 41%|████      | 39/96 [02:33<03:40,  3.87s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 42%|████▏     | 40/96 [02:36<03:36,  3.87s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | {'loss': 1.4548, 'grad_norm': 1.6968165636062622, 'learning_rate': 7.286211616523193e-05, 'epoch': 1.23}\n",
      "f4qy70hcyr-algo-1-une3w  | 42%|████▏     | 40/96 [02:36<03:36,  3.87s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 43%|████▎     | 41/96 [02:41<03:37,  3.95s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 44%|████▍     | 42/96 [02:44<03:31,  3.92s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 45%|████▍     | 43/96 [02:48<03:25,  3.88s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 46%|████▌     | 44/96 [02:52<03:19,  3.83s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 47%|████▋     | 45/96 [02:56<03:17,  3.87s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 48%|████▊     | 46/96 [03:00<03:15,  3.90s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 49%|████▉     | 47/96 [03:04<03:14,  3.98s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 50%|█████     | 48/96 [03:08<03:09,  3.96s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 51%|█████     | 49/96 [03:12<03:05,  3.94s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 52%|█████▏    | 50/96 [03:16<03:01,  3.96s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | {'loss': 1.3869, 'grad_norm': 2.1912894248962402, 'learning_rate': 5.546856041889373e-05, 'epoch': 1.53}\n",
      "f4qy70hcyr-algo-1-une3w  | 52%|█████▏    | 50/96 [03:16<03:01,  3.96s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 53%|█████▎    | 51/96 [03:20<03:00,  4.02s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 54%|█████▍    | 52/96 [03:24<02:50,  3.88s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 55%|█████▌    | 53/96 [03:27<02:46,  3.88s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 56%|█████▋    | 54/96 [03:31<02:42,  3.87s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 57%|█████▋    | 55/96 [03:35<02:38,  3.86s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 58%|█████▊    | 56/96 [03:39<02:36,  3.90s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 59%|█████▉    | 57/96 [03:43<02:33,  3.93s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 60%|██████    | 58/96 [03:47<02:26,  3.85s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 61%|██████▏   | 59/96 [03:51<02:24,  3.92s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 62%|██████▎   | 60/96 [03:55<02:18,  3.86s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | {'loss': 1.3949, 'grad_norm': 2.1762142181396484, 'learning_rate': 3.735333088041596e-05, 'epoch': 1.84}\n",
      "f4qy70hcyr-algo-1-une3w  | 62%|██████▎   | 60/96 [03:55<02:18,  3.86s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 64%|██████▎   | 61/96 [03:59<02:17,  3.92s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 65%|██████▍   | 62/96 [04:02<02:11,  3.86s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 66%|██████▌   | 63/96 [04:06<02:08,  3.90s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 67%|██████▋   | 64/96 [04:10<02:02,  3.82s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 68%|██████▊   | 65/96 [04:14<02:01,  3.92s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 69%|██████▉   | 66/96 [04:18<01:59,  3.99s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 70%|██████▉   | 67/96 [04:22<01:54,  3.95s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 71%|███████   | 68/96 [04:26<01:48,  3.89s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 72%|███████▏  | 69/96 [04:30<01:44,  3.85s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 73%|███████▎  | 70/96 [04:34<01:40,  3.88s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | {'loss': 1.2917, 'grad_norm': 1.6295247077941895, 'learning_rate': 2.090705422210237e-05, 'epoch': 2.15}\n",
      "f4qy70hcyr-algo-1-une3w  | 73%|███████▎  | 70/96 [04:34<01:40,  3.88s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 74%|███████▍  | 71/96 [04:38<01:40,  4.02s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 75%|███████▌  | 72/96 [04:42<01:34,  3.94s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 76%|███████▌  | 73/96 [04:46<01:29,  3.89s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 77%|███████▋  | 74/96 [04:49<01:25,  3.90s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 78%|███████▊  | 75/96 [04:54<01:22,  3.94s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 79%|███████▉  | 76/96 [04:57<01:18,  3.92s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 80%|████████  | 77/96 [05:02<01:15,  3.98s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 81%|████████▏ | 78/96 [05:05<01:10,  3.94s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 82%|████████▏ | 79/96 [05:09<01:06,  3.89s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 83%|████████▎ | 80/96 [05:13<01:02,  3.90s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | {'loss': 1.2162, 'grad_norm': 1.9883239269256592, 'learning_rate': 8.30010910550611e-06, 'epoch': 2.45}\n",
      "f4qy70hcyr-algo-1-une3w  | 83%|████████▎ | 80/96 [05:13<01:02,  3.90s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 84%|████████▍ | 81/96 [05:17<00:58,  3.93s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 85%|████████▌ | 82/96 [05:21<00:54,  3.90s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 86%|████████▋ | 83/96 [05:25<00:51,  3.94s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 88%|████████▊ | 84/96 [05:29<00:47,  3.95s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 89%|████████▊ | 85/96 [05:33<00:43,  3.95s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 90%|████████▉ | 86/96 [05:36<00:38,  3.86s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 91%|█████████ | 87/96 [05:40<00:34,  3.79s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 92%|█████████▏| 88/96 [05:44<00:30,  3.75s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 93%|█████████▎| 89/96 [05:48<00:26,  3.82s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 94%|█████████▍| 90/96 [05:52<00:22,  3.82s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | {'loss': 1.2137, 'grad_norm': 1.7457506656646729, 'learning_rate': 1.196206122203647e-06, 'epoch': 2.76}\n",
      "f4qy70hcyr-algo-1-une3w  | 94%|█████████▍| 90/96 [05:52<00:22,  3.82s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 95%|█████████▍| 91/96 [05:56<00:19,  3.91s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 96%|█████████▌| 92/96 [06:00<00:15,  3.92s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 97%|█████████▋| 93/96 [06:03<00:11,  3.86s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 98%|█████████▊| 94/96 [06:07<00:07,  3.91s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 99%|█████████▉| 95/96 [06:11<00:03,  3.93s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 100%|██████████| 96/96 [06:15<00:00,  3.89s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:3705] 2024-11-02 11:37:11,202 >> Saving model checkpoint to /tmp/finetuned_model/checkpoint-96\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:3705] 2024-11-02 11:37:11,202 >> Saving model checkpoint to /tmp/finetuned_model/checkpoint-96\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:673] 2024-11-02 11:37:11,229 >> loading configuration file /tmp/model_path/config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:673] 2024-11-02 11:37:11,229 >> loading configuration file /tmp/model_path/config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:742] 2024-11-02 11:37:11,230 >> Model config LlamaConfig {\n",
      "f4qy70hcyr-algo-1-une3w  |   \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"architectures\": [\n",
      "f4qy70hcyr-algo-1-une3w  |     \"LlamaForCausalLM\"\n",
      "f4qy70hcyr-algo-1-une3w  |   ],\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_dropout\": 0.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"bos_token_id\": 128000,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"eos_token_id\": 128001,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"head_dim\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_act\": \"silu\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_size\": 4096,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"initializer_range\": 0.02,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"intermediate_size\": 14336,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"max_position_embeddings\": 8192,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"mlp_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"model_type\": \"llama\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_attention_heads\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_hidden_layers\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_key_value_heads\": 8,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"pretraining_tp\": 1,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"quantization_config\": {\n",
      "f4qy70hcyr-algo-1-une3w  |     \"bits\": 4,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"group_size\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"modules_to_not_convert\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"quant_method\": \"awq\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"version\": \"gemm\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"zero_point\": true\n",
      "f4qy70hcyr-algo-1-une3w  |   },\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rms_norm_eps\": 1e-05,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_scaling\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_theta\": 500000.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"tie_word_embeddings\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"torch_dtype\": \"float16\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"transformers_version\": \"4.45.2\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"use_cache\": true,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"vocab_size\": 128256\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:742] 2024-11-02 11:37:11,230 >> Model config LlamaConfig {\n",
      "f4qy70hcyr-algo-1-une3w  |   \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"architectures\": [\n",
      "f4qy70hcyr-algo-1-une3w  |     \"LlamaForCausalLM\"\n",
      "f4qy70hcyr-algo-1-une3w  |   ],\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_dropout\": 0.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"bos_token_id\": 128000,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"eos_token_id\": 128001,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"head_dim\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_act\": \"silu\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_size\": 4096,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"initializer_range\": 0.02,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"intermediate_size\": 14336,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"max_position_embeddings\": 8192,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"mlp_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"model_type\": \"llama\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_attention_heads\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_hidden_layers\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_key_value_heads\": 8,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"pretraining_tp\": 1,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"quantization_config\": {\n",
      "f4qy70hcyr-algo-1-une3w  |     \"bits\": 4,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"group_size\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"modules_to_not_convert\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"quant_method\": \"awq\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"version\": \"gemm\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"zero_point\": true\n",
      "f4qy70hcyr-algo-1-une3w  |   },\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rms_norm_eps\": 1e-05,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_scaling\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_theta\": 500000.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"tie_word_embeddings\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"torch_dtype\": \"float16\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"transformers_version\": \"4.45.2\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"use_cache\": true,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"vocab_size\": 128256\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2641] 2024-11-02 11:37:11,401 >> tokenizer config file saved in /tmp/finetuned_model/checkpoint-96/tokenizer_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2641] 2024-11-02 11:37:11,401 >> tokenizer config file saved in /tmp/finetuned_model/checkpoint-96/tokenizer_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2650] 2024-11-02 11:37:11,402 >> Special tokens file saved in /tmp/finetuned_model/checkpoint-96/special_tokens_map.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2650] 2024-11-02 11:37:11,402 >> Special tokens file saved in /tmp/finetuned_model/checkpoint-96/special_tokens_map.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2505] 2024-11-02 11:37:11,905 >> \n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:2505] 2024-11-02 11:37:11,905 >> \n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | {'train_runtime': 376.3603, 'train_samples_per_second': 2.08, 'train_steps_per_second': 0.255, 'train_loss': 1.5095102190971375, 'epoch': 2.94}\n",
      "f4qy70hcyr-algo-1-une3w  | 100%|██████████| 96/96 [06:16<00:00,  3.89s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | 100%|██████████| 96/96 [06:16<00:00,  3.92s/it]\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:3705] 2024-11-02 11:37:11,907 >> Saving model checkpoint to /tmp/finetuned_model\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|trainer.py:3705] 2024-11-02 11:37:11,907 >> Saving model checkpoint to /tmp/finetuned_model\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:673] 2024-11-02 11:37:11,934 >> loading configuration file /tmp/model_path/config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:673] 2024-11-02 11:37:11,934 >> loading configuration file /tmp/model_path/config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:742] 2024-11-02 11:37:11,935 >> Model config LlamaConfig {\n",
      "f4qy70hcyr-algo-1-une3w  |   \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"architectures\": [\n",
      "f4qy70hcyr-algo-1-une3w  |     \"LlamaForCausalLM\"\n",
      "f4qy70hcyr-algo-1-une3w  |   ],\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_dropout\": 0.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"bos_token_id\": 128000,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"eos_token_id\": 128001,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"head_dim\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_act\": \"silu\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_size\": 4096,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"initializer_range\": 0.02,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"intermediate_size\": 14336,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"max_position_embeddings\": 8192,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"mlp_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"model_type\": \"llama\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_attention_heads\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_hidden_layers\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_key_value_heads\": 8,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"pretraining_tp\": 1,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"quantization_config\": {\n",
      "f4qy70hcyr-algo-1-une3w  |     \"bits\": 4,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"group_size\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"modules_to_not_convert\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"quant_method\": \"awq\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"version\": \"gemm\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"zero_point\": true\n",
      "f4qy70hcyr-algo-1-une3w  |   },\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rms_norm_eps\": 1e-05,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_scaling\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_theta\": 500000.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"tie_word_embeddings\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"torch_dtype\": \"float16\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"transformers_version\": \"4.45.2\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"use_cache\": true,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"vocab_size\": 128256\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|configuration_utils.py:742] 2024-11-02 11:37:11,935 >> Model config LlamaConfig {\n",
      "f4qy70hcyr-algo-1-une3w  |   \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"architectures\": [\n",
      "f4qy70hcyr-algo-1-une3w  |     \"LlamaForCausalLM\"\n",
      "f4qy70hcyr-algo-1-une3w  |   ],\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"attention_dropout\": 0.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"bos_token_id\": 128000,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"eos_token_id\": 128001,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"head_dim\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_act\": \"silu\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"hidden_size\": 4096,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"initializer_range\": 0.02,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"intermediate_size\": 14336,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"max_position_embeddings\": 8192,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"mlp_bias\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"model_type\": \"llama\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_attention_heads\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_hidden_layers\": 32,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"num_key_value_heads\": 8,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"pretraining_tp\": 1,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"quantization_config\": {\n",
      "f4qy70hcyr-algo-1-une3w  |     \"bits\": 4,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"group_size\": 128,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"modules_to_not_convert\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |     \"quant_method\": \"awq\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"version\": \"gemm\",\n",
      "f4qy70hcyr-algo-1-une3w  |     \"zero_point\": true\n",
      "f4qy70hcyr-algo-1-une3w  |   },\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rms_norm_eps\": 1e-05,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_scaling\": null,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"rope_theta\": 500000.0,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"tie_word_embeddings\": false,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"torch_dtype\": \"float16\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"transformers_version\": \"4.45.2\",\n",
      "f4qy70hcyr-algo-1-une3w  |   \"use_cache\": true,\n",
      "f4qy70hcyr-algo-1-une3w  |   \"vocab_size\": 128256\n",
      "f4qy70hcyr-algo-1-une3w  | }\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2641] 2024-11-02 11:37:12,106 >> tokenizer config file saved in /tmp/finetuned_model/tokenizer_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2641] 2024-11-02 11:37:12,106 >> tokenizer config file saved in /tmp/finetuned_model/tokenizer_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2650] 2024-11-02 11:37:12,107 >> Special tokens file saved in /tmp/finetuned_model/special_tokens_map.json\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|tokenization_utils_base.py:2650] 2024-11-02 11:37:12,107 >> Special tokens file saved in /tmp/finetuned_model/special_tokens_map.json\n",
      "f4qy70hcyr-algo-1-une3w  | ***** train metrics *****\n",
      "f4qy70hcyr-algo-1-une3w  | epoch                    =     2.9425\n",
      "f4qy70hcyr-algo-1-une3w  |   total_flos               =   332543GF\n",
      "f4qy70hcyr-algo-1-une3w  |   train_loss               =     1.5095\n",
      "f4qy70hcyr-algo-1-une3w  |   train_runtime            = 0:06:16.36\n",
      "f4qy70hcyr-algo-1-une3w  |   train_samples_per_second =       2.08\n",
      "f4qy70hcyr-algo-1-une3w  |   train_steps_per_second   =      0.255\n",
      "f4qy70hcyr-algo-1-une3w  | Figure saved at: /tmp/finetuned_model/training_loss.png\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:37:12 - WARNING - llamafactory.extras.ploting - No metric eval_loss to plot.\n",
      "f4qy70hcyr-algo-1-une3w  | 11/02/2024 11:37:12 - WARNING - llamafactory.extras.ploting - No metric eval_accuracy to plot.\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|modelcard.py:449] 2024-11-02 11:37:12,538 >> Dropping the following result as it does not have all the necessary fields:\n",
      "f4qy70hcyr-algo-1-une3w  | {'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n",
      "f4qy70hcyr-algo-1-une3w  | [INFO|modelcard.py:449] 2024-11-02 11:37:12,538 >> Dropping the following result as it does not have all the necessary fields:\n",
      "f4qy70hcyr-algo-1-une3w  | {'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n",
      "f4qy70hcyr-algo-1-une3w  | Checkpoint monitoring process stopped.\n",
      "f4qy70hcyr-algo-1-une3w  | *****************finished training, start cp finetuned model*****************************\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/checkpoint-96/README.md s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/README.md\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/checkpoint-96/trainer_state.json s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/trainer_state.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/README.md s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/README.md\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/training_args.bin s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/training_args.bin\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/all_results.json s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/all_results.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/trainer_log.jsonl s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/trainer_log.jsonl\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/checkpoint-96/adapter_config.json s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/adapter_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/runs/Nov02_11-30-44_algo-1-une3w/events.out.tfevents.1730547055.algo-1-une3w.353.0 s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/runs/Nov02_11-30-44_algo-1-une3w/events.out.tfevents.1730547055.algo-1-une3w.353.0\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/training_loss.png s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/training_loss.png\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/train_results.json s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/train_results.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/trainer_state.json s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/trainer_state.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/adapter_config.json s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/adapter_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/checkpoint-96/special_tokens_map.json s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/special_tokens_map.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/special_tokens_map.json s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/special_tokens_map.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/checkpoint-96/tokenizer_config.json s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/tokenizer_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/checkpoint-96/rng_state.pth s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/rng_state.pth\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/checkpoint-96/training_args.bin s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/training_args.bin\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/checkpoint-96/scheduler.pt s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/scheduler.pt\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/tokenizer_config.json s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/tokenizer_config.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/checkpoint-96/tokenizer.json s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/tokenizer.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/tokenizer.json s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/tokenizer.json\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/checkpoint-96/adapter_model.safetensors s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/adapter_model.safetensors\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/checkpoint-96/optimizer.pt s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/optimizer.pt\n",
      "f4qy70hcyr-algo-1-une3w  | cp /tmp/finetuned_model/adapter_model.safetensors s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/adapter_model.safetensors\n",
      "f4qy70hcyr-algo-1-une3w  | \n",
      "f4qy70hcyr-algo-1-une3w  | -----finished cp-------\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:37:15,625 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:37:15,625 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "f4qy70hcyr-algo-1-une3w  | 2024-11-02 11:37:15,625 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.local.image:===== Job Complete =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f4qy70hcyr-algo-1-une3w exited with code 0\n",
      "Aborting on container exit...\n",
      " Container f4qy70hcyr-algo-1-une3w  Stopping\n",
      " Container f4qy70hcyr-algo-1-une3w  Stopped\n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 至此步，本章节结束\n",
    "- 模型已经在本地的training job上训练完成，并上传至s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下是可选步骤，直接在本地使用LLaMA-Factory cli进行训练\n",
    "### 本地运行LLaMA-Factory cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirm = input(\"Are you sure you want to continue? (y/n) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#切换工作目录到LLaMA-Factory\n",
    "os.chdir('LLaMA-Factory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#安装LLaMA-Factory\n",
    "os.system(\"pip install --no-deps -e .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.system(\"pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/identity_2.json data/identity_2.json\n",
      "cp s3://sagemaker-us-east-1-434444145045/dataset-for-training/train/ruozhiba.json data/ruozhiba.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#下载数据集\n",
    "os.system(\"chmod +x ./s5cmd\")\n",
    "os.system(\"./s5cmd sync {0} {1}\".format(training_input_path+'/*', 'data/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 启动训练\n",
    "本次训练过程大概15分钟左右"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICES=0\n",
    "os.system(f\"CUDA_VISIBLE_DEVICES={DEVICES} llamafactory-cli train {sg_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上传Lora模型文件至S3保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"./s5cmd sync {0} {1}\".format(save_dir, f's3://{default_bucket}/llama3-8b-qlora/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lora model file saved s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lora model file saved s3://{default_bucket}/llama3-8b-qlora/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

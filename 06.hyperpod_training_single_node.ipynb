{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3b6adcb-9ff5-419f-aeb0-40073aaaf5b0",
   "metadata": {},
   "source": [
    "# Using LLama Factory finetune on SageMaker - HyperPod 集群\n",
    "# 6. 在HyperPod集群提交训练任务-单节点任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461e9ae8-e9e9-4688-a1d6-8935362dcd92",
   "metadata": {},
   "source": [
    "## 6.1. 单节点单GPU QLora训练 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6fff4-7c50-4ea1-b072-a67d71aa6f2e",
   "metadata": {},
   "source": [
    "#### 先决条件：完成01.llama_factory_finetune_on_SageMaker_QLora-Local-Notebook中数据和yml配置准备部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd6f012-2940-4089-80cb-91fc3c59b53d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::434444145045:role/notebook-hyperpod-ExecutionRole-xHaRX2L05qHQ\n",
      "sagemaker bucket: sagemaker-us-west-2-434444145045\n",
      "sagemaker session region: us-west-2\n",
      "boto3 version: 1.34.123\n",
      "sagemaker version: 2.222.0\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "print(f\"boto3 version: {boto3.__version__}\")\n",
    "print(f\"sagemaker version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c60d2-57e8-43b9-bcaa-c32a33f2dae8",
   "metadata": {},
   "source": [
    "### 准备LLaMA-Factory 的 训练配置yaml文件\n",
    "-从LLaMA-Factory/examples/train_qlora/目录中复制出llama3_lora_sft_awq.yaml，并修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7624602a-1190-4084-89bf-d9de68f57f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load template\n",
    "import yaml\n",
    "file_name = './LLaMA-Factory/examples/train_qlora/llama3_lora_sft_awq.yaml'\n",
    "with open(file_name) as f:\n",
    "    doc = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37b05d1a-2615-408a-8e57-0df91a85cade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#设置模型的保存目录在本notebook实例本地\n",
    "# 如果是用SageMaker则使用以下模型文件路径\n",
    "doc['output_dir'] ='/home/ubuntu/finetuned_model'\n",
    "doc['per_device_train_batch_size'] =1\n",
    "doc['gradient_accumulation_steps'] =8\n",
    "# doc['lora_target'] = 'all'\n",
    "doc['cutoff_len'] = 2048\n",
    "doc['num_train_epochs'] = 5.0\n",
    "doc['warmup_steps'] = 10\n",
    "\n",
    "#实验时间，只选取前200条数据做训练\n",
    "doc['max_samples'] = 200 \n",
    "#数据集\n",
    "doc['dataset'] = 'identity,ruozhiba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85508e06-9ab8-4f98-ba64-57578ddf2222",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name_or_path': 'TechxGenus/Meta-Llama-3-8B-Instruct-AWQ',\n",
       " 'stage': 'sft',\n",
       " 'do_train': True,\n",
       " 'finetuning_type': 'lora',\n",
       " 'lora_target': 'all',\n",
       " 'dataset': 'identity,ruozhiba',\n",
       " 'template': 'llama3',\n",
       " 'cutoff_len': 2048,\n",
       " 'max_samples': 200,\n",
       " 'overwrite_cache': True,\n",
       " 'preprocessing_num_workers': 16,\n",
       " 'output_dir': '/home/ubuntu/finetuned_model',\n",
       " 'logging_steps': 10,\n",
       " 'save_steps': 500,\n",
       " 'plot_loss': True,\n",
       " 'overwrite_output_dir': True,\n",
       " 'per_device_train_batch_size': 1,\n",
       " 'gradient_accumulation_steps': 8,\n",
       " 'learning_rate': 0.0001,\n",
       " 'num_train_epochs': 5.0,\n",
       " 'lr_scheduler_type': 'cosine',\n",
       " 'warmup_ratio': 0.1,\n",
       " 'fp16': True,\n",
       " 'ddp_timeout': 180000000,\n",
       " 'val_size': 0.1,\n",
       " 'per_device_eval_batch_size': 1,\n",
       " 'eval_strategy': 'steps',\n",
       " 'eval_steps': 500,\n",
       " 'warmup_steps': 10}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#保存为训练配置文件\n",
    "sg_config = 'sg_config_qlora.yaml'\n",
    "with open(f'./LLaMA-Factory/{sg_config}', 'w') as f:\n",
    "    yaml.safe_dump(doc, f)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0df7cb-aecb-45e6-8e72-1cd8bca1c6e8",
   "metadata": {},
   "source": [
    "- ❌ 准备训练启动脚本 注意把s3 bucket 替换成自己账号的地址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c3b583-ce27-4737-8034-22f9bf7fae27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyperpod-scripts/train_single_lora.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyperpod-scripts/train_single_lora.sh\n",
    "#!/bin/bash\n",
    "source  ../miniconda3/bin/activate\n",
    "\n",
    "conda activate py310\n",
    "\n",
    "chmod +x ./s5cmd\n",
    "\n",
    "#download training dataset\n",
    "./s5cmd sync s3://sagemaker-us-west-2-434444145045/dataset-for-training/train/* /home/ubuntu/LLaMA-Factory/data/\n",
    "\n",
    "#start train\n",
    "CUDA_VISIBLE_DEVICES=0 llamafactory-cli train sg_config_qlora.yaml\n",
    "\n",
    "\n",
    "./s5cmd sync /home/ubuntu/finetuned_model s3://sagemaker-us-west-2-434444145045/hyperpod/llama3-8b-qlora/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d92c881-75b5-4c3a-885b-1eada74435e7",
   "metadata": {},
   "source": [
    "#### 上传训练脚本到S3 bucket中，之后S3 bucket会挂载到集群所有节点中，这样所有计算节点都可以访问训练代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1520244-4ce5-4207-83bc-a31079ce97fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp LLaMA-Factory/sg_config_qlora.yaml s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/sg_config_qlora.yaml\n",
      "cp LLaMA-Factory/data/dataset_info.json s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/data/dataset_info.json\n",
      "upload: hyperpod-scripts/train_batch.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/train_batch.sh\n",
      "upload: hyperpod-scripts/llama_factory_setup.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/llama_factory_setup.sh\n",
      "upload: hyperpod-scripts/train_multi_ds.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/train_multi_ds.sh\n",
      "upload: hyperpod-scripts/train_single_lora.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/train_single_lora.sh\n"
     ]
    }
   ],
   "source": [
    "!./s5cmd sync ./LLaMA-Factory s3://{bucket}/hyperpod/\n",
    "!aws s3 cp --recursive hyperpod-scripts/ s3://{bucket}/hyperpod/LLaMA-Factory/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfe3ec2-db52-4e3b-9d4d-d773b6720284",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### S3 bucket的目录下的代码更像到本地目录\n",
    "```bash\n",
    "sudo su ubuntu\n",
    "cd ~/LLaMA-Factory\n",
    "srun -N1 \"cp\" \"-r\" \"../mnt/hyperpod/LLaMA-Factory/data/dataset_info.json\" \"./data/dataset_info.json\"\n",
    "srun -N1 \"cp\" \"-r\" \"../mnt/hyperpod/LLaMA-Factory/train_single_lora.sh\" \"./train_single_lora.sh\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ced339-1324-4b03-956f-3c1f54443720",
   "metadata": {},
   "source": [
    "#### 提交训练\n",
    "```bash\n",
    "srun -N1 \"bash\" \"train_single_lora.sh\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82da19c-985f-4b38-82bf-c0e1f51db0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

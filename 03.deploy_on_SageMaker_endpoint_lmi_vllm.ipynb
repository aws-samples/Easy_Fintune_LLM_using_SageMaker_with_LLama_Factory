{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c19edf-f419-4d70-94ac-3201f01c1521",
   "metadata": {},
   "source": [
    "# Using LLama Factory finetune on SageMaker \n",
    "# 3. 使用SageMaker LMI(Large Model Inference) vLLM 引擎部署模型至SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c8dfa-c07f-4db6-b463-3cf8432828f7",
   "metadata": {},
   "source": [
    "The LMI container offers the out-of-box integration with SageMaker for hosting multiple LoRA adapters with higher performance (low latency and high throughput) using the vLLM library that uses S-LORA and Punica. S-LoRA stores all adapters in the main memory and fetches the adapters used by the currently running queries to the GPU memory. To efficiently use the GPU memory and reduce fragmentation, S-LoRA proposes Unified Paging. Unified Paging uses a unified memory pool to manage dynamic adapter weights with different ranks and KV cache tensors with varying sequence lengths. Additionally, S-LoRA employs a novel tensor parallelism strategy and highly optimized custom CUDA kernels for heterogeneous batching of LoRA computation. Collectively, these features enable S-LoRA to serve thousands of LoRA adapters on a single GPU or across multiple GPUs with a small overhead.\n",
    "\n",
    "Below diagram shows the Multi LoRA-Adapter serving stack of LMI container on SageMaker Multi LoRA-Adapter serving stack of LMI container on SageMaker  \n",
    "![imge](https://raw.githubusercontent.com/aws-samples/sagemaker-genai-hosting-examples/0a98859eef9c53a5aa3beeae7d59b38a8de934dc/Llama2/Llama2-7b/LMI/LoRA-LMI-SageMaker.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cdc3f0a-5e2f-4fcb-a17c-872a10c2f620",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "default_bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "35d07ddd-1ba1-4736-8f96-cee8ba4c5af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_model_prefix = \"Meta-Llama-3-8B-Instruct-AWQ\"  \n",
    "s3_model_path =  f\"s3://{default_bucket}/{s3_model_prefix}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "20aa0fd1-0c7b-44fd-94e4-36d4ff86bfcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image going to be used is ---- > 763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.29.0-lmi11.0.0-cu124\n"
     ]
    }
   ],
   "source": [
    "inference_image_uri = image_uris.retrieve(\n",
    "    framework=\"djl-lmi\",\n",
    "    region=sess.boto_session.region_name,\n",
    "    version=\"0.29.0\"\n",
    ")\n",
    "# inference_image_uri = (\n",
    "#     \"763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124-v1.0\"\n",
    "# )\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8ec4b57a-fe88-4874-b649-07cfd1bcc07e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_code_dir = 'vllm_inference'\n",
    "!mkdir -p {local_code_dir}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd5706-737f-4d21-81f7-aaf56d9257e5",
   "metadata": {},
   "source": [
    "* Note: option.model_id 需要改成模型下载的s3_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0e2ecdf9-14bc-4f01-a5f2-d5c091aaddd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vllm_inference/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile {local_code_dir}/serving.properties\n",
    "engine=Python\n",
    "option.model_id=TechxGenus/Meta-Llama-3-8B-Instruct-AWQ\n",
    "option.dtype=fp16\n",
    "option.enable_lora=true\n",
    "option.rolling_batch=vllm\n",
    "option.tensor_parallel_degree=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f47ae4ed-943f-4ac8-9d02-db3e0e287099",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vllm_inference/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {local_code_dir}/requirements.txt\n",
    "transformers==4.45.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a9c76212-df84-48cb-8927-fcdbc19f3ced",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vllm_inference/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile {local_code_dir}/serving.properties\n",
    "engine=MPI\n",
    "option.model_id=TechxGenus/Meta-Llama-3-8B-Instruct-AWQ\n",
    "option.rolling_batch=lmi-dist\n",
    "option.tensor_parallel_degree=1\n",
    "option.enable_lora=true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef411ce7-7da5-4ce0-847c-874f321e0490",
   "metadata": {
    "tags": []
   },
   "source": [
    "- 创建lora目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ff6b4a0d-a80b-45c9-98ca-9289da66a00a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p {local_code_dir}/adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36bfbc-6014-4a8d-b03c-24c7753e4507",
   "metadata": {},
   "source": [
    "### 下载训练好的Lora至本地目录打包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f23d8f59-78d7-4eae-89b8-1857e28e8e56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/adapter_config.json to vllm_inference/adapters/exp/checkpoint-500/adapter_config.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/README.md to vllm_inference/adapters/exp/checkpoint-500/README.md\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/rng_state.pth to vllm_inference/adapters/exp/checkpoint-500/rng_state.pth\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/tokenizer_config.json to vllm_inference/adapters/exp/checkpoint-500/tokenizer_config.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/special_tokens_map.json to vllm_inference/adapters/exp/checkpoint-500/special_tokens_map.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/scheduler.pt to vllm_inference/adapters/exp/checkpoint-500/scheduler.pt\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/trainer_state.json to vllm_inference/adapters/exp/checkpoint-500/trainer_state.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/training_args.bin to vllm_inference/adapters/exp/checkpoint-500/training_args.bin\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/adapter_config.json to vllm_inference/adapters/exp/checkpoint-96/adapter_config.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/README.md to vllm_inference/adapters/exp/checkpoint-96/README.md\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/tokenizer.json to vllm_inference/adapters/exp/checkpoint-500/tokenizer.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/rng_state.pth to vllm_inference/adapters/exp/checkpoint-96/rng_state.pth\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/scheduler.pt to vllm_inference/adapters/exp/checkpoint-96/scheduler.pt\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/special_tokens_map.json to vllm_inference/adapters/exp/checkpoint-96/special_tokens_map.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/tokenizer_config.json to vllm_inference/adapters/exp/checkpoint-96/tokenizer_config.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/adapter_model.safetensors to vllm_inference/adapters/exp/checkpoint-500/adapter_model.safetensors\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/tokenizer.json to vllm_inference/adapters/exp/checkpoint-96/tokenizer.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/trainer_state.json to vllm_inference/adapters/exp/checkpoint-96/trainer_state.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/training_args.bin to vllm_inference/adapters/exp/checkpoint-96/training_args.bin\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/runs/Jun05_16-14-18_algo-1/events.out.tfevents.1717607995.algo-1.259.1 to vllm_inference/adapters/exp/runs/Jun05_16-14-18_algo-1/events.out.tfevents.1717607995.algo-1.259.1\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/adapter_model.safetensors to vllm_inference/adapters/exp/checkpoint-96/adapter_model.safetensors\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/runs/Jun05_16-14-18_algo-1/events.out.tfevents.1717604084.algo-1.259.0 to vllm_inference/adapters/exp/runs/Jun05_16-14-18_algo-1/events.out.tfevents.1717604084.algo-1.259.0\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/runs/Nov02_11-30-44_algo-1-une3w/events.out.tfevents.1730547055.algo-1-une3w.353.0 to vllm_inference/adapters/exp/runs/Nov02_11-30-44_algo-1-une3w/events.out.tfevents.1730547055.algo-1-une3w.353.0\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/optimizer.pt to vllm_inference/adapters/exp/checkpoint-500/optimizer.pt\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/optimizer.pt to vllm_inference/adapters/exp/checkpoint-96/optimizer.pt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync s3://{default_bucket}/llama3-8b-qlora/finetuned_model/ {local_code_dir}/adapters/exp\n",
    "!rm -rf {local_code_dir}/adapters/exp/checkpoint*\n",
    "!rm -rf {local_code_dir}/adapters/exp/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e573a8ed-ea46-4406-8f3c-e889f4dd34f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vllm_inference/\n",
      "vllm_inference/serving.properties\n",
      "vllm_inference/adapters/\n",
      "vllm_inference/adapters/exp/\n",
      "vllm_inference/adapters/exp/trainer_log.jsonl\n",
      "vllm_inference/adapters/exp/special_tokens_map.json\n",
      "vllm_inference/adapters/exp/eval_results.json\n",
      "vllm_inference/adapters/exp/README.md\n",
      "vllm_inference/adapters/exp/all_results.json\n",
      "vllm_inference/adapters/exp/adapter_model.safetensors\n",
      "vllm_inference/adapters/exp/adapter_config.json\n",
      "vllm_inference/adapters/exp/training_loss.png\n",
      "vllm_inference/adapters/exp/tokenizer.json\n",
      "vllm_inference/adapters/exp/train_results.json\n",
      "vllm_inference/adapters/exp/training_eval_loss.png\n",
      "vllm_inference/adapters/exp/tokenizer_config.json\n",
      "vllm_inference/adapters/exp/training_args.bin\n",
      "vllm_inference/adapters/exp/trainer_state.json\n",
      "vllm_inference/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!rm model.tar.gz\n",
    "!cd {local_code_dir} && rm -rf \".ipynb_checkpoints\"\n",
    "!tar czvf model.tar.gz {local_code_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e6bf418f-e299-40fb-8372-701e7a7cad06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_code_prefix: llm_finetune/llama-3-8b-qlora\n"
     ]
    }
   ],
   "source": [
    "s3_code_prefix = \"llm_finetune/llama-3-8b-qlora\"\n",
    "print(f\"s3_code_prefix: {s3_code_prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4f44d531-4dca-4b24-8a60-a4656f8b29e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-east-1-434444145045/llm_finetune/llama-3-8b-qlora/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "s3_code_artifact = sess.upload_data(\"model.tar.gz\", default_bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {s3_code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bfcd19-29fc-438e-8e03-81bae79ea020",
   "metadata": {},
   "source": [
    "### 创建SageMaker模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1c66e321-d9ae-4a42-907a-bde3e19f6d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-8b-qlora-2024-11-02-13-19-12-418\n",
      "Image going to be used is ---- > 763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.29.0-lmi11.0.0-cu124\n",
      "Created Model: arn:aws:sagemaker:us-east-1:434444145045:model/llama3-8b-qlora-2024-11-02-13-19-12-418\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "import boto3\n",
    "\n",
    "model_name = name_from_base(f\"llama3-8b-qlora\").replace('.','-').replace('_','-')\n",
    "print(model_name)\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": inference_image_uri,\n",
    "        \"ModelDataUrl\": s3_code_artifact\n",
    "    },\n",
    "    \n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab78c3a4-85b1-477f-ad77-a23e5c6f033a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 创建SageMaker端点模型配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "77e9ec38-96f8-47fc-8ac3-23257fa64f97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointConfigArn': 'arn:aws:sagemaker:us-east-1:434444145045:endpoint-config/llama3-8b-qlora-2024-11-02-13-19-12-418-config',\n",
       " 'ResponseMetadata': {'RequestId': '27361383-f26e-45d8-84e9-b0fe99b1ac9e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '27361383-f26e-45d8-84e9-b0fe99b1ac9e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '127',\n",
       "   'date': 'Sat, 02 Nov 2024 13:19:16 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "#Note: ml.g4dn.2xlarge 也可以选择\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.g5.2xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            # \"VolumeSizeInGB\" : 400,\n",
    "            # \"ModelDataDownloadTimeoutInSeconds\": 2400,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 10*60,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355233c6-79e2-4119-9d22-b44d2562ef2d",
   "metadata": {},
   "source": [
    "### 创建SageMaker端点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2c9ba70c-6465-40ac-a065-b0dd98326484",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Endpoint: arn:aws:sagemaker:us-east-1:434444145045:endpoint/llama3-8b-qlora-2024-11-02-13-19-12-418-endpoint\n"
     ]
    }
   ],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=f\"{endpoint_name}\", EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(f\"Created Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691cc7a0-d925-4238-88b1-178f190618e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 大概等到8分钟左右节点部署成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "83307f44-8971-4f48-92be-098a6eb07f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-east-1:434444145045:endpoint/llama3-8b-qlora-2024-11-02-13-19-12-418-endpoint\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11f90b8-9b58-4aeb-ad90-4ddd9cea5d9a",
   "metadata": {},
   "source": [
    "### 加载Tokenizer， 使用其chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e2d5a6bc-546e-48a5-afce-01fd002cad19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = 'TechxGenus/Meta-Llama-3-8B-Instruct-AWQ'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00d22c-cda6-4f95-8dd8-72f89b5bb8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8eac2e8-5971-45af-8c05-645bf010e816",
   "metadata": {},
   "source": [
    "## 调用SageMaker Endpoint 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f06f456f-a37b-4b2e-abc3-23d4a3199f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.69 ms, sys: 568 μs, total: 3.26 ms\n",
      "Wall time: 2.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "parameters = {\n",
    "  \"max_new_tokens\": 512,\n",
    "  \"temperature\": 0.9,\n",
    "  \"top_p\":0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "09f6715d-3bee-4557-a835-0469c3c212d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#测试第一个消息\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\":\"请始终用中文回答\"},\n",
    "     {\"role\": \"user\", \"content\": \"你是谁？\"},\n",
    "]\n",
    "\n",
    "# 测试第二个消息\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\":\"请始终用中文回答\"},\n",
    "#      {\"role\": \"user\", \"content\": \"睡觉时被女鬼压床我该怎么办？\"},\n",
    "# ]\n",
    "\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "67394413-7d67-4e8c-8a39-acbc72aa9920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        \"max_tokens\":512, \n",
    "        \"temperature\": 0.5,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea57f7e1-3d17-43e4-bfe1-4f71d6d50b9a",
   "metadata": {},
   "source": [
    "## 不使用Lora的情况下测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5f2acdc4-8301-45ff-9095-9c71272df714",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': '我是 LLaMA，一个由 Meta 开发的基于人工智能的对话系统。我可以理解和生成自然语言，帮助用户'}\n"
     ]
    }
   ],
   "source": [
    "invoke_response = smr_client.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            Body=json.dumps(\n",
    "            {\n",
    "                \"inputs\": inputs,\n",
    "                \"stream\" : False,\n",
    "                **parameters,\n",
    "            }\n",
    "            ),\n",
    "            ContentType=\"application/json\",\n",
    "            CustomAttributes='accept_eula=false'\n",
    "        )\n",
    "\n",
    "# print(invoke_response)\n",
    "print(json.loads(invoke_response[\"Body\"].read().decode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3201f5a-3b19-418a-a385-48c65e30430a",
   "metadata": {},
   "source": [
    "## 使用Lora的情况下测试\n",
    "- 通过指定 \"adapters\":\"exp\" 加载lora，如果有多个lora模型，也可以实现不同lora模型之间的切换\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7d8f3e86-758f-4648-acf5-d0861d738551",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': '您好，我是 Riverbot，一个由 Riverbot 开发的人工智能助手。我的任务是回答用户的问题并提供必要的支持'}\n"
     ]
    }
   ],
   "source": [
    "invoke_response = smr_client.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            Body=json.dumps(\n",
    "            {\n",
    "                \"inputs\": inputs,\n",
    "                \"stream\" : False,\n",
    "                 \"adapters\":\"exp\" , # Lora Adapter\n",
    "                     **parameters,\n",
    "            }\n",
    "            ),\n",
    "            ContentType=\"application/json\",\n",
    "            CustomAttributes='accept_eula=false'\n",
    "        )\n",
    "\n",
    "# print(invoke_response)\n",
    "print(json.loads(invoke_response[\"Body\"].read().decode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f30b3b3-2249-4ee7-9d4c-1565edc51e8a",
   "metadata": {},
   "source": [
    "## ！！！！实验结束之后，运行下面命令删除节点！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "635e958b-6768-4e70-a9bb-03762dc577bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws sagemaker delete-endpoint --endpoint-name {endpoint_name}\n",
    "!aws sagemaker delete-endpoint-config --endpoint-config-name {endpoint_config_name}\n",
    "!aws sagemaker delete-model --model-name {model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6b4e5-1674-4c99-a38c-ca22825ffc2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

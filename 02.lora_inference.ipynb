{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07cc3ce3-e024-4990-b6bb-d22c78514efa",
   "metadata": {},
   "source": [
    "# Using LLama Factory finetune on SageMaker \n",
    "# 2. 使用vLLM进行本地推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ce18b-d8a7-4f31-b8d6-1de1725124af",
   "metadata": {},
   "source": [
    "## 安装依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66561ea-0d2b-440c-ade2-d1820ea01e67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vllm==0.5.5\n",
      "  Downloading vllm-0.5.5-cp38-abi3-manylinux1_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.5.5) (6.0.0)\n",
      "Collecting sentencepiece (from vllm==0.5.5)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: numpy<2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.5.5) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.5.5) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.5.5) (4.66.5)\n",
      "Collecting py-cpuinfo (from vllm==0.5.5)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting transformers>=4.43.2 (from vllm==0.5.5)\n",
      "  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting tokenizers>=0.19.1 (from vllm==0.5.5)\n",
      "  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: protobuf in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.5.5) (4.25.5)\n",
      "Collecting fastapi (from vllm==0.5.5)\n",
      "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.5.5) (3.10.10)\n",
      "Collecting openai>=1.0 (from vllm==0.5.5)\n",
      "  Downloading openai-1.53.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn[standard] (from vllm==0.5.5)\n",
      "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pydantic>=2.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.5.5) (2.9.2)\n",
      "Requirement already satisfied: pillow in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.5.5) (10.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.5.5) (0.21.0)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm==0.5.5)\n",
      "  Downloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken>=0.6.0 (from vllm==0.5.5)\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting lm-format-enforcer==0.10.6 (from vllm==0.5.5)\n",
      "  Downloading lm_format_enforcer-0.10.6-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting outlines<0.1,>=0.0.43 (from vllm==0.5.5)\n",
      "  Downloading outlines-0.0.46-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.5.5) (4.12.2)\n",
      "Requirement already satisfied: filelock>=3.10.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.5.5) (3.16.1)\n",
      "Requirement already satisfied: pyzmq in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.5.5) (26.2.0)\n",
      "Collecting msgspec (from vllm==0.5.5)\n",
      "  Downloading msgspec-0.18.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting librosa (from vllm==0.5.5)\n",
      "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting soundfile (from vllm==0.5.5)\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_17_x86_64.whl.metadata (14 kB)\n",
      "Collecting gguf==0.9.1 (from vllm==0.5.5)\n",
      "  Downloading gguf-0.9.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.5.5) (6.11.0)\n",
      "Collecting ray>=2.9 (from vllm==0.5.5)\n",
      "  Downloading ray-2.38.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: nvidia-ml-py in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.5.5) (12.560.30)\n",
      "Collecting torch==2.4.0 (from vllm==0.5.5)\n",
      "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting torchvision==0.19 (from vllm==0.5.5)\n",
      "  Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "Collecting xformers==0.0.27.post2 (from vllm==0.5.5)\n",
      "  Downloading xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting vllm-flash-attn==2.6.1 (from vllm==0.5.5)\n",
      "  Downloading vllm_flash_attn-2.6.1-cp310-cp310-manylinux1_x86_64.whl.metadata (476 bytes)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.10.6->vllm==0.5.5)\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from lm-format-enforcer==0.10.6->vllm==0.5.5) (21.3)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from lm-format-enforcer==0.10.6->vllm==0.5.5) (6.0.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.4.0->vllm==0.5.5) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.4.0->vllm==0.5.5) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.4.0->vllm==0.5.5) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.4.0->vllm==0.5.5) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.4.0->vllm==0.5.5) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.4.0->vllm==0.5.5) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.4.0->vllm==0.5.5) (12.1.105)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0->vllm==0.5.5)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.4.0->vllm==0.5.5) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.4.0->vllm==0.5.5) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.4.0->vllm==0.5.5) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.4.0->vllm==0.5.5) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.4.0->vllm==0.5.5) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.4.0->vllm==0.5.5) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.4.0->vllm==0.5.5) (12.1.105)\n",
      "Collecting triton==3.0.0 (from torch==2.4.0->vllm==0.5.5)\n",
      "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->vllm==0.5.5) (12.6.77)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from openai>=1.0->vllm==0.5.5) (4.6.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.0->vllm==0.5.5)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from openai>=1.0->vllm==0.5.5) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.0->vllm==0.5.5)\n",
      "  Downloading jiter-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from openai>=1.0->vllm==0.5.5) (1.3.1)\n",
      "Collecting lark (from outlines<0.1,>=0.0.43->vllm==0.5.5)\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nest-asyncio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.5.5) (1.6.0)\n",
      "Requirement already satisfied: cloudpickle in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.5.5) (2.2.1)\n",
      "Collecting diskcache (from outlines<0.1,>=0.0.43->vllm==0.5.5)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numba in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.5.5) (0.60.0)\n",
      "Requirement already satisfied: referencing in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.5.5) (0.35.1)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.5.5) (4.23.0)\n",
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm==0.5.5) (2.21.0)\n",
      "Collecting pycountry (from outlines<0.1,>=0.0.43->vllm==0.5.5)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pyairports (from outlines<0.1,>=0.0.43->vllm==0.5.5)\n",
      "  Downloading pyairports-2.1.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting starlette<1.0.0,>=0.30.0 (from prometheus-fastapi-instrumentator>=7.0.0->vllm==0.5.5)\n",
      "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic>=2.8->vllm==0.5.5) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic>=2.8->vllm==0.5.5) (2.23.4)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ray>=2.9->vllm==0.5.5) (8.1.7)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.9->vllm==0.5.5)\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: aiosignal in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ray>=2.9->vllm==0.5.5) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ray>=2.9->vllm==0.5.5) (1.5.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken>=0.6.0->vllm==0.5.5)\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->vllm==0.5.5) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->vllm==0.5.5) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->vllm==0.5.5) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->vllm==0.5.5) (2024.8.30)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tokenizers>=0.19.1->vllm==0.5.5) (0.26.2)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.43.2->vllm==0.5.5)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->vllm==0.5.5) (2.4.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->vllm==0.5.5) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->vllm==0.5.5) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->vllm==0.5.5) (1.17.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->vllm==0.5.5) (4.0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata->vllm==0.5.5) (3.20.2)\n",
      "Collecting audioread>=2.1.9 (from librosa->vllm==0.5.5)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa->vllm==0.5.5) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa->vllm==0.5.5) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa->vllm==0.5.5) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa->vllm==0.5.5) (5.1.1)\n",
      "Collecting pooch>=1.1 (from librosa->vllm==0.5.5)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa->vllm==0.5.5)\n",
      "  Downloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting lazy-loader>=0.1 (from librosa->vllm==0.5.5)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from soundfile->vllm==0.5.5) (1.17.1)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.5.5) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]->vllm==0.5.5)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm==0.5.5)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm==0.5.5)\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm==0.5.5)\n",
      "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm==0.5.5)\n",
      "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.0->vllm==0.5.5) (1.2.2)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from cffi>=1.0->soundfile->vllm==0.5.5) (2.22)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.0->vllm==0.5.5) (1.0.5)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from numba->outlines<0.1,>=0.0.43->vllm==0.5.5) (0.43.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->lm-format-enforcer==0.10.6->vllm==0.5.5) (3.1.4)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pooch>=1.1->librosa->vllm==0.5.5) (4.3.6)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa->vllm==0.5.5) (3.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->vllm==0.5.5) (0.2.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.5.5) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.5.5) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.5.5) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.5.5) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.5.5) (0.70.16)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch==2.4.0->vllm==0.5.5) (2.1.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->outlines<0.1,>=0.0.43->vllm==0.5.5) (2023.12.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->outlines<0.1,>=0.0.43->vllm==0.5.5) (0.20.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch==2.4.0->vllm==0.5.5) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.5.5) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.5.5) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.5.5) (1.16.0)\n",
      "Downloading vllm-0.5.5-cp38-abi3-manylinux1_x86_64.whl (134.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.6/134.6 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gguf-0.9.1-py3-none-any.whl (49 kB)\n",
      "Downloading lm_format_enforcer-0.10.6-py3-none-any.whl (43 kB)\n",
      "Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading vllm_flash_attn-2.6.1-cp310-cp310-manylinux1_x86_64.whl (75.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl (20.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.53.0-py3-none-any.whl (387 kB)\n",
      "Downloading outlines-0.0.46-py3-none-any.whl (101 kB)\n",
      "Downloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading ray-2.38.0-cp310-cp310-manylinux2014_x86_64.whl (66.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.46.1-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
      "Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_17_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgspec-0.18.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading jiter-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Downloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
      "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
      "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
      "Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Downloading pyairports-2.1.1-py3-none-any.whl (371 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "Installing collected packages: sentencepiece, pyairports, py-cpuinfo, websockets, uvloop, uvicorn, triton, soxr, safetensors, regex, python-dotenv, pycountry, nvidia-cudnn-cu12, msgspec, msgpack, lark, jiter, interegular, httptools, gguf, distro, diskcache, audioread, watchfiles, tiktoken, starlette, soundfile, pooch, lazy-loader, torch, tokenizers, prometheus-fastapi-instrumentator, openai, lm-format-enforcer, librosa, fastapi, xformers, vllm-flash-attn, transformers, torchvision, ray, bitsandbytes, outlines, vllm\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.3.0\n",
      "    Uninstalling triton-2.3.0:\n",
      "      Successfully uninstalled triton-2.3.0\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
      "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.0\n",
      "    Uninstalling torch-2.3.0:\n",
      "      Successfully uninstalled torch-2.3.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.17.2\n",
      "    Uninstalling torchvision-0.17.2:\n",
      "      Successfully uninstalled torchvision-0.17.2\n",
      "Successfully installed audioread-3.0.1 bitsandbytes-0.44.1 diskcache-5.6.3 distro-1.9.0 fastapi-0.115.4 gguf-0.9.1 httptools-0.6.4 interegular-0.3.3 jiter-0.7.0 lark-1.2.2 lazy-loader-0.4 librosa-0.10.2.post1 lm-format-enforcer-0.10.6 msgpack-1.1.0 msgspec-0.18.6 nvidia-cudnn-cu12-9.1.0.70 openai-1.53.0 outlines-0.0.46 pooch-1.8.2 prometheus-fastapi-instrumentator-7.0.0 py-cpuinfo-9.0.0 pyairports-2.1.1 pycountry-24.6.1 python-dotenv-1.0.1 ray-2.38.0 regex-2024.9.11 safetensors-0.4.5 sentencepiece-0.2.0 soundfile-0.12.1 soxr-0.5.0.post1 starlette-0.41.2 tiktoken-0.8.0 tokenizers-0.20.1 torch-2.4.0 torchvision-0.19.0 transformers-4.46.1 triton-3.0.0 uvicorn-0.32.0 uvloop-0.21.0 vllm-0.5.5 vllm-flash-attn-2.6.1 watchfiles-0.24.0 websockets-13.1 xformers-0.0.27.post2\n"
     ]
    }
   ],
   "source": [
    "!pip install vllm==0.5.5 bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a58403-cdd7-495c-8539-7a44757d3d0e",
   "metadata": {},
   "source": [
    "### 从s3下载模型文件到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "411aa6cd-fb67-4a1e-a397-2082c87ade0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import sagemaker\n",
    "sagemaker_session =  sagemaker.session.Session() #sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d2eafc8-a6b3-49d0-9dee-349243e3888a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/adapter_config.json to local_model/finetuned_model/adapter_config.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/README.md to local_model/finetuned_model/README.md\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/all_results.json to local_model/finetuned_model/all_results.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/README.md to local_model/finetuned_model/checkpoint-500/README.md\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/rng_state.pth to local_model/finetuned_model/checkpoint-500/rng_state.pth\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/adapter_config.json to local_model/finetuned_model/checkpoint-500/adapter_config.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/scheduler.pt to local_model/finetuned_model/checkpoint-500/scheduler.pt\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/special_tokens_map.json to local_model/finetuned_model/checkpoint-500/special_tokens_map.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/tokenizer_config.json to local_model/finetuned_model/checkpoint-500/tokenizer_config.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/tokenizer.json to local_model/finetuned_model/checkpoint-500/tokenizer.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/training_args.bin to local_model/finetuned_model/checkpoint-500/training_args.bin\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/trainer_state.json to local_model/finetuned_model/checkpoint-500/trainer_state.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/adapter_config.json to local_model/finetuned_model/checkpoint-96/adapter_config.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/README.md to local_model/finetuned_model/checkpoint-96/README.md\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/adapter_model.safetensors to local_model/finetuned_model/adapter_model.safetensors\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/rng_state.pth to local_model/finetuned_model/checkpoint-96/rng_state.pth\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/scheduler.pt to local_model/finetuned_model/checkpoint-96/scheduler.pt\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/adapter_model.safetensors to local_model/finetuned_model/checkpoint-500/adapter_model.safetensors\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/special_tokens_map.json to local_model/finetuned_model/checkpoint-96/special_tokens_map.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/tokenizer_config.json to local_model/finetuned_model/checkpoint-96/tokenizer_config.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/trainer_state.json to local_model/finetuned_model/checkpoint-96/trainer_state.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/tokenizer.json to local_model/finetuned_model/checkpoint-96/tokenizer.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/training_args.bin to local_model/finetuned_model/checkpoint-96/training_args.bin\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/eval_results.json to local_model/finetuned_model/eval_results.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/runs/Jun05_16-14-18_algo-1/events.out.tfevents.1717604084.algo-1.259.0 to local_model/finetuned_model/runs/Jun05_16-14-18_algo-1/events.out.tfevents.1717604084.algo-1.259.0\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/adapter_model.safetensors to local_model/finetuned_model/checkpoint-96/adapter_model.safetensors\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/runs/Nov02_11-30-44_algo-1-une3w/events.out.tfevents.1730547055.algo-1-une3w.353.0 to local_model/finetuned_model/runs/Nov02_11-30-44_algo-1-une3w/events.out.tfevents.1730547055.algo-1-une3w.353.0\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/runs/Jun05_16-14-18_algo-1/events.out.tfevents.1717607995.algo-1.259.1 to local_model/finetuned_model/runs/Jun05_16-14-18_algo-1/events.out.tfevents.1717607995.algo-1.259.1\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/special_tokens_map.json to local_model/finetuned_model/special_tokens_map.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/tokenizer_config.json to local_model/finetuned_model/tokenizer_config.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/train_results.json to local_model/finetuned_model/train_results.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/training_args.bin to local_model/finetuned_model/training_args.bin\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/trainer_state.json to local_model/finetuned_model/trainer_state.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/trainer_log.jsonl to local_model/finetuned_model/trainer_log.jsonl\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/training_loss.png to local_model/finetuned_model/training_loss.png\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/training_eval_loss.png to local_model/finetuned_model/training_eval_loss.png\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/tokenizer.json to local_model/finetuned_model/tokenizer.json\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-500/optimizer.pt to local_model/finetuned_model/checkpoint-500/optimizer.pt\n",
      "download: s3://sagemaker-us-east-1-434444145045/llama3-8b-qlora/finetuned_model/checkpoint-96/optimizer.pt to local_model/finetuned_model/checkpoint-96/optimizer.pt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync s3://{default_bucket}/llama3-8b-qlora/ ./local_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efb1132-2f03-4ee8-82c7-1c5aad5cad24",
   "metadata": {},
   "source": [
    "## 加载模型tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff8d2745-b522-4f24-98fc-544c59981a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb0dda29-eace-4024-baa9-a31cbe38e6a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = 'TechxGenus/Meta-Llama-3-8B-Instruct-AWQ'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb16486-c28d-4f1a-8252-b65228d191c3",
   "metadata": {},
   "source": [
    "## 加载sample数据，用于对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce41018c-4d78-421b-a989-8a1cd08001c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from random import randrange\n",
    "# dataset_name = \"zxbsmk/webnovel_cn\"\n",
    "dataset_name = \"hfl/ruozhiba_gpt4\"\n",
    "# Load dataset from the hub\n",
    "train_dataset = load_dataset(dataset_name, split=\"train\",revision='41d2c61beb86c8d4c61916cc656c39d018c40ce5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cc42343-da60-47a7-a3c7-5e35bf63c2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 4898\n",
      "\n",
      "Training sample:\n",
      "\n",
      "{'input': '', 'instruction': '既然高考是看排名的，那大家为什么不都考0分呢? 这样人人都有大学上了', 'output': '这个提议存在一个根本性的逻辑错误。如果所有考生都考0分，高考的基本功能就失去了，因为高考的排名机制是为了区分不同学生的学术能力，以便分配教育资源。如果大家都考0分，无法区分谁有资格上大学，也没法合理分配教育资源。此外，大学的学习难度和要求也需要一定的基础知识，如果入学没有任何学术依据，学生在大学的学习中很难跟上课程。因此，0分的想法实际上是对高考制度和教育体系严重误解，不可能实现人人都上大学的目标。'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Training size: {len(train_dataset)}\")\n",
    "print(\"\\nTraining sample:\\n\")\n",
    "num_samples = 200\n",
    "print(train_dataset[randrange(num_samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86b51667-4bda-49b3-8453-b6602fc650c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_lora_path = './local_model/finetuned_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a54f14-bc6b-4536-af7e-3f402773fb98",
   "metadata": {},
   "source": [
    "## 使用本地的vLLM部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb9259ec-03be-46bf-a7bc-b558b5f4d23f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vllm.lora.request import LoRARequest\n",
    "from vllm import LLM,SamplingParams\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b590cc15-e64f-4da2-abe2-ff42640cab80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = 'TechxGenus/Meta-Llama-3-8B-Instruct-AWQ'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39cf9c61-4c9c-49af-baac-01aaabf695cd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c8bec6ea30476086dbafff8b5d4d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/885 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-02 11:44:10 awq_marlin.py:89] The model is convertible to awq_marlin during runtime. Using awq_marlin kernel.\n",
      "WARNING 11-02 11:44:10 config.py:1451] awq_marlin quantization is not tested with LoRA yet.\n",
      "INFO 11-02 11:44:10 llm_engine.py:184] Initializing an LLM engine (v0.5.5) with config: model='TechxGenus/Meta-Llama-3-8B-Instruct-AWQ', speculative_config=None, tokenizer='TechxGenus/Meta-Llama-3-8B-Instruct-AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq_marlin, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=TechxGenus/Meta-Llama-3-8B-Instruct-AWQ, use_v2_block_manager=False, enable_prefix_caching=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98bed2b1c62f4cc4810aea4414908e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/152 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-02 11:44:11 model_runner.py:879] Starting to load model TechxGenus/Meta-Llama-3-8B-Instruct-AWQ...\n",
      "INFO 11-02 11:44:11 weight_utils.py:236] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331e0f1e71f24b7091bf57c5402bfbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8d2cd479af4717aae657989a62f50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a98508539e4fdbaf116eab941be742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/63.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79a9620d68744f5ac22269aa7e7cfbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-02 11:51:42 model_runner.py:890] Loading model weights took 5.3492 GB\n",
      "INFO 11-02 11:51:52 gpu_executor.py:121] # GPU blocks: 6466, # CPU blocks: 2048\n",
      "INFO 11-02 11:51:54 model_runner.py:1181] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 11-02 11:51:54 model_runner.py:1185] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 11-02 11:52:20 model_runner.py:1300] Graph capturing finished in 26 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=model_id,max_model_len=4096,enable_lora=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26f3ac73-dea3-413c-957a-dc9a615285e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#测试第一个消息\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\":\"请始终用中文回答\"},\n",
    "     {\"role\": \"user\", \"content\": \"你是谁？你是干嘛的\"},\n",
    "]\n",
    "\n",
    "#测试第二个消息\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\":\"请始终用中文回答\"},\n",
    "#      {\"role\": \"user\", \"content\": \"睡觉时被女鬼压床我该怎么办？\"},\n",
    "# ]\n",
    "\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9236a21c-ce2b-4be6-8ee6-b669dd7a266d",
   "metadata": {},
   "source": [
    "### 使用原始模型进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86d0f474-83bb-4a03-b2bd-b2c4e3c998b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.80s/it, est. speed input: 16.64 toks/s, output: 71.53 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n请始终用中文回答<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n你是谁？你是干嘛的<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'\n",
      "Response:\n",
      "'我是 LLaMA，一个由 Meta AI 开发的语言模型。我是一个人工智能语言模型，旨在与用户交谈，回答问题，提供信息和帮助。我的能力包括：\\n\\n* 回答问题：我可以回答各种问题，包括历史、科学、技术、文化、娱乐等领域。\\n* 提供信息：我可以提供相关信息，帮助用户了解某个主题或问题。\\n* 对话：我可以与用户进行对话，回答问题，提供建议和帮助。\\n\\n我是一个机器人，旨在帮助用户获取信息，解决问题和提高语言能力。'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sampling_params = SamplingParams(temperature=0.1, top_p=0.95,max_tokens=512)\n",
    "\n",
    "outputs = llm.generate(inputs, sampling_params)\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt:\\n{prompt!r}\")\n",
    "    print(f\"Response:\\n{generated_text!r}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009c25a2-449e-4af5-b1c8-873c92ad9243",
   "metadata": {},
   "source": [
    "### 加载Lora进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43a3463f-d618-47ec-a618-89719b210134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_lora_path = './local_model/finetuned_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95db9394-c997-48ce-92c3-33381e837833",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29027/343688066.py:1: DeprecationWarning: The 'lora_local_path' attribute is deprecated and will be removed in a future version. Please use 'lora_path' instead.\n",
      "  outputs = llm.generate(inputs, sampling_params,lora_request=LoRARequest(\"adapter\", 1, sql_lora_path))\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s, est. speed input: 42.50 toks/s, output: 56.67 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n请始终用中文回答<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n你是谁？你是干嘛的<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'\n",
      "Response:\n",
      "'您好，我是 Riverbot，一个由 Riverbot 开发的人工智能助手。我可以回答各种问题、提供信息和解决方案，帮助用户解决问题和满足需求。'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = llm.generate(inputs, sampling_params,lora_request=LoRARequest(\"adapter\", 1, sql_lora_path))\n",
    "\n",
    "# Print the outputs.\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt:\\n{prompt!r}\")\n",
    "    print(f\"Response:\\n{generated_text!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ce7ba-6ff2-45b7-ba9a-ef909a590d68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

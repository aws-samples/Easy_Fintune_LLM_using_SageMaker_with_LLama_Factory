{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80cb756b-391c-4fe1-b4cd-a38b9c0ad880",
   "metadata": {},
   "source": [
    "# Using LLama Factory finetune on SageMaker - HyperPod 集群\n",
    "# 5. HyperPod集群环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d229515a-2141-416d-90f4-36f5960901a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.32.101 requires botocore==1.34.101, but you have botocore 1.34.123 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -Uq sagemaker boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4eacae63-dc24-476c-904b-5ff99d8b22dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8e47a8ad-bf79-4c97-a2f7-17d34652c147",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::434444145045:role/notebook-hyperpod-ExecutionRole-xHaRX2L05qHQ\n",
      "sagemaker bucket: sagemaker-us-west-2-434444145045\n",
      "sagemaker session region: us-west-2\n",
      "boto3 version: 1.34.122\n",
      "sagemaker version: 2.222.0\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "print(f\"boto3 version: {boto3.__version__}\")\n",
    "print(f\"sagemaker version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b367fd2-52f2-4c23-91b3-9862e5be671f",
   "metadata": {},
   "source": [
    "## 1. 创建HyperPod集群\n",
    "### 1.1 把lifecycle配置文件上传到 S3 存储桶。在创建集群期间，在每个实例组中 HyperPod 运行它们。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31ed44-2608-4a72-ab58-f99f347bb72e",
   "metadata": {},
   "source": [
    "- 写一个 Slurm 配置文件并将其另存为provisioning_parameters.json。在文件中，指定基本的 Slurm 配置参数，以便将 Slurm 节点正确分配给集群实例组。 \n",
    "- 本教程中，设置2个名为\n",
    "    - my-controller-group、\n",
    "    - worker-group-1，\n",
    "- 如以下示例配置所示。provisioning_parameters.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5d96d90a-ea6d-4219-98b5-51846ccbf5a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_code_dir = 'lifecycle-scripts'\n",
    "!rm -rf {local_code_dir}\n",
    "!mkdir -p {local_code_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b12db07f-1efd-4352-bcfa-4f6dac1c16ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lifecycle-scripts/provisioning_parameters.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile {local_code_dir}/provisioning_parameters.json\n",
    "{\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"workload_manager\": \"slurm\",\n",
    "    \"controller_group\": \"my-controller-group\",\n",
    "    \"worker_groups\": [\n",
    "        {\n",
    "            \"instance_group_name\": \"worker-group-1\",\n",
    "            \"partition_name\": \"partition-1\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8bd53c15-25c9-49b7-a8e5-360cd206c7bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf {local_code_dir}/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3dfffa-32b7-446c-a842-42962e3248db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a575194-7d1a-4ccf-a03a-a6228ec5fcf9",
   "metadata": {},
   "source": [
    "### 1.2 将awsome-distributed-training/中的sample配置文件和provisioning_params.json 上传到s3目录中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "43d4ded6-b365-42e7-8e4e-88ffadb16efc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/config.py to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/config.py\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/add_users.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/add_users.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/apply_hotfix.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/apply_hotfix.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/hotfix/hold-lustre-client.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/hotfix/hold-lustre-client.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/initsmhp/fix-profile.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/initsmhp/fix-profile.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/initsmhp.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/initsmhp.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/initsmhp/gen-keypair-ubuntu.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/initsmhp/gen-keypair-ubuntu.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/initsmhp/howto-miniconda.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/initsmhp/howto-miniconda.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/initsmhp/install-git-remote-codecommit.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/initsmhp/install-git-remote-codecommit.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/initsmhp/install-mount-s3.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/initsmhp/install-mount-s3.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/initsmhp/ssh-to-compute.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/initsmhp/ssh-to-compute.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/mount_fsx.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/mount_fsx.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/on_create.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/on_create.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/hotfix/mock-gpu-driver-deb.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/hotfix/mock-gpu-driver-deb.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/setup_mariadb_accounting.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/setup_mariadb_accounting.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/initsmhp/install-pkgs.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/initsmhp/install-pkgs.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/shared_users_sample.txt to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/shared_users_sample.txt\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/lifecycle_script.py to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/lifecycle_script.py\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/setup_sssd.py to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/setup_sssd.py\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/setup_rds_accounting.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/setup_rds_accounting.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/utils/fsx_ubuntu.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/utils/fsx_ubuntu.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/utils/enroot.conf to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/utils/enroot.conf\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/start_slurm.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/start_slurm.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/utils/install_dcgm_exporter.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/utils/install_dcgm_exporter.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/utils/install_docker.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/utils/install_docker.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/utils/install_enroot_pyxis.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/utils/install_enroot_pyxis.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/utils/install_head_node_exporter.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/utils/install_head_node_exporter.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/utils/install_efa_node_exporter.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/utils/install_efa_node_exporter.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/utils/motd.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/utils/motd.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/utils/motd.txt to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/utils/motd.txt\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/utils/install_slurm_exporter.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/utils/install_slurm_exporter.sh\n",
      "upload: awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/utils/install_prometheus.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/utils/install_prometheus.sh\n",
      "upload: lifecycle-scripts/provisioning_parameters.json to s3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts/provisioning_parameters.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/ s3://{bucket}/hyperpod/LifecycleScripts/\n",
    "!aws s3 cp --recursive lifecycle-scripts/ s3://{bucket}/hyperpod/LifecycleScripts/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d40cbc-a80d-4016-be69-1522a0286dd2",
   "metadata": {},
   "source": [
    "### 1.3 准备一个 create_cluster.json 文件，用于CreateCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "64e7334e-cb32-481a-b361-4dd5ca618f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a75839df-a0f1-4544-9903-5bd3fda88559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_name = \"hyperpod-cluster-1\"\n",
    "SourceS3Uri = f\"s3://{bucket}/hyperpod/LifecycleScripts\"\n",
    "worker_instance = \"ml.c5.2xlarge\"\n",
    "worker_count = 2\n",
    "create_cluster = \\\n",
    "{\n",
    "    \"ClusterName\": cluster_name,\n",
    "    \"InstanceGroups\": [\n",
    "        {\n",
    "            \"InstanceGroupName\": \"my-controller-group\",\n",
    "            \"InstanceType\": \"ml.c5.xlarge\",\n",
    "            \"InstanceCount\": 1,\n",
    "            \"LifeCycleConfig\": {\n",
    "              \"SourceS3Uri\": SourceS3Uri,\n",
    "              \"OnCreate\": \"on_create.sh\"\n",
    "            },\n",
    "            \"ExecutionRole\": role,\n",
    "            \"ThreadsPerCore\": 1\n",
    "        },\n",
    "        {\n",
    "            \"InstanceGroupName\": \"worker-group-1\",\n",
    "            \"InstanceType\": worker_instance,\n",
    "            \"InstanceCount\": worker_count,\n",
    "            \"LifeCycleConfig\": {\n",
    "              \"SourceS3Uri\": SourceS3Uri,\n",
    "              \"OnCreate\": \"on_create.sh\"\n",
    "            },\n",
    "            \"ExecutionRole\": role,\n",
    "            \"ThreadsPerCore\": 1\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fba24770-ae78-41da-91e7-b76c57767369",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ClusterName': 'hyperpod-cluster-1',\n",
       " 'InstanceGroups': [{'InstanceGroupName': 'my-controller-group',\n",
       "   'InstanceType': 'ml.c5.xlarge',\n",
       "   'InstanceCount': 1,\n",
       "   'LifeCycleConfig': {'SourceS3Uri': 's3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts',\n",
       "    'OnCreate': 'on_create.sh'},\n",
       "   'ExecutionRole': 'arn:aws:iam::434444145045:role/notebook-hyperpod-ExecutionRole-xHaRX2L05qHQ',\n",
       "   'ThreadsPerCore': 1},\n",
       "  {'InstanceGroupName': 'worker-group-1',\n",
       "   'InstanceType': 'ml.c5.2xlarge',\n",
       "   'InstanceCount': 2,\n",
       "   'LifeCycleConfig': {'SourceS3Uri': 's3://sagemaker-us-west-2-434444145045/hyperpod/LifecycleScripts',\n",
       "    'OnCreate': 'on_create.sh'},\n",
       "   'ExecutionRole': 'arn:aws:iam::434444145045:role/notebook-hyperpod-ExecutionRole-xHaRX2L05qHQ',\n",
       "   'ThreadsPerCore': 1}]}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"create_cluster.json\",\"w\") as f:\n",
    "    json.dump(create_cluster,f)\n",
    "create_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70cea5e-51a9-4255-86dc-90e56da05524",
   "metadata": {},
   "source": [
    "### 1.4 Validate the JSON configuration files before creating a Slurm cluster on HyperPod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "54e2f1d1-5be6-4d06-b759-aa92f1c69602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python3 awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/validate-config.py --cluster-config create_cluster.json --provisioning-parameters {local_code_dir}/provisioning_parameters.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c725748a-34ff-4cdf-902a-f8f73b20b09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19685c64-8b45-4a67-bfd2-dccf4511aaaa",
   "metadata": {},
   "source": [
    "### 1.5 运行以下命令来创建集群。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e88692a0-84f7-4098-b067-ede118047549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ClusterArn\": \"arn:aws:sagemaker:us-west-2:434444145045:cluster/lufsrbfh2k78\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker create-cluster --cli-input-json file://~/SageMaker/llm_finetune/create_cluster.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d05ba76-fcdc-4efa-a346-3fc77794a195",
   "metadata": {},
   "source": [
    "### 1.6 持续检测集群部署进度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ead39593-a977-46d1-a602-dcf4b4d0d3d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "sm_client = boto3.client(\"sagemaker\")  # client to intreract with SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "abeb2cbb-be37-4b9f-bf34-8eecbb5f9c78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: InService\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resp = sm_client.describe_cluster(\n",
    "    ClusterName=cluster_name\n",
    ")\n",
    "status = resp[\"ClusterStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_cluster(\n",
    "        ClusterName=cluster_name\n",
    "    )\n",
    "    status = resp[\"ClusterStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"ClusterStatus\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3248a9d7-9f1d-4404-9575-740f5bd30c16",
   "metadata": {},
   "source": [
    "### 1.7 列出集群node信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d12935a6-197a-4dc7-98aa-abd0d2b9ef31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ClusterSummaries\": [\n",
      "        {\n",
      "            \"ClusterArn\": \"arn:aws:sagemaker:us-west-2:434444145045:cluster/lufsrbfh2k78\",\n",
      "            \"ClusterName\": \"hyperpod-cluster-1\",\n",
      "            \"CreationTime\": 1718116220.42,\n",
      "            \"ClusterStatus\": \"InService\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"ClusterNodeSummaries\": [\n",
      "        {\n",
      "            \"InstanceGroupName\": \"my-controller-group\",\n",
      "            \"InstanceId\": \"i-00a9b6904d395124d\",\n",
      "            \"InstanceType\": \"ml.c5.xlarge\",\n",
      "            \"LaunchTime\": 1718116227.781,\n",
      "            \"InstanceStatus\": {\n",
      "                \"Status\": \"Running\",\n",
      "                \"Message\": \"\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"InstanceGroupName\": \"worker-group-1\",\n",
      "            \"InstanceId\": \"i-076e276ccf232112e\",\n",
      "            \"InstanceType\": \"ml.c5.2xlarge\",\n",
      "            \"LaunchTime\": 1718116229.03,\n",
      "            \"InstanceStatus\": {\n",
      "                \"Status\": \"Running\",\n",
      "                \"Message\": \"\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"InstanceGroupName\": \"worker-group-1\",\n",
      "            \"InstanceId\": \"i-0b2b3b8af708b5d90\",\n",
      "            \"InstanceType\": \"ml.c5.2xlarge\",\n",
      "            \"LaunchTime\": 1718116229.03,\n",
      "            \"InstanceStatus\": {\n",
      "                \"Status\": \"Running\",\n",
      "                \"Message\": \"\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker list-clusters\n",
    "!aws sagemaker list-cluster-nodes --cluster-name {cluster_name} --region us-west-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59254343-1d47-44bc-8964-c775b6493972",
   "metadata": {},
   "source": [
    "### 1.8 使用awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/easy-ssh.sh 快速登录"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb799d-837d-4a80-9889-2d9695972d92",
   "metadata": {},
   "source": [
    "1. 打开notebook上的终端terminal\n",
    "2. 安装ssm plugin\n",
    "```bash\n",
    "sudo yum install -y https://s3.amazonaws.com/session-manager-downloads/plugin/latest/linux_64bit/session-manager-plugin.rpm\n",
    "\n",
    "```\n",
    "\n",
    "3. 拷贝easy-ssh.sh到当前用户目录\n",
    "```bash\n",
    "cp awsome-distributed-training/1.architectures/5.sagemaker-hyperpod/easy-ssh.sh ./\n",
    "```\n",
    "\n",
    "4. 登录工作节点\n",
    "```bash\n",
    "chmod +x easy-ssh.sh \n",
    "cluster_name=hyperpod-cluster-1\n",
    "group=worker-group-1\n",
    "./easy-ssh.sh $cluster_name --controller-group $group\n",
    "```\n",
    "\n",
    "5. 登录进入之后，切换到ubuntu用户,运行sinfo查看当前集群状态\n",
    "```bash\n",
    "sudo su ubuntu\n",
    "sinfo\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b4361c-fe36-4b4c-b5c0-c85c3c80133f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. 上传训练脚本到S3 bucket中，之后S3 bucket会挂载到集群所有节点中，这样所有计算节点都可以访问训练代码和数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b156397c-155c-4c3e-bba3-02005d6e6584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d72916b1-361a-4544-8ee6-6765b20a3680",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: hyperpod-scripts/.ipynb_checkpoints/llama_factory_setup-checkpoint.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/.ipynb_checkpoints/llama_factory_setup-checkpoint.sh\n",
      "upload: hyperpod-scripts/train_batch.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/train_batch.sh\n",
      "upload: hyperpod-scripts/llama_factory_setup.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/llama_factory_setup.sh\n",
      "upload: hyperpod-scripts/train_multi_ds.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/train_multi_ds.sh\n",
      "upload: hyperpod-scripts/train_single_lora.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/train_single_lora.sh\n",
      "upload: hyperpod-scripts/.ipynb_checkpoints/train_single_lora-checkpoint.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/.ipynb_checkpoints/train_single_lora-checkpoint.sh\n"
     ]
    }
   ],
   "source": [
    "!./s5cmd sync ./LLaMA-Factory s3://{bucket}/hyperpod/\n",
    "!aws s3 cp --recursive hyperpod-scripts/ s3://{bucket}/hyperpod/LLaMA-Factory/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2cd06e-6ad2-4527-a507-b25614317b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9782ab3-eb9a-49e2-980f-a19ab9a83417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb1dde5-7633-4a8f-b605-33a05b19da1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec0a1bb4-04b4-4a6c-a519-7789a95dce67",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. 挂载S3\n",
    "- Hyperpod 集群特别适合大规模集群分布式训练，由于其提供了底层 IaaS 基础设施的接入，因此可以方便的使用业界流行的各种分布式框架，如 accelerate，Deepspeed…etc。\n",
    "- 与 EC2 实例一样，Hyperpod 集群实例上可以挂载各种共享存储，如 EFS，Lustre，S3 等，此处我们以 mount-s3 为例。\n",
    "- mount-s3 共享存储安装及挂载脚本示例：\n",
    "- 仍然ssh到集群中执行\n",
    "```bash\n",
    "###下载 s3mount\n",
    "cd ~\n",
    "\n",
    "srun -N2 \"wget\" \"https://s3.amazonaws.com/mountpoint-s3-release/latest/x86_64/mount-s3.deb\"\n",
    "srun -N2 sudo apt-get install -y  ./mount-s3.deb\n",
    "\n",
    "\n",
    "# 挂载到\"~/mnt\" 中， 注意实验中只用了1个计算节点，所以N 1,如果是多节点，则>1\n",
    "srun -N2 \"sudo\" \"mkdir\" \"/home/ubuntu/mnt\" \n",
    "\n",
    "#在所有节点上挂载，注意region，account-id替换成您自己的aws region和 account id\n",
    "srun -N2 \"sudo\" \"mount-s3\" \"--allow-other\" \"--allow-overwrite\"   \"sagemaker-us-west-2-434444145045\" \"/home/ubuntu/mnt\" \n",
    "\n",
    "# unmount s3\n",
    "# srun -N1 \"sudo\" \"umount\" \"/home/ubuntu/mnt\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654c8032-f063-4091-8e53-0b9d178eea25",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. 在集群上安装LLaMA-Factory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1b689-02d7-45f5-a4dc-7ac9251aea61",
   "metadata": {},
   "source": [
    "1. 仍然保持登录到集群节点中，如果session expired，请参考以上的登录方法\n",
    "```bash\n",
    "chmod +x easy-ssh.sh \n",
    "cluster_name=hyperpod-cluster-1\n",
    "group=worker-group-1\n",
    "./easy-ssh.sh $cluster_name --controller-group $group\n",
    "```\n",
    "\n",
    "2. 把S3 bucket的目录下的代码copy到本地目录\n",
    "```bash\n",
    "sudo su ubuntu\n",
    "cd ~\n",
    "srun -N2 \"cp\" \"-r\" \"mnt/hyperpod/LLaMA-Factory\" \"LLaMA-Factory\"\n",
    "```\n",
    "\n",
    "3. 执行按照脚本\n",
    "```bash\n",
    "cd LLaMA-Factory\n",
    "srun -N2 \"rm\" \"-rf\" \"../miniconda3\"\n",
    "srun -N2 \"rm\" \"-rf\" \"Miniconda3-latest*\"\n",
    "srun -N2 \"bash\" \"llama_factory_setup.sh\" \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01636c65-32b8-4d5e-886a-3d20ffb40701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e15e4-25f9-45a4-bfd0-524827f01380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab73ec8-ee67-476f-93fd-85572b8a4d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f72f729b-f91f-4720-afb1-4aba446311a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 删除集群\n",
    "\n",
    "# !aws sagemaker delete-cluster --cluster-name hyperpod-cluster-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d5cf2a-c660-4fab-81a4-cd1c287b752b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

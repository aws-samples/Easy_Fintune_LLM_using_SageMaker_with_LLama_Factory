{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LLama Factory finetune on SageMaker - Multi Nodes\n",
    "# 4. 使用SageMaker Training Job分布式训练\n",
    "- 本示例使用deepspeed进行多机多GPU卡分布式训练\n",
    "- 如果指定instance数量为1，则是单机多GPU训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Pre-requisites 安装依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.32.101 requires botocore==1.34.101, but you have botocore 1.34.122 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq sagemaker boto3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import boto3\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import sagemaker\n",
    "from sagemaker.collection import Collection\n",
    "from sagemaker.utils import name_from_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session =  sagemaker.session.Session() #sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "sm_client = boto3.client('sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据集\n",
    "### 数据集1. 从huggingface上下载ruozhiba数据集\n",
    "- 该数据集有近5k条数据，本次实验我们可以只用前1k条做训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 4898\n",
      "\n",
      "Training sample:\n",
      "\n",
      "{'output': '虽然几何上两点之间的直线最短，但在现实生活中，其他因素也需要考虑。自由落体运动虽然能在最短时间内从高处下到低处，但由于重力加速度的作用，会产生巨大冲击力，导致严重的身体伤害甚至死亡。为保证安全，人们通常选择使用楼梯或电梯等缓解重力加速度的方法下楼。所以，从实用和安全角度出发，走楼梯或用电梯是更合适的选择，而不是实行自由落体运动。', 'input': '', 'instruction': '总所周知，两点之间线段最短 那么人下楼为什么要走楼梯而不做自由落体运动呢？'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from random import randrange\n",
    "dataset_name = \"hfl/ruozhiba_gpt4\"\n",
    "# Load dataset from the hub\n",
    "train_dataset = load_dataset(dataset_name, split=\"train\",revision='41d2c61beb86c8d4c61916cc656c39d018c40ce5')\n",
    "\n",
    "print(f\"Training size: {len(train_dataset)}\")\n",
    "print(\"\\nTraining sample:\\n\")\n",
    "print(train_dataset[randrange(len(train_dataset))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'output': '这个问题是针对《海绵宝宝》中的蟹老板和他的快餐店“蟹堡王”的情节。在动画中，蟹黄堡是蟹堡王里最受欢迎的食品，但是具体配方是保密的。虽然蟹老板是一只蟹，但是该动画并未明确指出蟹黄堡是使用蟹肉制作的。事实上，这更多是一种戏剧化的设定，用来增加情节的幽默感。因此，从字面上来理解蟹老板制作蟹黄堡吃掉同类是不正确的，这只是一种讽刺的艺术表现手法，旨在娱乐观众而已。', 'input': '', 'instruction': '为什么蟹老板做蟹黄堡蚕食它的同类？'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集2. 身份数据集\n",
    "```json\n",
    "[{'instruction': 'hi',\n",
    "  'input': '',\n",
    "  'output': 'Hello! I am {{name}}, an AI assistant developed by {{author}}. How can I assist you today?'},\n",
    " {'instruction': 'hello',\n",
    "  'input': '',\n",
    "  'output': 'Hello! I am {{name}}, an AI assistant developed by {{author}}. How can I assist you today?'},\n",
    " {'instruction': 'Who are you?',\n",
    "  'input': '',\n",
    "  'output': 'I am {{name}}, an AI assistant developed by {{author}}. How can I assist you today?'}]\n",
    "```\n",
    "把其中的name和author替换成您自己想替换的值，这样微调完成之后，问模型“你是谁，谁创造的你？”这类的身份问题，模型就会按这个新的值来回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_identity(origin_obj,name,author):\n",
    "    ret = []\n",
    "    for ele in origin_obj:\n",
    "        ele['output'] = ele['output'].replace(\"{{name}}\",name).replace(\"{{author}}\",author)\n",
    "        ret.append(ele)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 替换成您自己的设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NAME = 'RiverBot'\n",
    "AUTHOR = 'GOGOGO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'hi',\n",
       "  'input': '',\n",
       "  'output': 'Hello! I am RiverBot, an AI assistant developed by River. How can I assist you today?'},\n",
       " {'instruction': 'hello',\n",
       "  'input': '',\n",
       "  'output': 'Hello! I am RiverBot, an AI assistant developed by River. How can I assist you today?'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "file_name = './LLaMA-Factory/data/identity.json'\n",
    "with open(file_name) as f:\n",
    "    identity = json.load(f)\n",
    "\n",
    "identity_2 = format_identity(identity,name='RiverBot',author='River')\n",
    "identity_2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('./train',exist_ok=True)\n",
    "with open('./train/identity_2.json','w') as f:\n",
    "    json.dump(identity_2,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把数据copy至S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_data_uri = f\"s3://{default_bucket}/dataset-for-training\"\n",
    "training_input_path = f'{s3_data_uri}/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5a66e98c1f49ea9c18c7d7a9af8d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving training dataset to: s3://sagemaker-us-west-2-434444145045/dataset-for-training/train\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3\n",
    "train_dataset.to_json('./train/ruozhiba.json')\n",
    "sagemaker.s3.S3Uploader.upload(local_path=\"./train/ruozhiba.json\", desired_s3_uri=training_input_path, sagemaker_session=sagemaker_session)\n",
    "sagemaker.s3.S3Uploader.upload(local_path=\"./train/identity_2.json\", desired_s3_uri=training_input_path, sagemaker_session=sagemaker_session)\n",
    "\n",
    "print(f\"saving training dataset to: {training_input_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备LLaMA-Factory 的 dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "file_name = './LLaMA-Factory/data/dataset_info.json'\n",
    "with open(file_name) as f:\n",
    "    datainfo = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datainfo['identity']={'file_name': 'identity_2.json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datainfo['ruozhiba']={\n",
    "    'file_name':'ruozhiba.json',\n",
    "    \"columns\": {\n",
    "    \"prompt\": \"instruction\",\n",
    "    \"query\": \"input\",\n",
    "    \"response\": \"output\",\n",
    "  }      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./LLaMA-Factory/data/dataset_info.json','w') as f:\n",
    "    json.dump(fp=f,obj=datainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备LLaMA-Factory 的 训练配置yaml文件\n",
    "### 从LLaMA-Factory/examples/train_lora/目录中复制出llama3_lora_sft_ds3.yaml，并修改\n",
    "- 本次实验是使用Lora训练\n",
    "- 如果用全量微调，则使用LLaMA-Factory/examples/train_lora/llama3_lora_sft_ds3.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name_or_path': 'meta-llama/Meta-Llama-3-8B-Instruct',\n",
       " 'stage': 'sft',\n",
       " 'do_train': True,\n",
       " 'finetuning_type': 'lora',\n",
       " 'lora_target': 'all',\n",
       " 'deepspeed': 'examples/deepspeed/ds_z3_config.json',\n",
       " 'dataset': 'identity,alpaca_en_demo',\n",
       " 'template': 'llama3',\n",
       " 'cutoff_len': 1024,\n",
       " 'max_samples': 1000,\n",
       " 'overwrite_cache': True,\n",
       " 'preprocessing_num_workers': 16,\n",
       " 'output_dir': 'saves/llama3-8b/lora/sft',\n",
       " 'logging_steps': 10,\n",
       " 'save_steps': 500,\n",
       " 'plot_loss': True,\n",
       " 'overwrite_output_dir': True,\n",
       " 'per_device_train_batch_size': 1,\n",
       " 'gradient_accumulation_steps': 2,\n",
       " 'learning_rate': 0.0001,\n",
       " 'num_train_epochs': 3.0,\n",
       " 'lr_scheduler_type': 'cosine',\n",
       " 'warmup_ratio': 0.1,\n",
       " 'fp16': True,\n",
       " 'ddp_timeout': 180000000,\n",
       " 'val_size': 0.1,\n",
       " 'per_device_eval_batch_size': 1,\n",
       " 'eval_strategy': 'steps',\n",
       " 'eval_steps': 500}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load template\n",
    "import yaml\n",
    "file_name = './LLaMA-Factory/examples/train_lora/llama3_lora_sft_ds3.yaml'\n",
    "with open(file_name) as f:\n",
    "    doc = yaml.safe_load(f)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本次实验我们使用原始精度的LLaMA-3-8b， 从hf的repo 'unsloth/llama-3-8b-Instruct' 下载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = 'unsloth/llama-3-8b-Instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name_or_path': 'unsloth/llama-3-8b-Instruct',\n",
       " 'stage': 'sft',\n",
       " 'do_train': True,\n",
       " 'finetuning_type': 'lora',\n",
       " 'lora_target': 'all',\n",
       " 'deepspeed': 'examples/deepspeed/ds_z3_config.json',\n",
       " 'dataset': 'identity,ruozhiba',\n",
       " 'template': 'llama3',\n",
       " 'cutoff_len': 2048,\n",
       " 'max_samples': 200,\n",
       " 'overwrite_cache': True,\n",
       " 'preprocessing_num_workers': 16,\n",
       " 'output_dir': '/tmp/finetuned_model',\n",
       " 'logging_steps': 10,\n",
       " 'save_steps': 500,\n",
       " 'plot_loss': True,\n",
       " 'overwrite_output_dir': True,\n",
       " 'per_device_train_batch_size': 1,\n",
       " 'gradient_accumulation_steps': 2,\n",
       " 'learning_rate': 0.0001,\n",
       " 'num_train_epochs': 3,\n",
       " 'lr_scheduler_type': 'cosine',\n",
       " 'warmup_ratio': 0.1,\n",
       " 'fp16': True,\n",
       " 'ddp_timeout': 180000000,\n",
       " 'val_size': 0.1,\n",
       " 'per_device_eval_batch_size': 1,\n",
       " 'eval_strategy': 'steps',\n",
       " 'eval_steps': 500,\n",
       " 'warmup_steps': 10}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "doc['model_name_or_path'] = model_id\n",
    "doc['output_dir'] ='/tmp/finetuned_model'\n",
    "doc['num_train_epochs'] = 3\n",
    "doc['warmup_steps'] = 10\n",
    "doc['per_device_train_batch_size'] =1\n",
    "doc['gradient_accumulation_steps'] =2\n",
    "# doc['lora_target'] = 'all'\n",
    "doc['cutoff_len'] = 2048\n",
    "#实验时间，只选取前1000条数据做训练\n",
    "doc['max_samples'] = 200\n",
    "doc['dataset'] = 'identity,ruozhiba'\n",
    "doc['eval_steps'] = 500\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sg_config = 'sg_config_multl_node_lora_ds.yaml'\n",
    "with open(f'./LLaMA-Factory/{sg_config}', 'w') as f:\n",
    "    yaml.safe_dump(doc, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置Lora权重Merge 配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = './LLaMA-Factory/examples/merge_lora/llama3_lora_sft.yaml'\n",
    "with open(file_name) as f:\n",
    "    doc2 = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sg_lora_merge_config = 'sg_config_lora_merge.yaml'\n",
    "doc2['model_name_or_path'] = model_id\n",
    "doc2['adapter_name_or_path'] ='/tmp/finetuned_model'\n",
    "doc2['export_dir'] ='/tmp/finetuned_model_merged'\n",
    "with open(f'./LLaMA-Factory/{sg_lora_merge_config}', 'w') as f:\n",
    "    yaml.safe_dump(doc2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提交训练任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模型输出s3目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_s3 = f's3://{default_bucket}/llama3-8b-lora-sft-ds/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240613031908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: llama3-8b-instruct-finetune-2024-06-13-03-19-08-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-13 03:19:12 Starting - Starting the training job...\n",
      "2024-06-13 03:19:12 Pending - Training job waiting for capacity......\n",
      "2024-06-13 03:20:27 Pending - Preparing the instances for training...\n",
      "2024-06-13 03:21:03 Downloading - Downloading the training image...............\n",
      "2024-06-13 03:23:23 Training - Training image download completed. Training in progress.......\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-06-13 03:24:28,533 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-06-13 03:24:28,567 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-13 03:24:28,578 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-06-13 03:24:28,580 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-06-13 03:24:30,439 sagemaker-training-toolkit INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting transformers>=4.41.2 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.8/43.8 kB 2.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting datasets>=2.16.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting accelerate>=0.30.1 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting peft>=0.11.1 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting trl>=0.8.6 (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading trl-0.9.4-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting gradio>=4.0.0 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading gradio-4.36.1-py3-none-any.whl.metadata (15 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.8.0)\u001b[0m\n",
      "\u001b[34mCollecting sentencepiece (from -r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting tiktoken (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (3.20.3)\u001b[0m\n",
      "\u001b[34mCollecting uvicorn (from -r requirements.txt (line 12))\u001b[0m\n",
      "\u001b[34mDownloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2.7.2)\u001b[0m\n",
      "\u001b[34mCollecting fastapi (from -r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\u001b[0m\n",
      "\u001b[34mCollecting sse-starlette (from -r requirements.txt (line 15))\u001b[0m\n",
      "\u001b[34mDownloading sse_starlette-2.1.0-py3-none-any.whl.metadata (5.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (3.8.4)\u001b[0m\n",
      "\u001b[34mCollecting fire (from -r requirements.txt (line 17))\u001b[0m\n",
      "\u001b[34mDownloading fire-0.6.0.tar.gz (88 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.4/88.4 kB 5.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 19)) (6.0.1)\u001b[0m\n",
      "\u001b[34mCollecting deepspeed (from -r requirements.txt (line 20))\u001b[0m\n",
      "\u001b[34mDownloading deepspeed-0.14.3.tar.gz (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 31.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting autoawq (from -r requirements.txt (line 21))\u001b[0m\n",
      "\u001b[34mDownloading autoawq-0.2.5-cp310-cp310-manylinux2014_x86_64.whl.metadata (16 kB)\u001b[0m\n",
      "\u001b[34mCollecting metrics (from -r requirements.txt (line 22))\u001b[0m\n",
      "\u001b[34mDownloading metrics-0.3.3.tar.gz (18 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 23))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting rouge-chinese (from -r requirements.txt (line 24))\u001b[0m\n",
      "\u001b[34mDownloading rouge_chinese-1.0.3-py3-none-any.whl.metadata (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting jieba (from -r requirements.txt (line 25))\u001b[0m\n",
      "\u001b[34mDownloading jieba-0.42.1.tar.gz (19.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.2/19.2 MB 73.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.2->-r requirements.txt (line 1)) (3.14.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.23.0 (from transformers>=4.41.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.2->-r requirements.txt (line 1)) (1.26.4)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17 (from transformers>=4.41.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 6.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.2->-r requirements.txt (line 1)) (2.32.2)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.20,>=0.19 (from transformers>=4.41.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.4.1 (from transformers>=4.41.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.2->-r requirements.txt (line 1)) (4.66.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->-r requirements.txt (line 2)) (16.1.0)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow-hotfix (from datasets>=2.16.0->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->-r requirements.txt (line 2)) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->-r requirements.txt (line 2)) (2.2.2)\u001b[0m\n",
      "\u001b[34mCollecting xxhash (from datasets>=2.16.0->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->-r requirements.txt (line 2)) (0.70.16)\u001b[0m\n",
      "\u001b[34mCollecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets>=2.16.0->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp (from datasets>=2.16.0->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.30.1->-r requirements.txt (line 3)) (5.9.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.30.1->-r requirements.txt (line 3)) (2.2.0)\u001b[0m\n",
      "\u001b[34mCollecting tyro>=0.5.11 (from trl>=0.8.6->-r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading tyro-0.8.4-py3-none-any.whl.metadata (7.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiofiles<24.0,>=22.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting altair<6.0,>=4.2.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting ffmpy (from gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading ffmpy-0.3.2.tar.gz (5.5 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting gradio-client==1.0.1 (from gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading gradio_client-1.0.1-py3-none-any.whl.metadata (7.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting httpx>=0.24.1 (from gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-resources<7.0,>=1.3 (from gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (3.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (2.1.5)\u001b[0m\n",
      "\u001b[34mCollecting orjson~=3.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading orjson-3.10.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.7/49.7 kB 8.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (10.3.0)\u001b[0m\n",
      "\u001b[34mCollecting pydub (from gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting python-multipart>=0.0.9 (from gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting ruff>=0.2.2 (from gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading ruff-0.4.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\u001b[0m\n",
      "\u001b[34mCollecting semantic-version~=2.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting tomlkit==0.12.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting typer<1.0,>=0.12 (from gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (4.11.0)\u001b[0m\n",
      "\u001b[34mCollecting urllib3~=2.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting websockets<12.0,>=10.0 (from gradio-client==1.0.1->gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn->-r requirements.txt (line 12)) (8.1.7)\u001b[0m\n",
      "\u001b[34mCollecting h11>=0.8 (from uvicorn->-r requirements.txt (line 12))\u001b[0m\n",
      "\u001b[34mDownloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->-r requirements.txt (line 13)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic-core==2.18.3 in /opt/conda/lib/python3.10/site-packages (from pydantic->-r requirements.txt (line 13)) (2.18.3)\u001b[0m\n",
      "\u001b[34mCollecting starlette<0.38.0,>=0.37.2 (from fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting fastapi-cli>=0.0.2 (from fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting email_validator>=2.0.0 (from fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\u001b[0m\n",
      "\u001b[34mCollecting anyio (from sse-starlette->-r requirements.txt (line 15))\u001b[0m\n",
      "\u001b[34mDownloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (1.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (0.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (4.52.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (1.4.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (2.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire->-r requirements.txt (line 17)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting termcolor (from fire->-r requirements.txt (line 17))\u001b[0m\n",
      "\u001b[34mDownloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting hjson (from deepspeed->-r requirements.txt (line 20))\u001b[0m\n",
      "\u001b[34mDownloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed->-r requirements.txt (line 20)) (1.11.1.1)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-ml-py (from deepspeed->-r requirements.txt (line 20))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_ml_py-12.555.43-py3-none-any.whl.metadata (8.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting py-cpuinfo (from deepspeed->-r requirements.txt (line 20))\u001b[0m\n",
      "\u001b[34mDownloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zstandard in /opt/conda/lib/python3.10/site-packages (from autoawq->-r requirements.txt (line 21)) (0.22.0)\u001b[0m\n",
      "\u001b[34mCollecting autoawq-kernels (from autoawq->-r requirements.txt (line 21))\u001b[0m\n",
      "\u001b[34mDownloading autoawq_kernels-0.0.6-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting Pygments==2.2.0 (from metrics->-r requirements.txt (line 22))\u001b[0m\n",
      "\u001b[34mDownloading Pygments-2.2.0-py2.py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting pathspec==0.5.5 (from metrics->-r requirements.txt (line 22))\u001b[0m\n",
      "\u001b[34mDownloading pathspec-0.5.5.tar.gz (21 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting pathlib2>=2.3.0 (from metrics->-r requirements.txt (line 22))\u001b[0m\n",
      "\u001b[34mDownloading pathlib2-2.3.7.post1-py2.py3-none-any.whl.metadata (3.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 6)) (4.22.0)\u001b[0m\n",
      "\u001b[34mCollecting toolz (from altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->-r requirements.txt (line 14)) (3.7)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.16.0->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->-r requirements.txt (line 2)) (23.2.0)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.16.0->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.16.0->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.16.0->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0 (from aiohttp->datasets>=2.16.0->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 6)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mCollecting httpcore==1.* (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting sniffio (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->-r requirements.txt (line 2)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->-r requirements.txt (line 2)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.41.2->-r requirements.txt (line 1)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->sse-starlette->-r requirements.txt (line 15)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->-r requirements.txt (line 3)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (1.5.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (13.7.1)\u001b[0m\n",
      "\u001b[34mCollecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl>=0.8.6->-r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl>=0.8.6->-r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\u001b[0m\n",
      "\u001b[34mCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 6)) (2023.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 6)) (0.35.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 6)) (0.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (3.0.0)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of rich to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mCollecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-13.6.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-13.5.3-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-13.5.2-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-13.5.1-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-13.5.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mINFO: pip is still looking at multiple versions of rich to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mDownloading rich-13.4.1-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting markdown-it-py<3.0.0,>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading markdown_it_py-2.2.0-py3-none-any.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading rich-13.4.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-13.3.5-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-13.3.4-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-13.3.3-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\u001b[0m\n",
      "\u001b[34mDownloading rich-13.3.2-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-13.3.1-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-13.3.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-13.2.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-13.1.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting commonmark<0.10.0,>=0.9.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading rich-13.0.1-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-13.0.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-12.6.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-12.5.1-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-12.5.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-12.4.4-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-12.4.3-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-12.4.2-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-12.4.1-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-12.4.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-12.3.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-12.2.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-12.0.1-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-12.0.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-11.2.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: colorama<0.5.0,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (0.4.6)\u001b[0m\n",
      "\u001b[34mDownloading rich-11.1.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting tyro>=0.5.11 (from trl>=0.8.6->-r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading tyro-0.8.3-py3-none-any.whl.metadata (7.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading rich-11.0.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-10.16.2-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-10.16.1-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-10.16.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-10.15.2-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-10.15.1-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-10.15.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-10.14.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-10.13.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-10.12.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading rich-10.11.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting metrics (from -r requirements.txt (line 22))\u001b[0m\n",
      "\u001b[34mDownloading metrics-0.3.2.tar.gz (18 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mDownloading metrics-0.3.1.tar.gz (14 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mDownloading metrics-0.3.0.tar.gz (14 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mDownloading metrics-0.2.8.tar.gz (12 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting pathspec==0.5.3 (from metrics->-r requirements.txt (line 22))\u001b[0m\n",
      "\u001b[34mDownloading pathspec-0.5.3.tar.gz (20 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting metrics (from -r requirements.txt (line 22))\u001b[0m\n",
      "\u001b[34mDownloading metrics-0.2.7.tar.gz (12 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mDownloading metrics-0.2.6.tar.gz (12 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pygments>=0.8 in /opt/conda/lib/python3.10/site-packages (from metrics->-r requirements.txt (line 22)) (2.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.30.1->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (0.1.2)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.1/9.1 MB 104.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.19.2-py3-none-any.whl (542 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 542.1/542.1 kB 54.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.31.0-py3-none-any.whl (309 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 309.4/309.4 kB 36.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading peft-0.11.1-py3-none-any.whl (251 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 251.6/251.6 kB 34.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading trl-0.9.4-py3-none-any.whl (226 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 226.7/226.7 kB 29.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading gradio-4.36.1-py3-none-any.whl (12.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 87.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading gradio_client-1.0.1-py3-none-any.whl (318 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 318.1/318.1 kB 40.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\u001b[0m\n",
      "\u001b[34mDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 72.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 68.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.4/62.4 kB 11.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading fastapi-0.111.0-py3-none-any.whl (91 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.0/92.0 kB 14.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading sse_starlette-2.1.0-py3-none-any.whl (9.2 kB)\u001b[0m\n",
      "\u001b[34mDownloading autoawq-0.2.5-cp310-cp310-manylinux2014_x86_64.whl (84 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.3/84.3 kB 13.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.8/119.8 MB 20.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\u001b[0m\n",
      "\u001b[34mDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mDownloading altair-5.3.0-py3-none-any.whl (857 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 857.8/857.8 kB 61.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading email_validator-2.1.1-py3-none-any.whl (30 kB)\u001b[0m\n",
      "\u001b[34mDownloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 172.0/172.0 kB 26.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 70.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading h11-0.14.0-py3-none-any.whl (58 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 8.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.6/75.6 kB 14.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.9/77.9 kB 12.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 401.7/401.7 kB 50.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mDownloading orjson-3.10.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.7/142.7 kB 24.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 775.1/775.1 kB 56.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading ruff-0.4.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.8/8.8 MB 100.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 69.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.9/71.9 kB 13.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading anyio-4.4.0-py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 15.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 88.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading typer-0.12.3-py3-none-any.whl (47 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.2/47.2 kB 6.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tyro-0.8.4-py3-none-any.whl (102 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.4/102.4 kB 17.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.6/53.6 kB 9.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.1/121.1 kB 20.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading autoawq_kernels-0.0.6-cp310-cp310-manylinux2014_x86_64.whl (33.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 33.4/33.4 MB 53.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.0/54.0 kB 9.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_ml_py-12.555.43-py3-none-any.whl (39 kB)\u001b[0m\n",
      "\u001b[34mDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\u001b[0m\n",
      "\u001b[34mDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.1/194.1 kB 25.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\u001b[0m\n",
      "\u001b[34mDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.7/307.7 kB 30.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 239.5/239.5 kB 29.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 341.4/341.4 kB 35.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.3/124.3 kB 21.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\u001b[0m\n",
      "\u001b[34mDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mDownloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 91.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 67.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 129.9/129.9 kB 22.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.6/301.6 kB 39.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.1/56.1 kB 9.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: llamafactory, fire, deepspeed, metrics, jieba, ffmpy\u001b[0m\n",
      "\u001b[34mBuilding wheel for llamafactory (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for llamafactory (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for llamafactory: filename=llamafactory-0.8.2.dev0-py3-none-any.whl size=181325 sha256=f66d08c1f1f82c4550c09b14bdcec67ca66e4fac784d9239cd6d396622030cba\u001b[0m\n",
      "\u001b[34mStored in directory: /tmp/pip-ephem-wheel-cache-rhde6mf7/wheels/ee/79/1e/3fb168dd34359b627e23b53045c3eb498188294150b39e2fb0\u001b[0m\n",
      "\u001b[34mBuilding wheel for fire (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for fire (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117031 sha256=150af3595138e2b2deb24c8ac00c59e2d28abebcf8a9217ab59ac65e8ec86b68\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\u001b[0m\n",
      "\u001b[34mBuilding wheel for deepspeed (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for deepspeed (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for deepspeed: filename=deepspeed-0.14.3-py3-none-any.whl size=1443099 sha256=07717561b2f95d24d8e2d08222fb28f3cc72c6e60c4ff6c334c7fff0cd357e3d\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/82/bb/60/29f264d7ca7f5f2f3c9c1a6275883578977c0f608f1dee0790\u001b[0m\n",
      "\u001b[34mBuilding wheel for metrics (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for metrics (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for metrics: filename=metrics-0.2.6-py3-none-any.whl size=12791 sha256=874f7bf820f181750b74de304c89db3304cdfa4e20e66327418f260bd3dd40c3\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/c5/ca/d1/efae53ccccfba939be676f12c0449626e9da6ec1f6ec6e6e3d\u001b[0m\n",
      "\u001b[34mBuilding wheel for jieba (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for jieba (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314459 sha256=8c5e993a18419ee77a9066431a134617b42e84d8c662aa0a2071ecbe14930d9e\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/c9/69/31/d56d90b22a1777b0b231e234b00302a55be255930f8bd92dcd\u001b[0m\n",
      "\u001b[34mBuilding wheel for ffmpy (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for ffmpy (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=95a34c1a6f47245b254d8d10ad14e39dc74e0700b481eb2762d112fcba9235b1\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\u001b[0m\n",
      "\u001b[34mSuccessfully built llamafactory fire deepspeed metrics jieba ffmpy\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sentencepiece, pydub, py-cpuinfo, nvidia-ml-py, jieba, hjson, ffmpy, xxhash, websockets, uvloop, urllib3, ujson, toolz, tomlkit, termcolor, sniffio, shtab, semantic-version, safetensors, ruff, rouge-chinese, regex, python-multipart, python-dotenv, pyarrow-hotfix, orjson, multidict, metrics, importlib-resources, httptools, h11, fsspec, frozenlist, docstring-parser, dnspython, async-timeout, aiofiles, yarl, uvicorn, httpcore, fire, email_validator, anyio, aiosignal, watchfiles, tyro, typer, tiktoken, starlette, huggingface-hub, httpx, deepspeed, bitsandbytes, autoawq-kernels, aiohttp, tokenizers, sse-starlette, gradio-client, fastapi-cli, altair, accelerate, transformers, fastapi, datasets, trl, peft, gradio, autoawq, llamafactory\u001b[0m\n",
      "\u001b[34mAttempting uninstall: urllib3\u001b[0m\n",
      "\u001b[34mFound existing installation: urllib3 1.26.18\u001b[0m\n",
      "\u001b[34mUninstalling urllib3-1.26.18:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled urllib3-1.26.18\u001b[0m\n",
      "\u001b[34mAttempting uninstall: fsspec\u001b[0m\n",
      "\u001b[34mFound existing installation: fsspec 2024.5.0\u001b[0m\n",
      "\u001b[34mUninstalling fsspec-2024.5.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled fsspec-2024.5.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: typer\u001b[0m\n",
      "\u001b[34mFound existing installation: typer 0.9.4\u001b[0m\n",
      "\u001b[34mUninstalling typer-0.9.4:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled typer-0.9.4\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.22.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.22.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.22.0\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mspacy 3.7.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\n",
      "\u001b[34mweasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.31.0 aiofiles-23.2.1 aiohttp-3.9.5 aiosignal-1.3.1 altair-5.3.0 anyio-4.4.0 async-timeout-4.0.3 autoawq-0.2.5 autoawq-kernels-0.0.6 bitsandbytes-0.43.1 datasets-2.19.2 deepspeed-0.14.3 dnspython-2.6.1 docstring-parser-0.16 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 fire-0.6.0 frozenlist-1.4.1 fsspec-2024.3.1 gradio-4.36.1 gradio-client-1.0.1 h11-0.14.0 hjson-3.1.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 huggingface-hub-0.23.3 importlib-resources-6.4.0 jieba-0.42.1 llamafactory-0.8.2.dev0 metrics-0.2.6 multidict-6.0.5 nvidia-ml-py-12.555.43 orjson-3.10.4 peft-0.11.1 py-cpuinfo-9.0.0 pyarrow-hotfix-0.6 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 regex-2024.5.15 rouge-chinese-1.0.3 ruff-0.4.8 safetensors-0.4.3 semantic-version-2.10.0 sentencepiece-0.2.0 shtab-1.7.1 sniffio-1.3.1 sse-starlette-2.1.0 starlette-0.37.2 termcolor-2.4.0 tiktoken-0.7.0 tokenizers-0.19.1 tomlkit-0.12.0 toolz-0.12.1 transformers-4.41.2 trl-0.9.4 typer-0.12.3 tyro-0.8.4 ujson-5.10.0 urllib3-2.2.1 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3 xxhash-3.4.1 yarl-1.9.4\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2024-06-13 03:25:25,746 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-06-13 03:25:25,746 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-06-13 03:25:25,805 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-13 03:25:25,854 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-13 03:25:25,903 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-13 03:25:25,916 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.12xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"llama3-8b-instruct-finetune-2024-06-13-03-19-08-100\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-434444145045/llama3-8b-instruct-finetune-2024-06-13-03-19-08-100/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"entry-multi-nodes\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"entry-multi-nodes.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=entry-multi-nodes.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.12xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=entry-multi-nodes\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-434444145045/llama3-8b-instruct-finetune-2024-06-13-03-19-08-100/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.12xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"llama3-8b-instruct-finetune-2024-06-13-03-19-08-100\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-434444145045/llama3-8b-instruct-finetune-2024-06-13-03-19-08-100/source/sourcedir.tar.gz\",\"module_name\":\"entry-multi-nodes\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"entry-multi-nodes.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m entry-multi-nodes\u001b[0m\n",
      "\u001b[34m2024-06-13 03:25:25,918 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-06-13 03:25:25,918 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mObtaining file:///opt/ml/code\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mChecking if build backend supports build_editable: started\u001b[0m\n",
      "\u001b[34mChecking if build backend supports build_editable: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build editable: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build editable: finished with status 'done'\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing editable metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing editable metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: llamafactory\u001b[0m\n",
      "\u001b[34mBuilding editable for llamafactory (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding editable for llamafactory (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for llamafactory: filename=llamafactory-0.8.2.dev0-0.editable-py3-none-any.whl size=18802 sha256=28f9b71be6b72b435748445bc0264447241186bcbfd2c59aa9b30c28b9d5d6f6\u001b[0m\n",
      "\u001b[34mStored in directory: /tmp/pip-ephem-wheel-cache-qzzlrlnz/wheels/ee/79/1e/3fb168dd34359b627e23b53045c3eb498188294150b39e2fb0\u001b[0m\n",
      "\u001b[34mSuccessfully built llamafactory\u001b[0m\n",
      "\u001b[34mInstalling collected packages: llamafactory\u001b[0m\n",
      "\u001b[34mAttempting uninstall: llamafactory\u001b[0m\n",
      "\u001b[34mFound existing installation: llamafactory 0.8.2.dev0\u001b[0m\n",
      "\u001b[34mUninstalling llamafactory-0.8.2.dev0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled llamafactory-0.8.2.dev0\u001b[0m\n",
      "\u001b[34mSuccessfully installed llamafactory-0.8.2.dev0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers>=4.41.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (4.41.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate>=0.30.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.31.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: peft>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: trl>=0.8.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gradio>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (4.36.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (3.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: uvicorn in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.30.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.111.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sse-starlette in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (3.8.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fire in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (0.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 19)) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: deepspeed in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (0.14.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: autoawq in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 21)) (0.2.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: metrics in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (0.2.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 23)) (0.43.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rouge-chinese in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 24)) (1.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jieba in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 25)) (0.42.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.2->-r requirements.txt (line 1)) (3.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.2->-r requirements.txt (line 1)) (0.23.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.2->-r requirements.txt (line 1)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.2->-r requirements.txt (line 1)) (2024.5.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.2->-r requirements.txt (line 1)) (2.32.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.2->-r requirements.txt (line 1)) (0.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.2->-r requirements.txt (line 1)) (0.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.2->-r requirements.txt (line 1)) (4.66.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->-r requirements.txt (line 2)) (16.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->-r requirements.txt (line 2)) (0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->-r requirements.txt (line 2)) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->-r requirements.txt (line 2)) (2.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->-r requirements.txt (line 2)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->-r requirements.txt (line 2)) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets>=2.16.0->-r requirements.txt (line 2)) (2024.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->-r requirements.txt (line 2)) (3.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.30.1->-r requirements.txt (line 3)) (5.9.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.30.1->-r requirements.txt (line 3)) (2.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl>=0.8.6->-r requirements.txt (line 5)) (0.8.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (23.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (5.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ffmpy in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (0.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gradio-client==1.0.1 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (0.27.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (6.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (3.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (3.10.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (10.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (0.25.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (0.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ruff>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: semantic-version~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (2.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tomlkit==0.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (0.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (0.12.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (4.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (2.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.0.1->gradio>=4.0.0->-r requirements.txt (line 6)) (11.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn->-r requirements.txt (line 12)) (8.1.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn->-r requirements.txt (line 12)) (0.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->-r requirements.txt (line 13)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic-core==2.18.3 in /opt/conda/lib/python3.10/site-packages (from pydantic->-r requirements.txt (line 13)) (2.18.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi->-r requirements.txt (line 14)) (0.37.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fastapi-cli>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from fastapi->-r requirements.txt (line 14)) (0.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from fastapi->-r requirements.txt (line 14)) (5.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: email_validator>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->-r requirements.txt (line 14)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from sse-starlette->-r requirements.txt (line 15)) (4.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (1.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (0.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (4.52.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (1.4.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 16)) (2.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire->-r requirements.txt (line 17)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire->-r requirements.txt (line 17)) (2.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: hjson in /opt/conda/lib/python3.10/site-packages (from deepspeed->-r requirements.txt (line 20)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed->-r requirements.txt (line 20)) (1.11.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-ml-py in /opt/conda/lib/python3.10/site-packages (from deepspeed->-r requirements.txt (line 20)) (12.555.43)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed->-r requirements.txt (line 20)) (9.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zstandard in /opt/conda/lib/python3.10/site-packages (from autoawq->-r requirements.txt (line 21)) (0.22.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: autoawq-kernels in /opt/conda/lib/python3.10/site-packages (from autoawq->-r requirements.txt (line 21)) (0.0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pygments>=0.8 in /opt/conda/lib/python3.10/site-packages (from metrics->-r requirements.txt (line 22)) (2.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 6)) (4.22.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 6)) (0.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->-r requirements.txt (line 14)) (2.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->-r requirements.txt (line 14)) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->-r requirements.txt (line 2)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->-r requirements.txt (line 2)) (23.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->-r requirements.txt (line 2)) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->-r requirements.txt (line 2)) (6.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->-r requirements.txt (line 2)) (1.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->-r requirements.txt (line 2)) (4.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 6)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 6)) (1.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 6)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->-r requirements.txt (line 2)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->-r requirements.txt (line 2)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.41.2->-r requirements.txt (line 1)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->sse-starlette->-r requirements.txt (line 15)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->-r requirements.txt (line 3)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (1.5.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (13.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.8.6->-r requirements.txt (line 5)) (0.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.8.6->-r requirements.txt (line 5)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 14)) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 14)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 14)) (0.19.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 14)) (0.22.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 6)) (2023.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 6)) (0.35.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 6)) (0.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.30.1->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (0.1.2)\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCITATION.cff\u001b[0m\n",
      "\u001b[34mDockerfile\u001b[0m\n",
      "\u001b[34mLICENSE\u001b[0m\n",
      "\u001b[34mMANIFEST.in\u001b[0m\n",
      "\u001b[34mMakefile\u001b[0m\n",
      "\u001b[34mREADME.md\u001b[0m\n",
      "\u001b[34mREADME_zh.md\u001b[0m\n",
      "\u001b[34massets\u001b[0m\n",
      "\u001b[34mbuild\u001b[0m\n",
      "\u001b[34mdata\u001b[0m\n",
      "\u001b[34mdocker-compose.yml\u001b[0m\n",
      "\u001b[34mentry-multi-nodes.py\u001b[0m\n",
      "\u001b[34mentry_single_lora.py\u001b[0m\n",
      "\u001b[34mevaluation\u001b[0m\n",
      "\u001b[34mexamples\u001b[0m\n",
      "\u001b[34mpyproject.toml\u001b[0m\n",
      "\u001b[34mrequirements.txt\u001b[0m\n",
      "\u001b[34ms5cmd\u001b[0m\n",
      "\u001b[34mscripts\u001b[0m\n",
      "\u001b[34msetup.py\u001b[0m\n",
      "\u001b[34msg_config_lora_merge.yaml\u001b[0m\n",
      "\u001b[34msg_config_multl_node_lora_ds.yaml\u001b[0m\n",
      "\u001b[34msg_config_qlora.yaml\u001b[0m\n",
      "\u001b[34msrc\u001b[0m\n",
      "\u001b[34mtests\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-434444145045/dataset-for-training/train/identity_2.json /opt/ml/code/data/identity_2.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-434444145045/dataset-for-training/train/ruozhiba.json /opt/ml/code/data/ruozhiba.json\u001b[0m\n",
      "\u001b[34m------envs------\u001b[0m\n",
      "\u001b[34mnum_machines:1\u001b[0m\n",
      "\u001b[34mnum_processes:4\u001b[0m\n",
      "\u001b[34mhost_rank:0\u001b[0m\n",
      "\u001b[34m[2024-06-13 03:25:48,748] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34mdf: /root/.triton/autotune: No such file or directory\u001b[0m\n",
      "\u001b[34m#033[93m [WARNING] #033[0m async_io requires the dev libaio .so object and headers but these were not found.\u001b[0m\n",
      "\u001b[34m#033[93m [WARNING] #033[0m async_io: please install the libaio-dev package with apt\u001b[0m\n",
      "\u001b[34m#033[93m [WARNING] #033[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\u001b[0m\n",
      "\u001b[34m#033[93m [WARNING] #033[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\u001b[0m\n",
      "\u001b[34m#033[93m [WARNING] #033[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2\u001b[0m\n",
      "\u001b[34m#033[93m [WARNING] #033[0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible\u001b[0m\n",
      "\u001b[34m06/13/2024 03:25:51 - INFO - llamafactory.cli - Initializing distributed tasks at: 10.0.177.85:29500\u001b[0m\n",
      "\u001b[34m[2024-06-13 03:25:52,249] torch.distributed.run: [WARNING] \u001b[0m\n",
      "\u001b[34m[2024-06-13 03:25:52,249] torch.distributed.run: [WARNING] *****************************************\u001b[0m\n",
      "\u001b[34m[2024-06-13 03:25:52,249] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \u001b[0m\n",
      "\u001b[34m[2024-06-13 03:25:52,249] torch.distributed.run: [WARNING] *****************************************\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/bin/torchrun\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('torch==2.2.0', 'console_scripts', 'torchrun')())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 347, in wrapper\u001b[0m\n",
      "\u001b[34mreturn f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 812, in main\u001b[0m\n",
      "\u001b[34mrun(args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 803, in run\u001b[0m\n",
      "\u001b[34melastic_launch(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 135, in __call__\u001b[0m\n",
      "\u001b[34mreturn launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 259, in launch_agent\u001b[0m\n",
      "\u001b[34mresult = agent.run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 123, in wrapper\u001b[0m\n",
      "\u001b[34mresult = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 727, in run\u001b[0m\n",
      "\u001b[34mresult = self._invoke_run(role)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 862, in _invoke_run\u001b[0m\n",
      "\u001b[34mself._initialize_workers(self._worker_group)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 123, in wrapper\u001b[0m\n",
      "\u001b[34mresult = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 699, in _initialize_workers\u001b[0m\n",
      "\u001b[34mself._rendezvous(worker_group)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 123, in wrapper\u001b[0m\n",
      "\u001b[34mresult = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 542, in _rendezvous\u001b[0m\n",
      "\u001b[34mstore, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py\", line 55, in next_rendezvous\u001b[0m\n",
      "\u001b[34mself._store = TCPStore(  # type: ignore[call-arg]\u001b[0m\n",
      "\u001b[34mtorch.distributed.DistStoreError: Timed out after 901 seconds waiting for clients. 1/2 clients joined.\u001b[0m\n",
      "\u001b[34m-----start merge lora-------\u001b[0m\n",
      "\u001b[34m[2024-06-13 03:41:05,594] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m#033[93m [WARNING] #033[0m async_io requires the dev libaio .so object and headers but these were not found.\u001b[0m\n",
      "\u001b[34m#033[93m [WARNING] #033[0m async_io: please install the libaio-dev package with apt\u001b[0m\n",
      "\u001b[34m#033[93m [WARNING] #033[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\u001b[0m\n",
      "\u001b[34m#033[93m [WARNING] #033[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\u001b[0m\n",
      "\u001b[34m#033[93m [WARNING] #033[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2\u001b[0m\n",
      "\u001b[34m#033[93m [WARNING] #033[0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2108] 2024-06-13 03:41:08,749 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/tokenizer.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2108] 2024-06-13 03:41:08,749 >> loading file added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2108] 2024-06-13 03:41:08,749 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2108] 2024-06-13 03:41:08,749 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/tokenizer.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2108] 2024-06-13 03:41:08,749 >> loading file added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2108] 2024-06-13 03:41:08,749 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2108] 2024-06-13 03:41:08,749 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2108] 2024-06-13 03:41:08,749 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[WARNING|logging.py:314] 2024-06-13 03:41:09,055 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m[WARNING|logging.py:314] 2024-06-13 03:41:09,055 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m06/13/2024 03:41:09 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:733] 2024-06-13 03:41:09,241 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:733] 2024-06-13 03:41:09,241 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:796] 2024-06-13 03:41:09,242 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:796] 2024-06-13 03:41:09,242 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m06/13/2024 03:41:09 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3474] 2024-06-13 03:41:09,625 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/model.safetensors.index.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3474] 2024-06-13 03:41:09,625 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/model.safetensors.index.json\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  25%|██▌       | 1/4 [00:23<01:09, 23.19s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 2/4 [00:44<00:43, 21.99s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards:  75%|███████▌  | 3/4 [01:05<00:21, 21.73s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 4/4 [01:10<00:00, 15.03s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 4/4 [01:10<00:00, 17.63s/it]\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1519] 2024-06-13 03:42:20,151 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1519] 2024-06-13 03:42:20,151 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:962] 2024-06-13 03:42:20,152 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:962] 2024-06-13 03:42:20,152 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.31it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.29it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.29it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.39it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.35it/s]\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:4280] 2024-06-13 03:42:20,995 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:4280] 2024-06-13 03:42:20,995 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:4288] 2024-06-13 03:42:20,995 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:4288] 2024-06-13 03:42:20,995 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:917] 2024-06-13 03:42:21,195 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/generation_config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:917] 2024-06-13 03:42:21,195 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/generation_config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:962] 2024-06-13 03:42:21,196 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ]\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:962] 2024-06-13 03:42:21,196 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ]\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m06/13/2024 03:42:21 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\u001b[0m\n",
      "\u001b[34m06/13/2024 03:42:21 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\u001b[0m\n",
      "\u001b[34m06/13/2024 03:42:21 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/peft/config.py\", line 197, in _get_peft_type\n",
      "    config_file = hf_hub_download(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n",
      "    validate_repo_id(arg_value)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n",
      "    raise HFValidationError(\u001b[0m\n",
      "\u001b[34mhuggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/tmp/finetuned_model'. Use `repo_type` argument if needed.\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/bin/llamafactory-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/ml/code/src/llamafactory/cli.py\", line 73, in main\n",
      "    export_model()\n",
      "  File \"/opt/ml/code/src/llamafactory/train/tuner.py\", line 59, in export_model\n",
      "    model = load_model(tokenizer, model_args, finetuning_args)  # must after fixing tokenizer to resize vocab\n",
      "  File \"/opt/ml/code/src/llamafactory/model/loader.py\", line 146, in load_model\n",
      "    model = init_adapter(config, model, model_args, finetuning_args, is_trainable)\n",
      "  File \"/opt/ml/code/src/llamafactory/model/adapter.py\", line 271, in init_adapter\n",
      "    model = _setup_lora_tuning(\n",
      "  File \"/opt/ml/code/src/llamafactory/model/adapter.py\", line 159, in _setup_lora_tuning\n",
      "    model: \"LoraModel\" = PeftModel.from_pretrained(model, adapter, offload_folder=model_args.offload_folder)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/peft/peft_model.py\", line 372, in from_pretrained\n",
      "    PeftConfig._get_peft_type(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/peft/config.py\", line 203, in _get_peft_type\n",
      "    raise ValueError(f\"Can't find '{CONFIG_NAME}' at '{model_id}'\")\u001b[0m\n",
      "\u001b[34mValueError: Can't find 'adapter_config.json' at '/tmp/finetuned_model'\u001b[0m\n",
      "\u001b[34m-----end merge lora-------\u001b[0m\n",
      "\u001b[34mName:\n",
      "  sync - sync objects\u001b[0m\n",
      "\u001b[34mUsage:\n",
      "  sync [options] source destination\u001b[0m\n",
      "\u001b[34mOptions:\u001b[0m\n",
      "\u001b[34mERROR \"sync /tmp/finetuned_model_merged s3://sagemaker-us-west-2-434444145045/llama3-8b-lora-sft-ds/output/\": given object not found\u001b[0m\n",
      "\u001b[34m--delete                       delete objects in destination but not in source (default: false)\n",
      "  --size-only                    make size of object only criteria to decide whether an object should be synced (default: false)\n",
      "  --no-follow-symlinks           do not follow symbolic links (default: false)\n",
      "  --storage-class value          set storage class for target ('STANDARD','REDUCED_REDUNDANCY','GLACIER','STANDARD_IA','ONEZONE_IA','INTELLIGENT_TIERING','DEEP_ARCHIVE')\n",
      "  --concurrency value, -c value  number of concurrent parts transferred between host and remote server (default: 5)\n",
      "  --part-size value, -p value    size of each part transferred between host and remote server, in MiB (default: 50)\n",
      "  --sse value                    perform server side encryption of the data at its destination, e.g. aws:kms\n",
      "  --sse-kms-key-id value         customer master key (CMK) id for SSE-KMS encryption; leave it out if server-side generated key is desired\n",
      "  --acl value                    set acl for target: defines granted accesses and their types on different accounts/groups, e.g. cp --acl 'public-read'\n",
      "  --cache-control value          set cache control for target: defines cache control header for object, e.g. cp --cache-control 'public, max-age=345600'\n",
      "  --expires value                set expires for target (uses RFC3339 format): defines expires header for object, e.g. cp  --expires '2024-10-01T20:30:00Z'\n",
      "  --force-glacier-transfer       force transfer of glacier objects whether they are restored or not (default: false)\n",
      "  --ignore-glacier-warnings      turns off glacier warnings: ignore errors encountered during copying, downloading and moving glacier objects (default: false)\n",
      "  --source-region value          set the region of source bucket; the region of the source bucket will be automatically discovered if --source-region is not specified\n",
      "  --destination-region value     set the region of destination bucket: the region of the destination bucket will be automatically discovered if --destination-region is not specified\n",
      "  --exclude value                exclude objects with given pattern\u001b[0m\n",
      "\u001b[34m--raw                          disable the wildcard operations, useful with filenames that contains glob characters (default: false)\n",
      "  --help, -h                     show help (default: false)\u001b[0m\n",
      "\u001b[34mExamples:\n",
      "  01. Sync local folder to s3 bucket\n",
      "     > s5cmd sync folder/ s3://bucket/\n",
      "  02. Sync S3 bucket to local folder\n",
      "     > s5cmd sync s3://bucket/* folder/\n",
      "  03. Sync S3 bucket objects under prefix to S3 bucket.\n",
      "     > s5cmd sync s3://sourcebucket/prefix/* s3://destbucket/\n",
      "  04. Sync local folder to S3 but delete the files that S3 bucket has but local does not have.\n",
      "     > s5cmd sync --delete folder/ s3://bucket/\n",
      "  05. Sync S3 bucket to local folder but use size as only comparison criteria.\n",
      "     > s5cmd sync --size-only s3://bucket/* folder/\n",
      "  06. Sync a file to S3 bucket\n",
      "     > s5cmd sync myfile.gz s3://bucket/\n",
      "  07. Sync matching S3 objects to another bucket\n",
      "     > s5cmd sync s3://bucket/*.gz s3://target-bucket/prefix/\n",
      "  08. Perform KMS Server Side Encryption of the object(s) at the destination\n",
      "     > s5cmd sync --sse aws:kms s3://bucket/object s3://target-bucket/prefix/object\n",
      "  09. Perform KMS-SSE of the object(s) at the destination using customer managed Customer Master Key (CMK) key id\n",
      "     > s5cmd sync --sse aws:kms --sse-kms-key-id <your-kms-key-id> s3://bucket/object s3://target-bucket/prefix/object\n",
      "  10. Sync all files to S3 bucket but exclude the ones with txt and gz extension\n",
      "     > s5cmd sync --exclude \"*.txt\" --exclude \"*.gz\" dir/ s3://bucket\u001b[0m\n",
      "\u001b[34m*****************finished training, start cp finetuned model*****************************\u001b[0m\n",
      "\u001b[34mERROR \"sync /tmp/finetuned_model s3://sagemaker-us-west-2-434444145045/llama3-8b-lora-sft-ds/output/\": given object not found\u001b[0m\n",
      "\u001b[34mName:\n",
      "  sync - sync objects\u001b[0m\n",
      "\u001b[34mUsage:\n",
      "  sync [options] source destination\u001b[0m\n",
      "\u001b[34mOptions:\u001b[0m\n",
      "\u001b[34m--delete                       delete objects in destination but not in source (default: false)\n",
      "  --size-only                    make size of object only criteria to decide whether an object should be synced (default: false)\n",
      "  --no-follow-symlinks           do not follow symbolic links (default: false)\n",
      "  --storage-class value          set storage class for target ('STANDARD','REDUCED_REDUNDANCY','GLACIER','STANDARD_IA','ONEZONE_IA','INTELLIGENT_TIERING','DEEP_ARCHIVE')\n",
      "  --concurrency value, -c value  number of concurrent parts transferred between host and remote server (default: 5)\n",
      "  --part-size value, -p value    size of each part transferred between host and remote server, in MiB (default: 50)\n",
      "  --sse value                    perform server side encryption of the data at its destination, e.g. aws:kms\n",
      "  --sse-kms-key-id value         customer master key (CMK) id for SSE-KMS encryption; leave it out if server-side generated key is desired\n",
      "  --acl value                    set acl for target: defines granted accesses and their types on different accounts/groups, e.g. cp --acl 'public-read'\n",
      "  --cache-control value          set cache control for target: defines cache control header for object, e.g. cp --cache-control 'public, max-age=345600'\n",
      "  --expires value                set expires for target (uses RFC3339 format): defines expires header for object, e.g. cp  --expires '2024-10-01T20:30:00Z'\n",
      "  --force-glacier-transfer       force transfer of glacier objects whether they are restored or not (default: false)\n",
      "  --ignore-glacier-warnings      turns off glacier warnings: ignore errors encountered during copying, downloading and moving glacier objects (default: false)\u001b[0m\n",
      "\u001b[34m--source-region value          set the region of source bucket; the region of the source bucket will be automatically discovered if --source-region is not specified\n",
      "  --destination-region value     set the region of destination bucket: the region of the destination bucket will be automatically discovered if --destination-region is not specified\n",
      "  --exclude value\u001b[0m\n",
      "\u001b[34mexclude objects with given pattern\n",
      "  --raw                          disable the wildcard operations, useful with filenames that contains glob characters (default: false)\n",
      "  --help, -h                     show help (default: false)\n",
      "  \u001b[0m\n",
      "\u001b[34mExamples:\n",
      "  01. Sync local folder to s3 bucket\n",
      "     > s5cmd sync folder/ s3://bucket/\n",
      "  02. Sync S3 bucket to local folder\n",
      "     > s5cmd sync s3://bucket/* folder/\n",
      "  03. Sync S3 bucket objects under prefix to S3 bucket.\n",
      "     > s5cmd sync s3://sourcebucket/prefix/* s3://destbucket/\n",
      "  04. Sync local folder to S3 but delete the files that S3 bucket has but local does not have.\n",
      "     > s5cmd sync --delete folder/ s3://bucket/\n",
      "  05. Sync S3 bucket to local folder but use size as only comparison criteria.\n",
      "     > s5cmd sync --size-only s3://bucket/* folder/\n",
      "  06. Sync a file to S3 bucket\n",
      "     > s5cmd sync myfile.gz s3://bucket/\n",
      "  07. Sync matching S3 objects to another bucket\n",
      "     > s5cmd sync s3://bucket/*.gz s3://target-bucket/prefix/\n",
      "  08. Perform KMS Server Side Encryption of the object(s) at the destination\n",
      "     > s5cmd sync --sse aws:kms s3://bucket/object s3://target-bucket/prefix/object\n",
      "  09. Perform KMS-SSE of the object(s) at the destination using customer managed Customer Master Key (CMK) key id\n",
      "     > s5cmd sync --sse aws:kms --sse-kms-key-id <your-kms-key-id> s3://bucket/object s3://target-bucket/prefix/object\n",
      "  10. Sync all files to S3 bucket but exclude the ones with txt and gz extension\n",
      "     > s5cmd sync --exclude \"*.txt\" --exclude \"*.gz\" dir/ s3://bucket\u001b[0m\n",
      "\u001b[34m-----finished cp-------\u001b[0m\n",
      "\u001b[34m2024-06-13 03:42:22,382 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-06-13 03:42:22,383 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-06-13 03:42:22,383 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-06-13 03:43:27 Uploading - Uploading generated training model\n",
      "2024-06-13 03:43:40 Completed - Training job completed\n",
      "Training seconds: 1368\n",
      "Billable seconds: 1368\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "instance_count = 2\n",
    "instance_type = 'ml.g5.48xlarge' \n",
    "max_time = 3600*24\n",
    "\n",
    "# Get the current time\n",
    "current_time = datetime.now()\n",
    "\n",
    "# wandb.sagemaker_auth(path=\"./\")\n",
    "# Format the current time as a string\n",
    "formatted_time = current_time.strftime(\"%Y%m%d%H%M%S\")\n",
    "print(formatted_time)\n",
    "\n",
    "base_job_name = 'llama3-8b-instruct-finetune'\n",
    "environment = {\n",
    "    'NODE_NUMBER':str(instance_count),\n",
    "    \"merge_lora\":\"1\", ##是否合并lora模型\n",
    "    \"sg_config\":sg_config,\n",
    "    \"sg_lora_merge_config\":sg_lora_merge_config,\n",
    "    \"s3_data_paths\":f\"{training_input_path}\",\n",
    "    'OUTPUT_MODEL_S3_PATH': destination_s3\n",
    "}\n",
    "\n",
    "estimator = PyTorch(entry_point='entry-multi-nodes.py',\n",
    "                            source_dir='./LLaMA-Factory/',\n",
    "                            role=role,\n",
    "                            base_job_name=base_job_name,\n",
    "                            environment=environment,\n",
    "                            framework_version='2.2.0',\n",
    "                            py_version='py310',\n",
    "                            script_mode=True,\n",
    "                            instance_count=instance_count,\n",
    "                            instance_type=instance_type,\n",
    "                            enable_remote_debug=True,\n",
    "                            # keep_alive_period_in_seconds=600,\n",
    "                            max_run=max_time)\n",
    "\n",
    "# # data in channel will be automatically copied to each node - /opt/ml/input/data/train1\n",
    "#input_channel = {'train': f's3://{sagemaker_default_bucket}/datasets/qiandao/{version}/train.json'}\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

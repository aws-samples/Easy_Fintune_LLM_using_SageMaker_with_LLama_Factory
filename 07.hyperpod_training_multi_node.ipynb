{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3b6adcb-9ff5-419f-aeb0-40073aaaf5b0",
   "metadata": {},
   "source": [
    "# Using LLama Factory finetune on SageMaker - HyperPod 集群\n",
    "# 7. 在HyperPod集群提交训练任务 - 多节点多GPU - deepspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461e9ae8-e9e9-4688-a1d6-8935362dcd92",
   "metadata": {},
   "source": [
    "## 7.1. 多节点多GPU 分布式训练 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6fff4-7c50-4ea1-b072-a67d71aa6f2e",
   "metadata": {},
   "source": [
    "#### 先决条件：完成04.04.llama_factory_finetune_on_SageMaker_multi_node中数据和yml配置准备部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dd6f012-2940-4089-80cb-91fc3c59b53d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::434444145045:role/notebook-hyperpod-ExecutionRole-xHaRX2L05qHQ\n",
      "sagemaker bucket: sagemaker-us-west-2-434444145045\n",
      "sagemaker session region: us-west-2\n",
      "boto3 version: 1.34.123\n",
      "sagemaker version: 2.222.0\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "print(f\"boto3 version: {boto3.__version__}\")\n",
    "print(f\"sagemaker version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c60d2-57e8-43b9-bcaa-c32a33f2dae8",
   "metadata": {},
   "source": [
    "### 准备LLaMA-Factory 的 训练配置yaml文件\n",
    "### 从LLaMA-Factory/examples/train_lora/目录中复制出llama3_lora_sft_ds3.yaml，并修改\n",
    "- 本次实验是使用Lora训练\n",
    "- 如果用全量微调，则使用LLaMA-Factory/examples/train_lora/llama3_lora_sft_ds3.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a84ddf-458b-4470-b0a2-5adf92b56250",
   "metadata": {
    "tags": []
   },
   "source": [
    "- ！如果需要full training请进入LLaMA-Factory/examples/查看其他的实例配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7624602a-1190-4084-89bf-d9de68f57f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load template\n",
    "import yaml\n",
    "file_name = './LLaMA-Factory/examples/train_lora/llama3_lora_sft_ds3.yaml'\n",
    "with open(file_name) as f:\n",
    "    doc = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d0c0c4-f276-4130-beb2-cf32430409ab",
   "metadata": {},
   "source": [
    "- 本次实验我们使用原始精度的LLaMA-3-8b， 从hf的repo 'unsloth/llama-3-8b-Instruct' 下载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b00770-f509-402c-ac21-99f4349e3808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = 'unsloth/llama-3-8b-Instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37b05d1a-2615-408a-8e57-0df91a85cade",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name_or_path': 'unsloth/llama-3-8b-Instruct',\n",
       " 'stage': 'sft',\n",
       " 'do_train': True,\n",
       " 'finetuning_type': 'lora',\n",
       " 'lora_target': 'all',\n",
       " 'deepspeed': 'examples/deepspeed/ds_z3_config.json',\n",
       " 'dataset': 'identity,ruozhiba',\n",
       " 'template': 'llama3',\n",
       " 'cutoff_len': 2048,\n",
       " 'max_samples': 1000,\n",
       " 'overwrite_cache': True,\n",
       " 'preprocessing_num_workers': 16,\n",
       " 'output_dir': '/home/ubuntu/finetuned_model',\n",
       " 'logging_steps': 10,\n",
       " 'save_steps': 500,\n",
       " 'plot_loss': True,\n",
       " 'overwrite_output_dir': True,\n",
       " 'per_device_train_batch_size': 1,\n",
       " 'gradient_accumulation_steps': 2,\n",
       " 'learning_rate': 0.0001,\n",
       " 'num_train_epochs': 3,\n",
       " 'lr_scheduler_type': 'cosine',\n",
       " 'warmup_ratio': 0.1,\n",
       " 'fp16': True,\n",
       " 'ddp_timeout': 180000000,\n",
       " 'val_size': 0.1,\n",
       " 'per_device_eval_batch_size': 1,\n",
       " 'eval_strategy': 'steps',\n",
       " 'eval_steps': 500,\n",
       " 'warmup_steps': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc['model_name_or_path'] = model_id\n",
    "doc['output_dir'] ='/home/ubuntu/finetuned_model'\n",
    "doc['num_train_epochs'] = 3\n",
    "doc['warmup_steps'] = 10\n",
    "doc['per_device_train_batch_size'] =1\n",
    "doc['gradient_accumulation_steps'] =2\n",
    "# doc['lora_target'] = 'all'\n",
    "doc['cutoff_len'] = 2048\n",
    "#实验时间，只选取前1000条数据做训练\n",
    "doc['max_samples'] = 1000\n",
    "doc['dataset'] = 'identity,ruozhiba'\n",
    "doc['eval_steps'] = 500\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85508e06-9ab8-4f98-ba64-57578ddf2222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sg_config = 'sg_config_multl_node_lora_ds.yaml'\n",
    "with open(f'./LLaMA-Factory/{sg_config}', 'w') as f:\n",
    "    yaml.safe_dump(doc, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0df7cb-aecb-45e6-8e72-1cd8bca1c6e8",
   "metadata": {},
   "source": [
    "### 准备训练脚本1\n",
    "- ❌ 准备训练启动脚本 注意把s3 bucket 替换成自己账号的地址\n",
    "- 使用节点自动恢复脚本提交任务 https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-hyperpod-resiliency.html#sagemaker-hyperpod-resiliency-auto-resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e933d476-7bc3-4214-926c-926d29a41787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyperpod-scripts/train_multi_ds.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyperpod-scripts/train_multi_ds.sh\n",
    "#!/bin/bash\n",
    "\n",
    "sg_config=sg_config_multl_node_lora_ds.yaml\n",
    "echo \"sg_config=$sg_config\"\n",
    "\n",
    "#注意把s3 bucket 替换成自己账号的地址\n",
    "OUTPUT_MODEL_S3_PATH=s3://sagemaker-us-west-2-434444145045/hyperpod/llama3-8b-ds/\n",
    "\n",
    "source  ../miniconda3/bin/activate\n",
    "\n",
    "conda activate py310\n",
    "\n",
    "pip install torch==2.3.0\n",
    "\n",
    "chmod +x ./s5cmd\n",
    "\n",
    "#download training dataset\n",
    "./s5cmd sync s3://sagemaker-us-west-2-434444145045/dataset-for-training/train/* /home/ubuntu/LLaMA-Factory/data/\n",
    "\n",
    "NODE_RANK=$SLURM_NODEID\n",
    "echo \"NODE_RANK=$NODE_RANK\"\n",
    "\n",
    "WORLD_SIZE_JOB=$SLURM_NTASKS\n",
    "echo \"WORLD_SIZE_JOB=$WORLD_SIZE_JOB\"\n",
    "\n",
    "MASTER_ADDR=(`scontrol show hostnames \\$SLURM_JOB_NODELIST | head -n 1`)\n",
    "MASTER_PORT=$(expr 10000 + $(echo -n $SLURM_JOBID | tail -c 4))\n",
    "\n",
    "echo \"MASTER_ADDR=$MASTER_ADDR\"\n",
    "echo \"MASTER_PORT=$MASTER_PORT\"\n",
    "\n",
    "# get gpu count\n",
    "gpu_count=$(nvidia-smi --query-gpu=gpu_name --format=csv,noheader | wc -l)\n",
    "\n",
    "DEVICES=\"\"\n",
    "\n",
    "# 构建设备字符串\n",
    "for ((i=0; i<gpu_count; i++)); do\n",
    "    DEVICES+=\"$i\"\n",
    "    if ((i < gpu_count - 1)); then\n",
    "        DEVICES+=\",\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "echo \"DEVICES=$DEVICES\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "export NCCL_IB_DISABLE=1\n",
    "# 注意这里的网卡不是eth0，需要登录等工作集群用ip addr show命令查看\n",
    "export NCCL_SOCKET_IFNAME=ens6\n",
    "export DS_BUILD_FUSED_ADAM=1\n",
    "export NCCL_PROTO=simple\n",
    "# export NCCL_DEBUG=INFO\n",
    "export HCCL_OVER_OFI=1\n",
    "#启用efa\n",
    "export FI_PROVIDER=efa\n",
    "export NCCL_IGNORE_DISABLED_P2P=1\n",
    "\n",
    "\n",
    "\n",
    "#注意如果有多个节点，则修改NNODES数了，并依次在各个node上执行llamafactory-cli train\n",
    "if [ \"$NODE_RANK\" == \"0\" ]; then\n",
    "    CUDA_VISIBLE_DEVICES=\"$DEVICES\" NNODES=$WORLD_SIZE_JOB RANK=0 MASTER_ADDR=\"$MASTER_ADDR\" MASTER_PORT=\"$MASTER_PORT\" llamafactory-cli train \"$sg_config\"\n",
    "else\n",
    "    CUDA_VISIBLE_DEVICES=\"$DEVICES\" NNODES=$WORLD_SIZE_JOB RANK=$NODE_RANK MASTER_ADDR=\"$MASTER_ADDR\" MASTER_PORT=\"$MASTER_PORT\" llamafactory-cli train \"$sg_config\"\n",
    "fi\n",
    "\n",
    "if [ \"$NODE_RANK\" == \"0\" ]; then\n",
    "    echo \"*****************finished training, start cp finetuned model*****************************\"\n",
    "    ./s5cmd sync \"/home/ubuntu/finetuned_model\" \"$OUTPUT_MODEL_S3_PATH\"\n",
    "    echo '-----finished cp-------'\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3fdb0b-972a-48ab-9d79-be580753588d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d92c881-75b5-4c3a-885b-1eada74435e7",
   "metadata": {},
   "source": [
    "#### 上传训练脚本到S3 bucket中，之后S3 bucket会挂载到集群所有节点中，这样所有计算节点都可以访问训练代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1520244-4ce5-4207-83bc-a31079ce97fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: hyperpod-scripts/train_batch.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/train_batch.sh\n",
      "upload: hyperpod-scripts/llama_factory_setup.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/llama_factory_setup.sh\n",
      "upload: hyperpod-scripts/train_single_lora.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/train_single_lora.sh\n",
      "upload: hyperpod-scripts/train_multi_ds.sh to s3://sagemaker-us-west-2-434444145045/hyperpod/LLaMA-Factory/train_multi_ds.sh\n"
     ]
    }
   ],
   "source": [
    "!./s5cmd sync ./LLaMA-Factory s3://{bucket}/hyperpod/\n",
    "!aws s3 cp --recursive hyperpod-scripts/ s3://{bucket}/hyperpod/LLaMA-Factory/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfe3ec2-db52-4e3b-9d4d-d773b6720284",
   "metadata": {
    "tags": []
   },
   "source": [
    "cd ~/LLaMA-Factory#### S3 bucket的目录下的代码更像到本地目录\n",
    "```bash\n",
    "sudo su ubuntu\n",
    "cd ~/LLaMA-Factory\n",
    "srun -N2 \"cp\" \"-r\" \"../mnt/hyperpod/LLaMA-Factory/data/dataset_info.json\" \"./data/dataset_info.json\"\n",
    "srun -N2 \"cp\" \"-r\" \"../mnt/hyperpod/LLaMA-Factory/train_multi_ds.sh\" \"./train_multi_ds.sh\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ced339-1324-4b03-956f-3c1f54443720",
   "metadata": {},
   "source": [
    "#### 提交训练\n",
    "```bash\n",
    "# srun -N2 \"bash\" \"llama_factory_setup.sh\"\n",
    "srun -N2 \"bash\" \"train_multi_ds.sh\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21909557-4447-4e29-b647-3d2a42a0df46",
   "metadata": {},
   "source": [
    "## 训练完成之后，删除集群\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ae16570-01d7-48c0-bf57-3b15c236a3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ClusterArn\": \"arn:aws:sagemaker:us-west-2:434444145045:cluster/3h9ogxf9ru7r\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 删除集群\n",
    "\n",
    "!aws sagemaker delete-cluster --cluster-name hyperpod-cluster-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649a6af-0579-4712-92bb-d3df2422c7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
